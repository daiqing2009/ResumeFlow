{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "A100",
   "machine_shape": "hm"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU",
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "30e0fd2014c44738a17d595ff9b4393a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_8fca5cfcd46f4e2ea0e5b4498ba7044b",
       "IPY_MODEL_335c64a9004b4f1cb7f648a1b9c33f7d",
       "IPY_MODEL_c1cf3a8ed43a4da293b8326fb34d4764"
      ],
      "layout": "IPY_MODEL_0adf2cb5b92b472abbd18c29eab6781c"
     }
    },
    "8fca5cfcd46f4e2ea0e5b4498ba7044b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3248639b6ec548ba9275ed277257fea3",
      "placeholder": "​",
      "style": "IPY_MODEL_5e902d434413400ebb2c04a856247e59",
      "value": "model.safetensors.index.json: 100%"
     }
    },
    "335c64a9004b4f1cb7f648a1b9c33f7d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7a6cd52051234c10b5aaea2e649430f2",
      "max": 39072,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_6d7b3938121a42b6b70f1cd73fa5a16c",
      "value": 39072
     }
    },
    "c1cf3a8ed43a4da293b8326fb34d4764": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e4b7bd52087f45b1bac49a15f6f94474",
      "placeholder": "​",
      "style": "IPY_MODEL_37446731e0c14bf08fce31e09039427b",
      "value": " 39.1k/39.1k [00:00&lt;00:00, 4.06MB/s]"
     }
    },
    "0adf2cb5b92b472abbd18c29eab6781c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3248639b6ec548ba9275ed277257fea3": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5e902d434413400ebb2c04a856247e59": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7a6cd52051234c10b5aaea2e649430f2": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6d7b3938121a42b6b70f1cd73fa5a16c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e4b7bd52087f45b1bac49a15f6f94474": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "37446731e0c14bf08fce31e09039427b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5c5f9f942e2c4f3a8951b828507dcd50": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_211ca2b52d934b8b8cf2dbedb0b87536",
       "IPY_MODEL_fa31446ed965456b8d3c30c243da374b",
       "IPY_MODEL_ef140bbc75bb40179187c9cdaa190231"
      ],
      "layout": "IPY_MODEL_8bb92e78cc0a4cd6b8d6142725ea5f52"
     }
    },
    "211ca2b52d934b8b8cf2dbedb0b87536": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8c46c2609a674d4fbb7881b726b3cee8",
      "placeholder": "​",
      "style": "IPY_MODEL_2da46949706743deb0d2c40dca467875",
      "value": "Downloading shards: 100%"
     }
    },
    "fa31446ed965456b8d3c30c243da374b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_551b617a2e274f95971835c399bdc030",
      "max": 4,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_47d13aca26a04084a35c6afb6de6f8e5",
      "value": 4
     }
    },
    "ef140bbc75bb40179187c9cdaa190231": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7ddfc777ff6c4b4ebb021de4330601ac",
      "placeholder": "​",
      "style": "IPY_MODEL_bce3c247bae44a81b42737316541fc30",
      "value": " 4/4 [00:54&lt;00:00, 13.14s/it]"
     }
    },
    "8bb92e78cc0a4cd6b8d6142725ea5f52": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8c46c2609a674d4fbb7881b726b3cee8": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2da46949706743deb0d2c40dca467875": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "551b617a2e274f95971835c399bdc030": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "47d13aca26a04084a35c6afb6de6f8e5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "7ddfc777ff6c4b4ebb021de4330601ac": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bce3c247bae44a81b42737316541fc30": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "84f003ad144647f0ba98d10dff58294e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f7cd87c8d8154c579968698ad3f0d5a0",
       "IPY_MODEL_5f8f70027ff74a6f9798afc3877e45ca",
       "IPY_MODEL_c33025e958f34ebda39aa718754e3456"
      ],
      "layout": "IPY_MODEL_f9a57f804353428cb8bc7b2141ba7bcc"
     }
    },
    "f7cd87c8d8154c579968698ad3f0d5a0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f485948c6aba412b8bb0a4cda9891920",
      "placeholder": "​",
      "style": "IPY_MODEL_e02e1a925a5d4a88a623bd702cd55d73",
      "value": "model-00001-of-00004.safetensors: 100%"
     }
    },
    "5f8f70027ff74a6f9798afc3877e45ca": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "danger",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_71981cc9743a474b89e1d846675a78bb",
      "max": 4903351912,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_2de02f8e19a44bacb7341f30cde6bf50",
      "value": 4903351445
     }
    },
    "c33025e958f34ebda39aa718754e3456": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7b87e37a2f964ce5b47540844ea86898",
      "placeholder": "​",
      "style": "IPY_MODEL_70c36748d0324070bc4afa1717bd02f9",
      "value": " 4.90G/4.90G [00:13&lt;00:00, 914MB/s]"
     }
    },
    "f9a57f804353428cb8bc7b2141ba7bcc": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f485948c6aba412b8bb0a4cda9891920": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e02e1a925a5d4a88a623bd702cd55d73": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "71981cc9743a474b89e1d846675a78bb": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2de02f8e19a44bacb7341f30cde6bf50": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "7b87e37a2f964ce5b47540844ea86898": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "70c36748d0324070bc4afa1717bd02f9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4feb65e9321a4fb0b42c4aee4854aab4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_5d42de59a3604aa1a1687d74647a6096",
       "IPY_MODEL_12cbca8e53284a57b9dbffc8a7e3c839",
       "IPY_MODEL_6382d4bcc0cd4c188dc95cad72ce5577"
      ],
      "layout": "IPY_MODEL_3e5718e8b4cd4f39844772ab679771a4"
     }
    },
    "5d42de59a3604aa1a1687d74647a6096": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_005c1f907d4d4008b4c8e1212d8f3e51",
      "placeholder": "​",
      "style": "IPY_MODEL_e15f690e37ed40a897e431265c385c48",
      "value": "model-00002-of-00004.safetensors: 100%"
     }
    },
    "12cbca8e53284a57b9dbffc8a7e3c839": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "danger",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ca8dfdd1d3c94571a56c193f73a23e44",
      "max": 4947570872,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e3419907bbd5463486c401d7b9ca4a9e",
      "value": 4947570401
     }
    },
    "6382d4bcc0cd4c188dc95cad72ce5577": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d53d574f897841b09e9e4bd7c8005db5",
      "placeholder": "​",
      "style": "IPY_MODEL_7c6c4e6f48894c6285c0e6407e94b472",
      "value": " 4.95G/4.95G [00:15&lt;00:00, 273MB/s]"
     }
    },
    "3e5718e8b4cd4f39844772ab679771a4": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "005c1f907d4d4008b4c8e1212d8f3e51": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e15f690e37ed40a897e431265c385c48": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ca8dfdd1d3c94571a56c193f73a23e44": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e3419907bbd5463486c401d7b9ca4a9e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d53d574f897841b09e9e4bd7c8005db5": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7c6c4e6f48894c6285c0e6407e94b472": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d7831487f6464720a222bde52856f3d2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ce7afc8f65454ba198830589dc279c2f",
       "IPY_MODEL_5b65de46996b41289e2a3b03b74f2a7f",
       "IPY_MODEL_b074e7f4c0074e67a19a5a54e459aa43"
      ],
      "layout": "IPY_MODEL_3bce8313ccd4405e83bba2e7768257c1"
     }
    },
    "ce7afc8f65454ba198830589dc279c2f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_012571ee491c449fb1be1d037cf58ee4",
      "placeholder": "​",
      "style": "IPY_MODEL_16474cb9f98a42cb9ae1041297596c5c",
      "value": "model-00003-of-00004.safetensors: 100%"
     }
    },
    "5b65de46996b41289e2a3b03b74f2a7f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "danger",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3ad2c693ed3d408ead96d270e2d1f2c5",
      "max": 4962221464,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_de5a6de409ef4c51a0871ceb428be315",
      "value": 4962220991
     }
    },
    "b074e7f4c0074e67a19a5a54e459aa43": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7e91373aa682465982bce6674293f5ac",
      "placeholder": "​",
      "style": "IPY_MODEL_8cff32d2f7b3437da4e7170695f5b499",
      "value": " 4.96G/4.96G [00:13&lt;00:00, 441MB/s]"
     }
    },
    "3bce8313ccd4405e83bba2e7768257c1": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "012571ee491c449fb1be1d037cf58ee4": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "16474cb9f98a42cb9ae1041297596c5c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3ad2c693ed3d408ead96d270e2d1f2c5": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "de5a6de409ef4c51a0871ceb428be315": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "7e91373aa682465982bce6674293f5ac": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8cff32d2f7b3437da4e7170695f5b499": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "49d9d54a9a4243e0965c0cab3187e4ab": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_085ef35e71cc478983f86ad90839652e",
       "IPY_MODEL_8606cdaa72b94500adfb10105efb4748",
       "IPY_MODEL_b9f4aa527516421f99a485428794aec9"
      ],
      "layout": "IPY_MODEL_504eb9bc18204f7495f941073519d382"
     }
    },
    "085ef35e71cc478983f86ad90839652e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bb79b9a1255e46c9a6607ba8cba57ccb",
      "placeholder": "​",
      "style": "IPY_MODEL_2eef0eaab0664775aa9e05c8380d7018",
      "value": "model-00004-of-00004.safetensors: 100%"
     }
    },
    "8606cdaa72b94500adfb10105efb4748": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "danger",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dee2228a2ea7495eb9971bd8d1697664",
      "max": 3670322200,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_03a3da2a64964eb89e5dda2b08cbdf59",
      "value": 3670321850
     }
    },
    "b9f4aa527516421f99a485428794aec9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cc4aa26482a94b24a606a4c8a7b3658c",
      "placeholder": "​",
      "style": "IPY_MODEL_abdd9726b88d423a8003efb665b06b42",
      "value": " 3.67G/3.67G [00:10&lt;00:00, 385MB/s]"
     }
    },
    "504eb9bc18204f7495f941073519d382": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bb79b9a1255e46c9a6607ba8cba57ccb": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2eef0eaab0664775aa9e05c8380d7018": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "dee2228a2ea7495eb9971bd8d1697664": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "03a3da2a64964eb89e5dda2b08cbdf59": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "cc4aa26482a94b24a606a4c8a7b3658c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "abdd9726b88d423a8003efb665b06b42": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3423dd06edf4427ab7f260a751a9bcc7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_1c37b5c5fa254a7691b6c3544a8bdc49",
       "IPY_MODEL_3c9e4c50e5464a69800377a0caed9fa2",
       "IPY_MODEL_b4492e4b32c14dca9cc924c0716fc554"
      ],
      "layout": "IPY_MODEL_597a784c9e12401cbf59b33d541d464f"
     }
    },
    "1c37b5c5fa254a7691b6c3544a8bdc49": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8f7ca3b8b61f4957a42bcc4fc039d146",
      "placeholder": "​",
      "style": "IPY_MODEL_96658f1063b24c7c80a8aeab056293c4",
      "value": "Loading checkpoint shards: 100%"
     }
    },
    "3c9e4c50e5464a69800377a0caed9fa2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9296d77d8ec44e48a669657748a27403",
      "max": 4,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_05905324d3eb47b3bde54911bd93d185",
      "value": 4
     }
    },
    "b4492e4b32c14dca9cc924c0716fc554": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6fbcdb2919df4a38baacaf7d854ad5da",
      "placeholder": "​",
      "style": "IPY_MODEL_b6bb9416da7244ff80bc9ace4c8a0fa3",
      "value": " 4/4 [00:07&lt;00:00,  1.75s/it]"
     }
    },
    "597a784c9e12401cbf59b33d541d464f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8f7ca3b8b61f4957a42bcc4fc039d146": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "96658f1063b24c7c80a8aeab056293c4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9296d77d8ec44e48a669657748a27403": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "05905324d3eb47b3bde54911bd93d185": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "6fbcdb2919df4a38baacaf7d854ad5da": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b6bb9416da7244ff80bc9ace4c8a0fa3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "11b93fcd96484236b410a18cdde0322a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b6acf29d6a8e4f939830da8e4c658937",
       "IPY_MODEL_85808a066a374ed2954e94b014d6b1b0",
       "IPY_MODEL_b0335942148145e5a997cf06e80a5bdc"
      ],
      "layout": "IPY_MODEL_a46a733b0c954d2ca315410b607a49cd"
     }
    },
    "b6acf29d6a8e4f939830da8e4c658937": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_370c732e5df64d359971e4312cae30be",
      "placeholder": "​",
      "style": "IPY_MODEL_b66ed4734f8d4947bbc89b53c0287ea3",
      "value": "generation_config.json: 100%"
     }
    },
    "85808a066a374ed2954e94b014d6b1b0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f72f57d98cb54be5af4fa588df399993",
      "max": 190,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_4859ec8dc5ee4b38a8ea3d89628229ab",
      "value": 190
     }
    },
    "b0335942148145e5a997cf06e80a5bdc": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_86ce1ae7e8ec497a807682b8a3d3a0ab",
      "placeholder": "​",
      "style": "IPY_MODEL_c8dda4c205184d16a91e6099e5b86034",
      "value": " 190/190 [00:00&lt;00:00, 24.3kB/s]"
     }
    },
    "a46a733b0c954d2ca315410b607a49cd": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "370c732e5df64d359971e4312cae30be": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b66ed4734f8d4947bbc89b53c0287ea3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f72f57d98cb54be5af4fa588df399993": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4859ec8dc5ee4b38a8ea3d89628229ab": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "86ce1ae7e8ec497a807682b8a3d3a0ab": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c8dda4c205184d16a91e6099e5b86034": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "759254a1560944169d0b9c1a891b55a0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a9d89b69a12c46b1930471b71d5a1120",
       "IPY_MODEL_1dc11b01ea53417692a7c8239d8265b2",
       "IPY_MODEL_f5b8a71a451345b29979150cd3944a02"
      ],
      "layout": "IPY_MODEL_e1a64bb27b8f4c98bb98c67f7905c400"
     }
    },
    "a9d89b69a12c46b1930471b71d5a1120": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8e2844fb6f7746b4b843d5e428d0a3c1",
      "placeholder": "​",
      "style": "IPY_MODEL_62ea0af5eaa944de887c00784bb2ac03",
      "value": "tokenizer_config.json: 100%"
     }
    },
    "1dc11b01ea53417692a7c8239d8265b2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b38b887141c74c4ba58c20ee93e6875d",
      "max": 46405,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_8769875eb0c24587bf4e6ff24b95cd33",
      "value": 46405
     }
    },
    "f5b8a71a451345b29979150cd3944a02": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5e9d2ff9de984295aa579197076b96c2",
      "placeholder": "​",
      "style": "IPY_MODEL_87715e6c80be415e97e820eef73a5c0c",
      "value": " 46.4k/46.4k [00:00&lt;00:00, 5.77MB/s]"
     }
    },
    "e1a64bb27b8f4c98bb98c67f7905c400": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8e2844fb6f7746b4b843d5e428d0a3c1": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "62ea0af5eaa944de887c00784bb2ac03": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b38b887141c74c4ba58c20ee93e6875d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8769875eb0c24587bf4e6ff24b95cd33": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "5e9d2ff9de984295aa579197076b96c2": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "87715e6c80be415e97e820eef73a5c0c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9a6fd1a841a74fee96a950c8e89c297e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_48eb5f41a35d4901adce66a303048b77",
       "IPY_MODEL_92350590b3fd4e9981d47133cea4303a",
       "IPY_MODEL_30b412b867ca494e8044139ea0aec888"
      ],
      "layout": "IPY_MODEL_072bd61edd544180bb42e228c6aad48f"
     }
    },
    "48eb5f41a35d4901adce66a303048b77": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0fa9136ad3ce4cb9a530efb2537aae5a",
      "placeholder": "​",
      "style": "IPY_MODEL_795dec924c1c473d88bc691e422b5168",
      "value": "tokenizer.model: 100%"
     }
    },
    "92350590b3fd4e9981d47133cea4303a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_87d56e79224d4b08a652f26930c2d252",
      "max": 4241003,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b89d6793c7b645ff8a937453cf456f2f",
      "value": 4241003
     }
    },
    "30b412b867ca494e8044139ea0aec888": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_73888b89739d40e7a9455e99dd13400b",
      "placeholder": "​",
      "style": "IPY_MODEL_a8d0bb160b4444d887132e843e50e688",
      "value": " 4.24M/4.24M [00:00&lt;00:00, 77.7MB/s]"
     }
    },
    "072bd61edd544180bb42e228c6aad48f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0fa9136ad3ce4cb9a530efb2537aae5a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "795dec924c1c473d88bc691e422b5168": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "87d56e79224d4b08a652f26930c2d252": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b89d6793c7b645ff8a937453cf456f2f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "73888b89739d40e7a9455e99dd13400b": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a8d0bb160b4444d887132e843e50e688": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "30d142a0ac1d4c588c8f433ea0ab0493": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_17c76e3176cc44579da4c620931ed0df",
       "IPY_MODEL_dbb6046f2e6042f88471cb14c6a732fa",
       "IPY_MODEL_0a46af65a8a742fea2166e7e19739272"
      ],
      "layout": "IPY_MODEL_40c072a877084986bcbd0c9357cb3a2d"
     }
    },
    "17c76e3176cc44579da4c620931ed0df": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_715f5592de7948d0bad793b545780dc0",
      "placeholder": "​",
      "style": "IPY_MODEL_0beaf6a289c6404da63b2bd3440f761c",
      "value": "special_tokens_map.json: 100%"
     }
    },
    "dbb6046f2e6042f88471cb14c6a732fa": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9f5cda7f2721436fa306ddf7cceeb496",
      "max": 636,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c92464cb82cd4781b4cc78d7e8be25bd",
      "value": 636
     }
    },
    "0a46af65a8a742fea2166e7e19739272": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f0c88ace2d94483391d0af5913b2f72b",
      "placeholder": "​",
      "style": "IPY_MODEL_49b26af4a5b24b78a4ac0292e03be860",
      "value": " 636/636 [00:00&lt;00:00, 83.5kB/s]"
     }
    },
    "40c072a877084986bcbd0c9357cb3a2d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "715f5592de7948d0bad793b545780dc0": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0beaf6a289c6404da63b2bd3440f761c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9f5cda7f2721436fa306ddf7cceeb496": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c92464cb82cd4781b4cc78d7e8be25bd": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "f0c88ace2d94483391d0af5913b2f72b": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "49b26af4a5b24b78a4ac0292e03be860": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "02f363b337ea4eeeaf7c1229b47f634e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_7e439350e3844757be55b65b5250c55e",
       "IPY_MODEL_a7d4e2a1303946569aa8c04ea0d94f1c",
       "IPY_MODEL_bd7e375b9d3647b6b59d686abc3cf2d6"
      ],
      "layout": "IPY_MODEL_9628a92fbabb43f9870c9e918cd1cbc4"
     }
    },
    "7e439350e3844757be55b65b5250c55e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_721590f023a6450ca28ad47eb16cf3eb",
      "placeholder": "​",
      "style": "IPY_MODEL_5ea343b7d4344e1b80d8fd999964cfd9",
      "value": "tokenizer.json: 100%"
     }
    },
    "a7d4e2a1303946569aa8c04ea0d94f1c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_be7940ae0c0746ea90de4cc921bab9c7",
      "max": 17525357,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_8519b65396124368bbb670d23253518b",
      "value": 17525357
     }
    },
    "bd7e375b9d3647b6b59d686abc3cf2d6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6d83e2217b1c4980beeb88c21e04fd36",
      "placeholder": "​",
      "style": "IPY_MODEL_8edafe37ba7e45a6a68550d0e47da6c9",
      "value": " 17.5M/17.5M [00:00&lt;00:00, 43.1MB/s]"
     }
    },
    "9628a92fbabb43f9870c9e918cd1cbc4": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "721590f023a6450ca28ad47eb16cf3eb": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5ea343b7d4344e1b80d8fd999964cfd9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "be7940ae0c0746ea90de4cc921bab9c7": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8519b65396124368bbb670d23253518b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "6d83e2217b1c4980beeb88c21e04fd36": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8edafe37ba7e45a6a68550d0e47da6c9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c5b6c161f4454656be06029159084661": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_cd8f8bc9e22141f6bc114375f76d6fae",
       "IPY_MODEL_2e5b0a85d1394b4682f1d4e4f3840094",
       "IPY_MODEL_e0f1090badf14723ae9977d109c1d874"
      ],
      "layout": "IPY_MODEL_53a1d8dbc1da4aef989de49966dd9f85"
     }
    },
    "cd8f8bc9e22141f6bc114375f76d6fae": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7167296f15cb48a598f50aeb4b4eb375",
      "placeholder": "​",
      "style": "IPY_MODEL_bbe90c278a614b618832c5219de2e1a0",
      "value": "README.md: 100%"
     }
    },
    "2e5b0a85d1394b4682f1d4e4f3840094": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5d7ba063866e4722b898fa777d2e1e08",
      "max": 31,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_65233e82a28746e0859a2d145806b4eb",
      "value": 31
     }
    },
    "e0f1090badf14723ae9977d109c1d874": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fbd4b9339f7f4eadb7ec20719ff02417",
      "placeholder": "​",
      "style": "IPY_MODEL_5fc2f15ea2884087a3efdafb713866b6",
      "value": " 31.0/31.0 [00:00&lt;00:00, 3.54kB/s]"
     }
    },
    "53a1d8dbc1da4aef989de49966dd9f85": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7167296f15cb48a598f50aeb4b4eb375": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bbe90c278a614b618832c5219de2e1a0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5d7ba063866e4722b898fa777d2e1e08": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "65233e82a28746e0859a2d145806b4eb": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "fbd4b9339f7f4eadb7ec20719ff02417": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5fc2f15ea2884087a3efdafb713866b6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4fc4087c99ea403f876c79fe88e48143": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_1ec0e1d1bfb04bb2b48b5cce032e9d8e",
       "IPY_MODEL_bf26e4e92cb24d648d609b01435b66bb",
       "IPY_MODEL_5ff536ac5cf0472ca666c7cf466e0211"
      ],
      "layout": "IPY_MODEL_6a166d1c1b224a6fbeed1f8e8b8c2230"
     }
    },
    "1ec0e1d1bfb04bb2b48b5cce032e9d8e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0ffbb56793d2475795bb1d45697a4d9e",
      "placeholder": "​",
      "style": "IPY_MODEL_b824e25deca844f0b26a8d3201329be1",
      "value": "finetuning_ds_v2.json: 100%"
     }
    },
    "bf26e4e92cb24d648d609b01435b66bb": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_182ec7733be442b7b13cf9c4295e0c9f",
      "max": 17036634,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b44e54aee7924aceba1842feb6ffb6bf",
      "value": 17036634
     }
    },
    "5ff536ac5cf0472ca666c7cf466e0211": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e304d1cffce74dbaaca876488a3f0573",
      "placeholder": "​",
      "style": "IPY_MODEL_4edca43de2a34127819b521bc60b32f3",
      "value": " 17.0M/17.0M [00:00&lt;00:00, 106MB/s]"
     }
    },
    "6a166d1c1b224a6fbeed1f8e8b8c2230": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0ffbb56793d2475795bb1d45697a4d9e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b824e25deca844f0b26a8d3201329be1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "182ec7733be442b7b13cf9c4295e0c9f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b44e54aee7924aceba1842feb6ffb6bf": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e304d1cffce74dbaaca876488a3f0573": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4edca43de2a34127819b521bc60b32f3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9e668eabee474293a840b207b53243d5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_5c4bf0fa73ef4979afd48ab3a228251c",
       "IPY_MODEL_0879a652f2674d208043b6e045710947",
       "IPY_MODEL_d48f0c4531a64f48b42419c1a0b6165a"
      ],
      "layout": "IPY_MODEL_c5f253ca8fee49ba91c3c0e199e3cd64"
     }
    },
    "5c4bf0fa73ef4979afd48ab3a228251c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_93c9aa916bc2481691b69c600c3e0c94",
      "placeholder": "​",
      "style": "IPY_MODEL_6f76876194874a64beaea0fc4e256427",
      "value": "Generating train split: 100%"
     }
    },
    "0879a652f2674d208043b6e045710947": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dc5027c3020f4789b8552a6fd8cf092b",
      "max": 1691,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_63377973facc4969883970fe8f23498e",
      "value": 1691
     }
    },
    "d48f0c4531a64f48b42419c1a0b6165a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_22bd89bd83d34824909e4a5026bac00c",
      "placeholder": "​",
      "style": "IPY_MODEL_c8bdfc7ad96a4eb0865f18fc828ca2c9",
      "value": " 1691/1691 [00:00&lt;00:00, 11927.02 examples/s]"
     }
    },
    "c5f253ca8fee49ba91c3c0e199e3cd64": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "93c9aa916bc2481691b69c600c3e0c94": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6f76876194874a64beaea0fc4e256427": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "dc5027c3020f4789b8552a6fd8cf092b": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "63377973facc4969883970fe8f23498e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "22bd89bd83d34824909e4a5026bac00c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c8bdfc7ad96a4eb0865f18fc828ca2c9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f0919e4ec75d4ed88db84561ccaa3834": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_803d0e1592dd4a1eb9c366daff094565",
       "IPY_MODEL_f58803a382d94e4eaa629dfe748c8d46",
       "IPY_MODEL_8ded6bdda8c7464ca7424669121e1acd"
      ],
      "layout": "IPY_MODEL_9596a00ea08a40b6a40d8ccf0bab446f"
     }
    },
    "803d0e1592dd4a1eb9c366daff094565": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_39ece10f07954503b108cfa629b89c39",
      "placeholder": "​",
      "style": "IPY_MODEL_db40f2612ef841dcbae74e9a5f90605c",
      "value": "Map: 100%"
     }
    },
    "f58803a382d94e4eaa629dfe748c8d46": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a769e248e07c4c9dab5e9191ef929a8b",
      "max": 1691,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_032f5e307335415c9838fff96575e1bb",
      "value": 1691
     }
    },
    "8ded6bdda8c7464ca7424669121e1acd": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fa383fab96c1438caaf40eef46698b01",
      "placeholder": "​",
      "style": "IPY_MODEL_9f4c27e837b34d7b9bc51b0214b8b6d9",
      "value": " 1691/1691 [00:00&lt;00:00, 15645.87 examples/s]"
     }
    },
    "9596a00ea08a40b6a40d8ccf0bab446f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "39ece10f07954503b108cfa629b89c39": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "db40f2612ef841dcbae74e9a5f90605c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a769e248e07c4c9dab5e9191ef929a8b": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "032f5e307335415c9838fff96575e1bb": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "fa383fab96c1438caaf40eef46698b01": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9f4c27e837b34d7b9bc51b0214b8b6d9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "83e0fb0db26b4ae3aeb98854408c882a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_808f90a750eb4af68ceebb6ec049a607",
       "IPY_MODEL_d7a6f98cec31474e9854e950bf0b0139",
       "IPY_MODEL_ed3754e2af784c71b43c537ba3b30359"
      ],
      "layout": "IPY_MODEL_28454556c91e45ed900603223c0bca62"
     }
    },
    "808f90a750eb4af68ceebb6ec049a607": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e68b8b5c87e94a07aa657ab94a923732",
      "placeholder": "​",
      "style": "IPY_MODEL_f31226542b8f4b2f902600fd88f0a402",
      "value": "Unsloth: Tokenizing [&quot;text&quot;] (num_proc=2): 100%"
     }
    },
    "d7a6f98cec31474e9854e950bf0b0139": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6908f8645e3e49a58a6f82651fdac9e2",
      "max": 1691,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_0654cf6763eb46aa8692469bce7210e9",
      "value": 1691
     }
    },
    "ed3754e2af784c71b43c537ba3b30359": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3179c16d7598432da9e327d0d3bf60bf",
      "placeholder": "​",
      "style": "IPY_MODEL_3720e4dc1afb420786055bf733eeec4f",
      "value": " 1691/1691 [00:08&lt;00:00, 249.53 examples/s]"
     }
    },
    "28454556c91e45ed900603223c0bca62": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e68b8b5c87e94a07aa657ab94a923732": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f31226542b8f4b2f902600fd88f0a402": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6908f8645e3e49a58a6f82651fdac9e2": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0654cf6763eb46aa8692469bce7210e9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "3179c16d7598432da9e327d0d3bf60bf": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3720e4dc1afb420786055bf733eeec4f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "701ded583d78417baf61633d7dc0e71c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_45497f50783347349717f5022485499d",
       "IPY_MODEL_d4fed4b171514f51a114dacc20b23edc",
       "IPY_MODEL_6b06d13ebab54e6fb6a6a42275a6d81c"
      ],
      "layout": "IPY_MODEL_1a55efc6afc2445fb7f92d10ec7f67af"
     }
    },
    "45497f50783347349717f5022485499d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0bf4329a71114d8daf695908cd66680d",
      "placeholder": "​",
      "style": "IPY_MODEL_a8c00a35351749faaddb32aadf675c2b",
      "value": "100%"
     }
    },
    "d4fed4b171514f51a114dacc20b23edc": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_59b46f14b2194d9dbd6cf812024a105b",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_6b12d237b06d4f86b9e2cc95e879eb6a",
      "value": 1
     }
    },
    "6b06d13ebab54e6fb6a6a42275a6d81c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bac1439d6b544edc935e53e463988abb",
      "placeholder": "​",
      "style": "IPY_MODEL_682606dc902743a0b99072dccd14c7c3",
      "value": " 1/1 [01:24&lt;00:00, 84.70s/it]"
     }
    },
    "1a55efc6afc2445fb7f92d10ec7f67af": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0bf4329a71114d8daf695908cd66680d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a8c00a35351749faaddb32aadf675c2b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "59b46f14b2194d9dbd6cf812024a105b": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6b12d237b06d4f86b9e2cc95e879eb6a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "bac1439d6b544edc935e53e463988abb": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "682606dc902743a0b99072dccd14c7c3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b414dfb0457d477988033fe97e4d1fc6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_421251eccdee4c559cdcb796a69d3ac9",
       "IPY_MODEL_f0866a0fcfbb457c8025a76144769819",
       "IPY_MODEL_d6724e577534472eb78ad6a3bb81806b"
      ],
      "layout": "IPY_MODEL_44067b13ff8942a1b3fcd2447d300554"
     }
    },
    "421251eccdee4c559cdcb796a69d3ac9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f1f08294b0c341ca87856a848448ca5f",
      "placeholder": "​",
      "style": "IPY_MODEL_630d08330f6d42ba81dfa1dc70935289",
      "value": "unsloth.Q8_0.gguf: "
     }
    },
    "f0866a0fcfbb457c8025a76144769819": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dcedd2b6a6e5474fa2e3fb9d8a13ee20",
      "max": 9827148000,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_eae5cfa670fb40448bace35ec4b02bd5",
      "value": 9827148000
     }
    },
    "d6724e577534472eb78ad6a3bb81806b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c43c2c0150c6413086c9d9237b7b9891",
      "placeholder": "​",
      "style": "IPY_MODEL_5da4a7f77875490386844d8da87cc9fe",
      "value": " 9.84G/? [01:24&lt;00:00, 549MB/s]"
     }
    },
    "44067b13ff8942a1b3fcd2447d300554": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f1f08294b0c341ca87856a848448ca5f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "630d08330f6d42ba81dfa1dc70935289": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "dcedd2b6a6e5474fa2e3fb9d8a13ee20": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "eae5cfa670fb40448bace35ec4b02bd5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "c43c2c0150c6413086c9d9237b7b9891": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5da4a7f77875490386844d8da87cc9fe": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d00dbff7a4b04ca3bdc40aa74b01fe57": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ecd93aa09b104ebeb1a9f8abb5ce832e",
       "IPY_MODEL_924446feeac444809846c4b8cc4772ec",
       "IPY_MODEL_59ad1421227a4049a645d1bfa3c6e496"
      ],
      "layout": "IPY_MODEL_dc33e26fff804b69bed80b7a258e0658"
     }
    },
    "ecd93aa09b104ebeb1a9f8abb5ce832e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_35a74584417a4eec9a9001e34b2fcfb2",
      "placeholder": "​",
      "style": "IPY_MODEL_a2d9f584ea694f9da723588d3851dfca",
      "value": "100%"
     }
    },
    "924446feeac444809846c4b8cc4772ec": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f62c093297e44b4d96ffd7a1bea90c1f",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_af7cd6c59c984d90b08e193942e50113",
      "value": 1
     }
    },
    "59ad1421227a4049a645d1bfa3c6e496": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f4e62442a670401f97fd2cf217a807c1",
      "placeholder": "​",
      "style": "IPY_MODEL_9d3ebc1d42de46df8898ae52716836d4",
      "value": " 1/1 [00:51&lt;00:00, 51.83s/it]"
     }
    },
    "dc33e26fff804b69bed80b7a258e0658": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "35a74584417a4eec9a9001e34b2fcfb2": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a2d9f584ea694f9da723588d3851dfca": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f62c093297e44b4d96ffd7a1bea90c1f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "af7cd6c59c984d90b08e193942e50113": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "f4e62442a670401f97fd2cf217a807c1": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9d3ebc1d42de46df8898ae52716836d4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "64c85b6218b044f0811c7af2b2bd2a2d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_824c1737562f4c2caff110c1e9cb9793",
       "IPY_MODEL_4ad9a932964d4b0baa9998fce8ca4264",
       "IPY_MODEL_d437a62deade44108bfdc6c5365141ab"
      ],
      "layout": "IPY_MODEL_c70f3097e04541039184400aabb4caa0"
     }
    },
    "824c1737562f4c2caff110c1e9cb9793": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_033a452869cf4391aa110b863d3b7c71",
      "placeholder": "​",
      "style": "IPY_MODEL_219ac65b85504b0984b06c67944b2ea2",
      "value": "unsloth.Q4_1.gguf: "
     }
    },
    "4ad9a932964d4b0baa9998fce8ca4264": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d8bfb69c96f2499286bced5b96d28710",
      "max": 5963366624,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_83924fd6ba7348e8b7edc34bad4da41e",
      "value": 5963366624
     }
    },
    "d437a62deade44108bfdc6c5365141ab": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_48d7e78993db4c7b82e3e23cf1d7b8da",
      "placeholder": "​",
      "style": "IPY_MODEL_5d858730982d45ad9092e0ca9df9fcb7",
      "value": " 5.97G/? [00:51&lt;00:00, 657MB/s]"
     }
    },
    "c70f3097e04541039184400aabb4caa0": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "033a452869cf4391aa110b863d3b7c71": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "219ac65b85504b0984b06c67944b2ea2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d8bfb69c96f2499286bced5b96d28710": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "83924fd6ba7348e8b7edc34bad4da41e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "48d7e78993db4c7b82e3e23cf1d7b8da": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5d858730982d45ad9092e0ca9df9fcb7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e9a707a78f454fe481c5f843988e5ec9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_fc4412542769418db5c362b2ef548e7f",
       "IPY_MODEL_4a94bc2a8e4941548c59e271e032291d",
       "IPY_MODEL_ea81e50ef52b4ad5afc266f6e2b67c27"
      ],
      "layout": "IPY_MODEL_63059fad228947edbc4f514428d18591"
     }
    },
    "fc4412542769418db5c362b2ef548e7f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6ad5aa9e57b54138b356e5332f197914",
      "placeholder": "​",
      "style": "IPY_MODEL_9816963e63994c65b635a2c1048b2a67",
      "value": "100%"
     }
    },
    "4a94bc2a8e4941548c59e271e032291d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7a2024faf8e0476c8b9b100c0d84909f",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_7c9a5285e0fe41189c0e54e8e5dfea25",
      "value": 1
     }
    },
    "ea81e50ef52b4ad5afc266f6e2b67c27": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_09278433f06e4cddb64c4470f54d6ab9",
      "placeholder": "​",
      "style": "IPY_MODEL_df868ffcbf1147b6b9ac1550fe8101b6",
      "value": " 1/1 [00:50&lt;00:00, 50.62s/it]"
     }
    },
    "63059fad228947edbc4f514428d18591": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6ad5aa9e57b54138b356e5332f197914": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9816963e63994c65b635a2c1048b2a67": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7a2024faf8e0476c8b9b100c0d84909f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7c9a5285e0fe41189c0e54e8e5dfea25": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "09278433f06e4cddb64c4470f54d6ab9": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "df868ffcbf1147b6b9ac1550fe8101b6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "dca90da87e7341c1a810558a500e447a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e6a0196ab9684632a428c59ace7303da",
       "IPY_MODEL_5dde400c225f4be2a5695f2ad1fefe11",
       "IPY_MODEL_526acd1a464f4ef3a00078ae3d0e5f74"
      ],
      "layout": "IPY_MODEL_874e200a52c243aa98e30e880c845a86"
     }
    },
    "e6a0196ab9684632a428c59ace7303da": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ad48076521fb4ab88f62411bc1bec8bc",
      "placeholder": "​",
      "style": "IPY_MODEL_1846ea7eb79e4a219a62ed2f81c4c5bf",
      "value": "unsloth.Q4_K_M.gguf: "
     }
    },
    "5dde400c225f4be2a5695f2ad1fefe11": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dd6b5364a2c84dbbbf33295a6e118347",
      "max": 5761056992,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_8c55cc46e6004395864c0eecb65f23c4",
      "value": 5761056992
     }
    },
    "526acd1a464f4ef3a00078ae3d0e5f74": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fa4812ecab9e4b7c99f2c9c9b3d69c19",
      "placeholder": "​",
      "style": "IPY_MODEL_17b28507d88a421fbb4bddd830fb0d99",
      "value": " 5.78G/? [00:50&lt;00:00, 224MB/s]"
     }
    },
    "874e200a52c243aa98e30e880c845a86": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ad48076521fb4ab88f62411bc1bec8bc": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1846ea7eb79e4a219a62ed2f81c4c5bf": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "dd6b5364a2c84dbbbf33295a6e118347": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8c55cc46e6004395864c0eecb65f23c4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "fa4812ecab9e4b7c99f2c9c9b3d69c19": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "17b28507d88a421fbb4bddd830fb0d99": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f315YrI2Mp7N"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install unsloth\n",
    "# Also get the latest nightly Unsloth!\n",
    "!pip install --force-reinstall --no-cache-dir --no-deps git+https://github.com/unslothai/unsloth.git\n",
    "!pip install --upgrade --force-reinstall --no-cache-dir --no-deps git+https://github.com/unslothai/unsloth-zoo.git"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "if torch.cuda.get_device_capability()[0] >= 8:\n",
    "    !pip install --no-deps packaging ninja einops \"flash-attn>=2.6.3\""
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X7pzc8GCW8QE",
    "outputId": "ac517374-9d7e-4b09-d809-04e9bd61d227"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (24.2)\n",
      "Collecting ninja\n",
      "  Downloading ninja-1.11.1.3-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (5.3 kB)\n",
      "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (0.8.1)\n",
      "Collecting flash-attn>=2.6.3\n",
      "  Downloading flash_attn-2.7.4.post1.tar.gz (6.0 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m6.0/6.0 MB\u001B[0m \u001B[31m109.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25h  Preparing metadata (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "Using cached ninja-1.11.1.3-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (422 kB)\n",
      "Building wheels for collected packages: flash-attn\n",
      "  Building wheel for flash-attn (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "  Created wheel for flash-attn: filename=flash_attn-2.7.4.post1-cp311-cp311-linux_x86_64.whl size=187831595 sha256=58853b28a5a926cae14402bfd8d4d93a45ebf8f9e79533f37ab09d0d77a99c05\n",
      "  Stored in directory: /root/.cache/pip/wheels/3d/88/d8/284b89f56af7d5bf366b10d6b8e251ac8a7c7bf3f04203fb4f\n",
      "Successfully built flash-attn\n",
      "Installing collected packages: ninja, flash-attn\n",
      "Successfully installed flash-attn-2.7.4.post1 ninja-1.11.1.3\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install evaluate"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3TCiaO39gHLi",
    "outputId": "98b16a63-51f2-448f-8117-d39e0ccacc1f"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting evaluate\n",
      "  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.4.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from evaluate) (1.26.4)\n",
      "Requirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from evaluate) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.70.16)\n",
      "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.10.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.28.1)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from evaluate) (24.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (3.17.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (18.1.0)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (3.11.13)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2025.1.31)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (25.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (0.3.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.18.3)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\n",
      "Downloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m84.0/84.0 kB\u001B[0m \u001B[31m9.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hInstalling collected packages: evaluate\n",
      "Successfully installed evaluate-0.4.3\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install --upgrade evaluate"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "STOrvkqY9PNx",
    "outputId": "990f17e7-09c5-48b7-ba67-ac82c7032d83"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: evaluate in /usr/local/lib/python3.11/dist-packages (0.4.3)\n",
      "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.4.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from evaluate) (1.26.4)\n",
      "Requirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from evaluate) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.70.16)\n",
      "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.10.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.28.1)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from evaluate) (24.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (3.17.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (18.1.0)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (3.11.13)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2025.1.31)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (25.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (0.3.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.18.3)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install --upgrade transformers"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0iuj1YWF7--n",
    "outputId": "2c0fe7c8-501c-4cf5-fb56-f130fb825a9d"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.48.3)\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.49.0-py3-none-any.whl.metadata (44 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m44.0/44.0 kB\u001B[0m \u001B[31m3.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.17.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.28.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (2024.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n",
      "Downloading transformers-4.49.0-py3-none-any.whl (10.0 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m10.0/10.0 MB\u001B[0m \u001B[31m122.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hInstalling collected packages: transformers\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.48.3\n",
      "    Uninstalling transformers-4.48.3:\n",
      "      Successfully uninstalled transformers-4.48.3\n",
      "Successfully installed transformers-4.49.0\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from unsloth import FastLanguageModel\n",
    "# import os\n",
    "# os.environ[\"UNSLOTH_RETURN_LOGITS\"] = \"1\"\n",
    "max_seq_length = 4096  # Choose any! We auto support RoPE Scaling internally!\n",
    "dtype = (\n",
    "    None  # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n",
    ")\n",
    "load_in_4bit = False  # Use 4bit quantization to reduce memory usage. Can be False.\n",
    "load_in_8bit = False\n",
    "# 4bit pre quantized models we support for 4x faster downloading + no OOMs.\n",
    "fourbit_models = [\n",
    "    \"unsloth/Meta-Llama-3.1-8B-bnb-4bit\",  # Llama-3.1 15 trillion tokens model 2x faster!\n",
    "    \"unsloth/Meta-Llama-3.1-8B-Instruct-bnb-4bit\",\n",
    "    \"unsloth/Meta-Llama-3.1-70B-bnb-4bit\",\n",
    "    \"unsloth/Meta-Llama-3.1-405B-bnb-4bit\",  # We also uploaded 4bit for 405b!\n",
    "    \"unsloth/Mistral-Nemo-Base-2407-bnb-4bit\",  # New Mistral 12b 2x faster!\n",
    "    \"unsloth/Mistral-Nemo-Instruct-2407-bnb-4bit\",\n",
    "    \"unsloth/mistral-7b-v0.3-bnb-4bit\",  # Mistral v3 2x faster!\n",
    "    \"unsloth/mistral-7b-instruct-v0.3-bnb-4bit\",\n",
    "    \"unsloth/Phi-3.5-mini-instruct\",  # Phi-3.5 2x faster!\n",
    "    \"unsloth/Phi-3-medium-4k-instruct\",\n",
    "    \"unsloth/gemma-2-9b-bnb-4bit\",\n",
    "    \"unsloth/gemma-2-27b-bnb-4bit\",  # Gemma 2x faster!\n",
    "]  # More models at https://huggingface.co/unsloth\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name=\"unsloth/gemma-2-9b\",\n",
    "    max_seq_length=max_seq_length,\n",
    "    dtype=dtype,\n",
    "    load_in_4bit=load_in_4bit,\n",
    "    load_in_8bit = load_in_8bit,\n",
    "    # token = \"hf_...\", # use one if using gated models like meta-llama/Llama-2-7b-hf\n",
    ")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 672,
     "referenced_widgets": [
      "30e0fd2014c44738a17d595ff9b4393a",
      "8fca5cfcd46f4e2ea0e5b4498ba7044b",
      "335c64a9004b4f1cb7f648a1b9c33f7d",
      "c1cf3a8ed43a4da293b8326fb34d4764",
      "0adf2cb5b92b472abbd18c29eab6781c",
      "3248639b6ec548ba9275ed277257fea3",
      "5e902d434413400ebb2c04a856247e59",
      "7a6cd52051234c10b5aaea2e649430f2",
      "6d7b3938121a42b6b70f1cd73fa5a16c",
      "e4b7bd52087f45b1bac49a15f6f94474",
      "37446731e0c14bf08fce31e09039427b",
      "5c5f9f942e2c4f3a8951b828507dcd50",
      "211ca2b52d934b8b8cf2dbedb0b87536",
      "fa31446ed965456b8d3c30c243da374b",
      "ef140bbc75bb40179187c9cdaa190231",
      "8bb92e78cc0a4cd6b8d6142725ea5f52",
      "8c46c2609a674d4fbb7881b726b3cee8",
      "2da46949706743deb0d2c40dca467875",
      "551b617a2e274f95971835c399bdc030",
      "47d13aca26a04084a35c6afb6de6f8e5",
      "7ddfc777ff6c4b4ebb021de4330601ac",
      "bce3c247bae44a81b42737316541fc30",
      "84f003ad144647f0ba98d10dff58294e",
      "f7cd87c8d8154c579968698ad3f0d5a0",
      "5f8f70027ff74a6f9798afc3877e45ca",
      "c33025e958f34ebda39aa718754e3456",
      "f9a57f804353428cb8bc7b2141ba7bcc",
      "f485948c6aba412b8bb0a4cda9891920",
      "e02e1a925a5d4a88a623bd702cd55d73",
      "71981cc9743a474b89e1d846675a78bb",
      "2de02f8e19a44bacb7341f30cde6bf50",
      "7b87e37a2f964ce5b47540844ea86898",
      "70c36748d0324070bc4afa1717bd02f9",
      "4feb65e9321a4fb0b42c4aee4854aab4",
      "5d42de59a3604aa1a1687d74647a6096",
      "12cbca8e53284a57b9dbffc8a7e3c839",
      "6382d4bcc0cd4c188dc95cad72ce5577",
      "3e5718e8b4cd4f39844772ab679771a4",
      "005c1f907d4d4008b4c8e1212d8f3e51",
      "e15f690e37ed40a897e431265c385c48",
      "ca8dfdd1d3c94571a56c193f73a23e44",
      "e3419907bbd5463486c401d7b9ca4a9e",
      "d53d574f897841b09e9e4bd7c8005db5",
      "7c6c4e6f48894c6285c0e6407e94b472",
      "d7831487f6464720a222bde52856f3d2",
      "ce7afc8f65454ba198830589dc279c2f",
      "5b65de46996b41289e2a3b03b74f2a7f",
      "b074e7f4c0074e67a19a5a54e459aa43",
      "3bce8313ccd4405e83bba2e7768257c1",
      "012571ee491c449fb1be1d037cf58ee4",
      "16474cb9f98a42cb9ae1041297596c5c",
      "3ad2c693ed3d408ead96d270e2d1f2c5",
      "de5a6de409ef4c51a0871ceb428be315",
      "7e91373aa682465982bce6674293f5ac",
      "8cff32d2f7b3437da4e7170695f5b499",
      "49d9d54a9a4243e0965c0cab3187e4ab",
      "085ef35e71cc478983f86ad90839652e",
      "8606cdaa72b94500adfb10105efb4748",
      "b9f4aa527516421f99a485428794aec9",
      "504eb9bc18204f7495f941073519d382",
      "bb79b9a1255e46c9a6607ba8cba57ccb",
      "2eef0eaab0664775aa9e05c8380d7018",
      "dee2228a2ea7495eb9971bd8d1697664",
      "03a3da2a64964eb89e5dda2b08cbdf59",
      "cc4aa26482a94b24a606a4c8a7b3658c",
      "abdd9726b88d423a8003efb665b06b42",
      "3423dd06edf4427ab7f260a751a9bcc7",
      "1c37b5c5fa254a7691b6c3544a8bdc49",
      "3c9e4c50e5464a69800377a0caed9fa2",
      "b4492e4b32c14dca9cc924c0716fc554",
      "597a784c9e12401cbf59b33d541d464f",
      "8f7ca3b8b61f4957a42bcc4fc039d146",
      "96658f1063b24c7c80a8aeab056293c4",
      "9296d77d8ec44e48a669657748a27403",
      "05905324d3eb47b3bde54911bd93d185",
      "6fbcdb2919df4a38baacaf7d854ad5da",
      "b6bb9416da7244ff80bc9ace4c8a0fa3",
      "11b93fcd96484236b410a18cdde0322a",
      "b6acf29d6a8e4f939830da8e4c658937",
      "85808a066a374ed2954e94b014d6b1b0",
      "b0335942148145e5a997cf06e80a5bdc",
      "a46a733b0c954d2ca315410b607a49cd",
      "370c732e5df64d359971e4312cae30be",
      "b66ed4734f8d4947bbc89b53c0287ea3",
      "f72f57d98cb54be5af4fa588df399993",
      "4859ec8dc5ee4b38a8ea3d89628229ab",
      "86ce1ae7e8ec497a807682b8a3d3a0ab",
      "c8dda4c205184d16a91e6099e5b86034",
      "759254a1560944169d0b9c1a891b55a0",
      "a9d89b69a12c46b1930471b71d5a1120",
      "1dc11b01ea53417692a7c8239d8265b2",
      "f5b8a71a451345b29979150cd3944a02",
      "e1a64bb27b8f4c98bb98c67f7905c400",
      "8e2844fb6f7746b4b843d5e428d0a3c1",
      "62ea0af5eaa944de887c00784bb2ac03",
      "b38b887141c74c4ba58c20ee93e6875d",
      "8769875eb0c24587bf4e6ff24b95cd33",
      "5e9d2ff9de984295aa579197076b96c2",
      "87715e6c80be415e97e820eef73a5c0c",
      "9a6fd1a841a74fee96a950c8e89c297e",
      "48eb5f41a35d4901adce66a303048b77",
      "92350590b3fd4e9981d47133cea4303a",
      "30b412b867ca494e8044139ea0aec888",
      "072bd61edd544180bb42e228c6aad48f",
      "0fa9136ad3ce4cb9a530efb2537aae5a",
      "795dec924c1c473d88bc691e422b5168",
      "87d56e79224d4b08a652f26930c2d252",
      "b89d6793c7b645ff8a937453cf456f2f",
      "73888b89739d40e7a9455e99dd13400b",
      "a8d0bb160b4444d887132e843e50e688",
      "30d142a0ac1d4c588c8f433ea0ab0493",
      "17c76e3176cc44579da4c620931ed0df",
      "dbb6046f2e6042f88471cb14c6a732fa",
      "0a46af65a8a742fea2166e7e19739272",
      "40c072a877084986bcbd0c9357cb3a2d",
      "715f5592de7948d0bad793b545780dc0",
      "0beaf6a289c6404da63b2bd3440f761c",
      "9f5cda7f2721436fa306ddf7cceeb496",
      "c92464cb82cd4781b4cc78d7e8be25bd",
      "f0c88ace2d94483391d0af5913b2f72b",
      "49b26af4a5b24b78a4ac0292e03be860",
      "02f363b337ea4eeeaf7c1229b47f634e",
      "7e439350e3844757be55b65b5250c55e",
      "a7d4e2a1303946569aa8c04ea0d94f1c",
      "bd7e375b9d3647b6b59d686abc3cf2d6",
      "9628a92fbabb43f9870c9e918cd1cbc4",
      "721590f023a6450ca28ad47eb16cf3eb",
      "5ea343b7d4344e1b80d8fd999964cfd9",
      "be7940ae0c0746ea90de4cc921bab9c7",
      "8519b65396124368bbb670d23253518b",
      "6d83e2217b1c4980beeb88c21e04fd36",
      "8edafe37ba7e45a6a68550d0e47da6c9"
     ]
    },
    "id": "a64elKE_QUd5",
    "outputId": "72999cf0-1e40-49a0-c38d-796c0efac2ac"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "🦥 Unsloth Zoo will now patch everything to make training faster!\n",
      "==((====))==  Unsloth 2025.3.17: Fast Gemma2 patching. Transformers: 4.49.0.\n",
      "   \\\\   /|    NVIDIA A100-SXM4-40GB. Num GPUs = 1. Max memory: 39.557 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 8.0. CUDA Toolkit: 12.4. Triton: 3.2.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.29.post3. FA2 = True]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/39.1k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "30e0fd2014c44738a17d595ff9b4393a"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5c5f9f942e2c4f3a8951b828507dcd50"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "model-00001-of-00004.safetensors:   0%|          | 0.00/4.90G [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "84f003ad144647f0ba98d10dff58294e"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "model-00002-of-00004.safetensors:   0%|          | 0.00/4.95G [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4feb65e9321a4fb0b42c4aee4854aab4"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "model-00003-of-00004.safetensors:   0%|          | 0.00/4.96G [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d7831487f6464720a222bde52856f3d2"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "model-00004-of-00004.safetensors:   0%|          | 0.00/3.67G [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "49d9d54a9a4243e0965c0cab3187e4ab"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3423dd06edf4427ab7f260a751a9bcc7"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "11b93fcd96484236b410a18cdde0322a"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/46.4k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "759254a1560944169d0b9c1a891b55a0"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/4.24M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9a6fd1a841a74fee96a950c8e89c297e"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/636 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "30d142a0ac1d4c588c8f433ea0ab0493"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/17.5M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "02f363b337ea4eeeaf7c1229b47f634e"
      }
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r = 16, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n",
    "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n",
    "    lora_alpha = 16,\n",
    "    lora_dropout = 0.1, # Supports any, but = 0 is optimized\n",
    "    bias = \"none\",    # Supports any, but = \"none\" is optimized\n",
    "    # [NEW] \"unsloth\" uses 30% less VRAM, fits 2x larger batch sizes!\n",
    "    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for very long context\n",
    "    random_state = 3407,\n",
    "    use_rslora = True,  # We support rank stabilized LoRA\n",
    "    loftq_config = None, # And LoftQ\n",
    ")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-EDxTJCRQrPP",
    "outputId": "b09eae10-0a27-4e2f-9aa0-d7a99e6e7b04"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Unsloth: Dropout = 0 is supported for fast patching. You are using dropout = 0.1.\n",
      "Unsloth will patch all other layers, except LoRA matrices, causing a performance hit.\n",
      "Unsloth 2025.3.17 patched 42 layers with 0 QKV layers, 0 O layers and 0 MLP layers.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "alpaca_prompt = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
    "\n",
    "### Instruction:\n",
    "{}\n",
    "\n",
    "### Input:\n",
    "{}\n",
    "\n",
    "### Response:\n",
    "{}\"\"\"\n",
    "\n",
    "EOS_TOKEN = tokenizer.eos_token # Must add EOS_TOKEN\n",
    "BOS_TOKEN = tokenizer.bos_token\n",
    "def formatting_prompts_func(examples):\n",
    "    instructions = examples[\"instruction\"]\n",
    "    inputs       = examples[\"input\"]\n",
    "    outputs      = examples[\"output\"]\n",
    "    texts = []\n",
    "    for instruction, input, output in zip(instructions, inputs, outputs):\n",
    "        # Must add EOS_TOKEN, otherwise your generation will go on forever!\n",
    "        text = BOS_TOKEN + alpaca_prompt.format(instruction, input, output) + EOS_TOKEN\n",
    "        texts.append(text)\n",
    "    return { \"text\" : texts, }\n",
    "pass\n",
    "\n",
    "from datasets import load_dataset\n",
    "# train_dataset = load_dataset(\"WildBurger/TestDatum\", split = \"train[:80%]\")\n",
    "train_dataset = load_dataset(\"WildBurger/FinetuneDataset1\", split = \"train\")\n",
    "train_dataset = train_dataset.map(formatting_prompts_func, batched = True,)\n",
    "\n",
    "# eval_dataset = load_dataset(\"WildBurger/TestDatum\", split = \"train[90%:]\")\n",
    "# eval_dataset = eval_dataset.map(formatting_prompts_func, batched = True,)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 145,
     "referenced_widgets": [
      "c5b6c161f4454656be06029159084661",
      "cd8f8bc9e22141f6bc114375f76d6fae",
      "2e5b0a85d1394b4682f1d4e4f3840094",
      "e0f1090badf14723ae9977d109c1d874",
      "53a1d8dbc1da4aef989de49966dd9f85",
      "7167296f15cb48a598f50aeb4b4eb375",
      "bbe90c278a614b618832c5219de2e1a0",
      "5d7ba063866e4722b898fa777d2e1e08",
      "65233e82a28746e0859a2d145806b4eb",
      "fbd4b9339f7f4eadb7ec20719ff02417",
      "5fc2f15ea2884087a3efdafb713866b6",
      "4fc4087c99ea403f876c79fe88e48143",
      "1ec0e1d1bfb04bb2b48b5cce032e9d8e",
      "bf26e4e92cb24d648d609b01435b66bb",
      "5ff536ac5cf0472ca666c7cf466e0211",
      "6a166d1c1b224a6fbeed1f8e8b8c2230",
      "0ffbb56793d2475795bb1d45697a4d9e",
      "b824e25deca844f0b26a8d3201329be1",
      "182ec7733be442b7b13cf9c4295e0c9f",
      "b44e54aee7924aceba1842feb6ffb6bf",
      "e304d1cffce74dbaaca876488a3f0573",
      "4edca43de2a34127819b521bc60b32f3",
      "9e668eabee474293a840b207b53243d5",
      "5c4bf0fa73ef4979afd48ab3a228251c",
      "0879a652f2674d208043b6e045710947",
      "d48f0c4531a64f48b42419c1a0b6165a",
      "c5f253ca8fee49ba91c3c0e199e3cd64",
      "93c9aa916bc2481691b69c600c3e0c94",
      "6f76876194874a64beaea0fc4e256427",
      "dc5027c3020f4789b8552a6fd8cf092b",
      "63377973facc4969883970fe8f23498e",
      "22bd89bd83d34824909e4a5026bac00c",
      "c8bdfc7ad96a4eb0865f18fc828ca2c9",
      "f0919e4ec75d4ed88db84561ccaa3834",
      "803d0e1592dd4a1eb9c366daff094565",
      "f58803a382d94e4eaa629dfe748c8d46",
      "8ded6bdda8c7464ca7424669121e1acd",
      "9596a00ea08a40b6a40d8ccf0bab446f",
      "39ece10f07954503b108cfa629b89c39",
      "db40f2612ef841dcbae74e9a5f90605c",
      "a769e248e07c4c9dab5e9191ef929a8b",
      "032f5e307335415c9838fff96575e1bb",
      "fa383fab96c1438caaf40eef46698b01",
      "9f4c27e837b34d7b9bc51b0214b8b6d9"
     ]
    },
    "id": "DPXcqtf3Te1I",
    "outputId": "8b6dd7b4-e492-4a56-c3ca-f3a3cca0c662"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "README.md:   0%|          | 0.00/31.0 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c5b6c161f4454656be06029159084661"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "finetuning_ds_v2.json:   0%|          | 0.00/17.0M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4fc4087c99ea403f876c79fe88e48143"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Generating train split:   0%|          | 0/1691 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9e668eabee474293a840b207b53243d5"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/1691 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f0919e4ec75d4ed88db84561ccaa3834"
      }
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install rouge_score\n",
    "!pip install --upgrade rouge_score"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HXceT3j9j8qB",
    "outputId": "b23e8db2-b709-42de-bd58-ae0c1d9ce74a"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting rouge_score\n",
      "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
      "  Preparing metadata (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from rouge_score) (1.4.0)\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (from rouge_score) (3.9.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from rouge_score) (1.26.4)\n",
      "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from rouge_score) (1.17.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (8.1.8)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (4.67.1)\n",
      "Building wheels for collected packages: rouge_score\n",
      "  Building wheel for rouge_score (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24935 sha256=d1c88b6ecb2454883846764f92aed948a3448770ea946257acc34b9af946ccff\n",
      "  Stored in directory: /root/.cache/pip/wheels/1e/19/43/8a442dc83660ca25e163e1bd1f89919284ab0d0c1475475148\n",
      "Successfully built rouge_score\n",
      "Installing collected packages: rouge_score\n",
      "Successfully installed rouge_score-0.1.2\n",
      "Requirement already satisfied: rouge_score in /usr/local/lib/python3.11/dist-packages (0.1.2)\n",
      "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from rouge_score) (1.4.0)\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (from rouge_score) (3.9.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from rouge_score) (1.26.4)\n",
      "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from rouge_score) (1.17.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (8.1.8)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (4.67.1)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# import nltk\n",
    "# nltk.download(\"punkt\", quiet=True)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eYubq1_Rir99",
    "outputId": "66880e8f-f5b9-40ef-b8be-d6b3be7503a0"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from trl import SFTTrainer\n",
    "from transformers import EvalPrediction, TrainingArguments\n",
    "from unsloth import is_bfloat16_supported\n",
    "# import evaluate\n",
    "# import numpy as np\n",
    "\n",
    "# def preprocess_logits_for_metrics(logits, labels):\n",
    "#     #This is a workaround to avoid storing too many tensors that are not needed.\n",
    "#     pred_ids = torch.argmax(logits, dim=-1)\n",
    "#     return pred_ids, labels\n",
    "\n",
    "# def compute_metrics(p: EvalPrediction, compute_result: bool = True):\n",
    "#     print(\"in compute\")\n",
    "#     return {\"metric\": 1}\n",
    "\n",
    "# Load the ROUGE metric\n",
    "# rouge_metric = evaluate.load(\"rouge\")\n",
    "# def compute_metrics(p: EvalPrediction, compute_result: bool = True):\n",
    "#     # Extract predictions and references from EvalPrediction\n",
    "#     predictions, references = p.predictions, p.label_ids\n",
    "#     # Ensure predictions and references are lists of lists\n",
    "#     if isinstance(predictions, torch.Tensor):\n",
    "#         predictions = predictions.cpu().tolist()  # Convert PyTorch tensor to list\n",
    "#     elif isinstance(predictions, np.ndarray):\n",
    "#         predictions = predictions.tolist()  # Convert NumPy array to list\n",
    "\n",
    "#     if isinstance(references, torch.Tensor):\n",
    "#         references = references.cpu().tolist()\n",
    "#     elif isinstance(references, np.ndarray):\n",
    "#         references = references.tolist()\n",
    "\n",
    "#     # Ensure predictions and references are lists of lists\n",
    "#     if isinstance(predictions, list) and isinstance(predictions[0], list) is False:\n",
    "#         predictions = [predictions]  # Convert to list of lists\n",
    "\n",
    "#     if isinstance(references, list) and isinstance(references[0], list) is False:\n",
    "#         references = [references]  # Convert to list of lists\n",
    "\n",
    "#     references = [[token if token != -100 else tokenizer.pad_token_id for token in seq] for seq in references]\n",
    "\n",
    "#     # Decode tokenized outputs into text\n",
    "#     decoded_predictions = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "#     decoded_references = tokenizer.batch_decode(references, skip_special_tokens=True)\n",
    "\n",
    "#     # Format for ROUGE (each sentence on a new line)\n",
    "#     decoded_predictions = [\"\\n\".join(nltk.sent_tokenize(pred.strip())) for pred in decoded_predictions]\n",
    "#     decoded_references = [\"\\n\".join(nltk.sent_tokenize(ref.strip())) for ref in decoded_references]\n",
    "\n",
    "#     # Compute ROUGE scores\n",
    "#     result = rouge_metric.compute(predictions=decoded_predictions, references=decoded_references, use_stemmer=True)\n",
    "\n",
    "#     return result\n",
    "\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model = model,\n",
    "    tokenizer = tokenizer,\n",
    "    train_dataset = train_dataset,\n",
    "    # eval_dataset = eval_dataset,\n",
    "    dataset_text_field = \"text\",\n",
    "    max_seq_length = max_seq_length,\n",
    "    dataset_num_proc = 2,\n",
    "    packing = False, # Can make training 5x faster for short sequences.\n",
    "    # compute_metrics=compute_metrics,\n",
    "    # preprocess_logits_for_metrics=preprocess_logits_for_metrics,\n",
    "    args = TrainingArguments(\n",
    "        num_train_epochs=3,\n",
    "        per_device_train_batch_size = 4,\n",
    "        gradient_accumulation_steps = 4,\n",
    "        # warmup_steps = 5,\n",
    "        warmup_ratio = 0.1,\n",
    "        max_steps = 300,\n",
    "        # learning_rate = 1e-4,\n",
    "        learning_rate = 2e-4,\n",
    "        # fp16_full_eval = True,\n",
    "        # per_device_eval_batch_size = 2,\n",
    "        # eval_accumulation_steps = 4,\n",
    "        # eval_strategy = \"epoch\",\n",
    "        # eval_steps = 50,\n",
    "        fp16 = not is_bfloat16_supported(),\n",
    "        bf16 = is_bfloat16_supported(),\n",
    "        logging_steps = 10,\n",
    "        optim = \"adamw_8bit\",\n",
    "        weight_decay = 0.1,\n",
    "        lr_scheduler_type = \"linear\",\n",
    "        seed = 3407,\n",
    "        output_dir = \"outputs\",\n",
    "        report_to = \"none\", # Use this for WandB etc\n",
    "    ),\n",
    ")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 66,
     "referenced_widgets": [
      "83e0fb0db26b4ae3aeb98854408c882a",
      "808f90a750eb4af68ceebb6ec049a607",
      "d7a6f98cec31474e9854e950bf0b0139",
      "ed3754e2af784c71b43c537ba3b30359",
      "28454556c91e45ed900603223c0bca62",
      "e68b8b5c87e94a07aa657ab94a923732",
      "f31226542b8f4b2f902600fd88f0a402",
      "6908f8645e3e49a58a6f82651fdac9e2",
      "0654cf6763eb46aa8692469bce7210e9",
      "3179c16d7598432da9e327d0d3bf60bf",
      "3720e4dc1afb420786055bf733eeec4f"
     ]
    },
    "id": "2TClgnecYXoI",
    "outputId": "6f0be2c5-311f-4df1-b6f5-783135455eaa"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Unsloth: We found double BOS tokens - we shall remove one automatically.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Unsloth: Tokenizing [\"text\"] (num_proc=2):   0%|          | 0/1691 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "83e0fb0db26b4ae3aeb98854408c882a"
      }
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# @title Show current memory stats\n",
    "gpu_stats = torch.cuda.get_device_properties(0)\n",
    "start_gpu_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
    "max_memory = round(gpu_stats.total_memory / 1024 / 1024 / 1024, 3)\n",
    "print(f\"GPU = {gpu_stats.name}. Max memory = {max_memory} GB.\")\n",
    "print(f\"{start_gpu_memory} GB of memory reserved.\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iHCX1BUtisqB",
    "outputId": "bf5f4341-0105-469a-e4d6-2fba5677152d"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "GPU = NVIDIA A100-SXM4-40GB. Max memory = 39.557 GB.\n",
      "17.441 GB of memory reserved.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "trainer_stats = trainer.train()\n",
    "# from unsloth import unsloth_train\n",
    "# trainer_stats = unsloth_train(trainer)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "egxD7b73fI5m",
    "outputId": "61dc7648-afa0-42a4-e437-0de60c71a729"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
      "   \\\\   /|    Num examples = 1,691 | Num Epochs = 3 | Total steps = 300\n",
      "O^O/ \\_/ \\    Batch size per device = 4 | Gradient accumulation steps = 4\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (4 x 4 x 1) = 16\n",
      " \"-____-\"     Trainable parameters = 54,018,048/9,295,724,032 (0.58% trained)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Unsloth: Will smartly offload gradients to save VRAM!\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [300/300 1:31:05, Epoch 2/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.637400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.886500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.180200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.119100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.046000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.054800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.063700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.040400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.036000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.031700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.024300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.024800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.022800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.024200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.024200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.025300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.023900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.025300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.032600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.023800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.023500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.023900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.020800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.021600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.021900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.021500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.018500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.017800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.026400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.018000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# @title Show final memory and time stats\n",
    "used_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
    "used_memory_for_lora = round(used_memory - start_gpu_memory, 3)\n",
    "used_percentage = round(used_memory / max_memory * 100, 3)\n",
    "lora_percentage = round(used_memory_for_lora / max_memory * 100, 3)\n",
    "print(f\"{trainer_stats.metrics['train_runtime']} seconds used for training.\")\n",
    "print(f\"{round(trainer_stats.metrics['train_runtime']/60, 2)} minutes used for training.\")\n",
    "print(f\"Peak reserved memory = {used_memory} GB.\")\n",
    "print(f\"Peak reserved memory for training = {used_memory_for_lora} GB.\")\n",
    "print(f\"Peak reserved memory % of max memory = {used_percentage} %.\")\n",
    "print(f\"Peak reserved memory for training % of max memory = {lora_percentage} %.\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ts0z7m_ccptf",
    "outputId": "b1b78c5e-ca45-41ab-a8c7-2cd2c67e702e"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "5509.7906 seconds used for training.\n",
      "91.83 minutes used for training.\n",
      "Peak reserved memory = 30.193 GB.\n",
      "Peak reserved memory for training = 12.752 GB.\n",
      "Peak reserved memory % of max memory = 76.328 %.\n",
      "Peak reserved memory for training % of max memory = 32.237 %.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "SKILLS = \"\"\"Instructions: Refine and rewrite the given \"skill_section\" section of resume in JSON format.\n",
    "Follow these criteria:\n",
    "1. Only return \"skill_section\" section as a response, don't include any other sections.\n",
    "2. Remove irrelevant skills to the job description.\n",
    "3. Format your response as the following template.\n",
    "    \"skill_section\": [\n",
    "        {{\n",
    "          \"name\": \"Programming Languages\",\n",
    "          \"skills\": [\"Python\", \"JavaScript\"]\n",
    "        }},\n",
    "        {{\n",
    "          \"name\": \"Cloud Platform\",\n",
    "          \"skills\": [ \"Azure\", \"AWS\"]\n",
    "        }}\n",
    "      ]\n",
    "\n",
    "4. Ensure most relevant skills in resume are retained, and enhance alignment with the job description.\n",
    "5. Add other relevant skills showed in other sections of resume if they are aligned with job requirements.\n",
    "6. Avoid adding new skills that are not showed in resume.\n",
    "\"\"\"\n",
    "\n",
    "EXPERIENCE = \"\"\"Instructions: Refine and rewrite the given \"work_experience\" section of resume in JSON format.\n",
    "Follow these criteria:\n",
    "1. Return refined \"work_experience\" section as a response, don't include other sections.\n",
    "2. Format each experience as the following output template.\n",
    "    \"work_experience\": [\n",
    "        {{\n",
    "          \"role\": \"Software Engineer\",\n",
    "          \"company\": \"Winjit Technologies\",\n",
    "          \"location\": \"Pune, India\"\n",
    "          \"from_date\": \"Jan 2020\",\n",
    "          \"to_date\": \"Jun 2022\",\n",
    "          \"description\": [\n",
    "            \"Engineered 10+ RESTful APIs Architecture and Distributed services.\",\n",
    "            \"Designed 30+ low-latency responsive UI/UX application features with high-quality web architecture.\",\n",
    "            \"Managed and optimized large-scale Databases. (Systems Design).\"\n",
    "          ]\n",
    "        }}\n",
    "    ]\n",
    "\n",
    "3. Retain at most top 3 relevant experience without altering factual details.\n",
    "4. Avoid adding details not given in the original resume data.\n",
    "5. In each experience, description should include information about responsibilities and impacts as string text.\n",
    "6. Ensure clarity, coherence, and alignment with the job description.\n",
    "\"\"\""
   ],
   "metadata": {
    "id": "rQrgo2kbnSAI"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# alpaca_prompt = Copied from above\n",
    "from transformers import TextStreamer\n",
    "FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n",
    "inputs = tokenizer(\n",
    "[\n",
    "    alpaca_prompt.format(\n",
    "      \"\"\"Instructions: Optimize the given \"work_experience\" section in JSON format.\n",
    "      - Format each project as the following output_example.\n",
    "      - In each experience, description should include information about responsibilities and impacts as string text.\n",
    "      - Only return \"work_experience\" section as a response, don't include any other sections.\n",
    "      - Improve clarity, structure, and alignment with the job description.\n",
    "      - Retain all important and relevant experience without altering factual details.\n",
    "      - Avoid adding details not given in the resume data.\n",
    "\n",
    "    <output_example>\n",
    "    \"work_experience\": [\n",
    "        {{\n",
    "          \"role\": \"Software Engineer\",\n",
    "          \"company\": \"Winjit Technologies\",\n",
    "          \"location\": \"Pune, India\"\n",
    "          \"from_date\": \"Jan 2020\",\n",
    "          \"to_date\": \"Jun 2022\",\n",
    "          \"description\": [\n",
    "            \"Engineered 10+ RESTful APIs Architecture and Distributed services; Designed 30+ low-latency responsive UI/UX application features with high-quality web architecture; Managed and optimized large-scale Databases. (Systems Design)\",\n",
    "            \"Initiated and Designed a standardized solution for dynamic forms generation, with customizable CSS capabilities feature, which reduces development time by 8x; Led and collaborated with a 12 member cross-functional team. (Idea Generation)\"\n",
    "          ]\n",
    "        }}\n",
    "      ]\n",
    "    </output_example>\n",
    "\n",
    "    \"\"\", # instruction\n",
    "    \"\"\"\n",
    "    {\n",
    "      \"resume\":{\n",
    "        \"Summary\": \"Results-oriented and organized bilingual accounting and finance professional with 10 years extensive and diverse accounting, auditing, and finance experience. Experience in all aspects of financial reporting, accruals, and managerial cost accounting, reporting systems, operational analysis, and human resources functions through the acceptance of expanded responsibilities after exceptional performance. Knowledge of accounting theory, principles, practices, and regulations including FASB, GAAP, and SOX compliance. CPA Candidate. Analytical Problem Solving and Decision Making, Performance and Productivity improvement, Team building, Leadership, Payroll Accounting, Tax Accounting, Financial Analysis, Strategic planning, Project and Inventory Management, Staff Management.\",\n",
    "        \"experience\": [\n",
    "        {\n",
    "          \"JobTitle\": \"Accountant\",\n",
    "          \"StartDate\": \"01/2014\",\n",
    "          \"EndDate\": \"Current\",\n",
    "          \"CompanyName\": \"Company Name\",\n",
    "          \"Location\": \"City, State\",\n",
    "          \"Responsibilities\": [\n",
    "            \"Compile and analyze financial information to prepare financial statements for the formulation of corporate tax returns for private and corporate clients.\",\n",
    "            \"Maintain general ledgers including posting, adjusting, and closing journal entries.\",\n",
    "            \"Analyze financial transactions to ensure they are recorded to the appropriate general ledger accounts and make any necessary corrections to journal entries as needed to properly reflect the financial position of the company.\"\n",
    "          ]\n",
    "        },\n",
    "        {\n",
    "          \"JobTitle\": \"Accountant\",\n",
    "          \"StartDate\": \"01/1999\",\n",
    "          \"EndDate\": \"Current\",\n",
    "          \"CompanyName\": \"Company Name\",\n",
    "          \"Location\": \"City, State\",\n",
    "          \"Responsibilities\": [\n",
    "            \"Oversee all financial accounting functions for a $15 million construction company.\",\n",
    "            \"Assist with the preparation and coordination of the month/year-end closing by ensuring financial statements are accurate and in compliance with GAAP.\",\n",
    "            \"Manage full cycle of AP disbursements including bank account reconciliations, journal entries, monthly accruals, and general ledger.\",\n",
    "            \"Prepare tax returns, Sales and Use tax, quarterly and year-end corporate payroll tax returns in compliance with IRS requirements.\",\n",
    "            \"Oversee employee benefits including health, dental, vision insurance, 401k, and commercial insurance.\",\n",
    "            \"Participated in various projects to improve process efficiency, overall timeliness, and accuracy of financial information.\",\n",
    "            \"Recognized potential problems and implemented innovative solutions.\"\n",
    "          ]\n",
    "        },\n",
    "        {\n",
    "          \"JobTitle\": \"Trading Assistant\",\n",
    "          \"StartDate\": \"01/1996\",\n",
    "          \"EndDate\": \"01/1999\",\n",
    "          \"CompanyName\": \"Company Name\",\n",
    "          \"Location\": \"City, State\",\n",
    "          \"Responsibilities\": [\n",
    "            \"Prepared reports, analyzed and audited internal billing while coordinating deliveries with accuracy and great attention to detail.\",\n",
    "            \"Maintained high level of customer satisfaction through business communications with international subsidiaries in Mexico and Japan in the preparation of documentation of import and export shipments.\",\n",
    "            \"Improved customer service satisfaction annually through streamlined inventory system operations by performing thorough inventory tracking.\",\n",
    "            \"Negotiated contracts including delivery point terms, price, and export/import duties.\"\n",
    "          ]\n",
    "        }\n",
    "      ],\n",
    "      \"education\": [\n",
    "        {\n",
    "          \"Degree\": \"Master of Business Administration\",\n",
    "          \"Field\": \"Accounting\",\n",
    "          \"GraduationDate\": \"2013\",\n",
    "          \"Institution\": \"LEWIS UNIVERSITY\",\n",
    "          \"Location\": \"City, State\",\n",
    "          \"Honors\": \"Cum Laude\"\n",
    "        },\n",
    "        {\n",
    "          \"Degree\": \"Bachelor of Arts\",\n",
    "          \"Field\": \"Accounting\",\n",
    "          \"GraduationDate\": \"2013\",\n",
    "          \"Institution\": \"ROBERT MORRIS UNIVERSITY\",\n",
    "          \"Location\": \"City, State\",\n",
    "          \"Honors\": \"Magna Cum Laude\"\n",
    "        }\n",
    "      ],\n",
    "      \"additional_information\": {\n",
    "        \"Certifications\": [\n",
    "          \"H&R Block Tax Courses\",\n",
    "          \"Wiley CPA Excel Review\"\n",
    "        ],\n",
    "        \"Affiliations\": [\n",
    "          \"ACFE (Association of Certified Forensic Examiners)\"\n",
    "        ]\n",
    "      }\n",
    "    }\n",
    "  }\"\"\", # input\n",
    "  \"\", # output - leave this blank for generation!\n",
    ")], return_tensors = \"pt\").to(\"cuda\")\n",
    "\n",
    "text_streamer = TextStreamer(tokenizer)\n",
    "_ = model.generate(**inputs, streamer = text_streamer, max_new_tokens = 2048, use_cache = True, temperature = 0.5, min_p = 0.5)"
   ],
   "metadata": {
    "id": "HSw5U2TifZ1q",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "9a8a0672-9a2f-4851-d22e-f10511827230"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<bos>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Instructions: Optimize the given \"work_experience\" section in JSON format.\n",
      "      - Format each project as the following output_example.\n",
      "      - In each experience, description should include information about responsibilities and impacts as string text.\n",
      "      - Only return \"work_experience\" section as a response, don't include any other sections.\n",
      "      - Improve clarity, structure, and alignment with the job description.\n",
      "      - Retain all important and relevant experience without altering factual details.\n",
      "      - Avoid adding details not given in the resume data.\n",
      "\n",
      "    <output_example>\n",
      "    \"work_experience\": [\n",
      "        {{\n",
      "          \"role\": \"Software Engineer\",\n",
      "          \"company\": \"Winjit Technologies\",\n",
      "          \"location\": \"Pune, India\"\n",
      "          \"from_date\": \"Jan 2020\",\n",
      "          \"to_date\": \"Jun 2022\",\n",
      "          \"description\": [\n",
      "            \"Engineered 10+ RESTful APIs Architecture and Distributed services; Designed 30+ low-latency responsive UI/UX application features with high-quality web architecture; Managed and optimized large-scale Databases. (Systems Design)\",\n",
      "            \"Initiated and Designed a standardized solution for dynamic forms generation, with customizable CSS capabilities feature, which reduces development time by 8x; Led and collaborated with a 12 member cross-functional team. (Idea Generation)\"\n",
      "          ]\n",
      "        }}\n",
      "      ]\n",
      "    </output_example>\n",
      "\n",
      "    \n",
      "\n",
      "### Input:\n",
      "\n",
      "    {\n",
      "      \"resume\":{\n",
      "        \"Summary\": \"Results-oriented and organized bilingual accounting and finance professional with 10 years extensive and diverse accounting, auditing, and finance experience. Experience in all aspects of financial reporting, accruals, and managerial cost accounting, reporting systems, operational analysis, and human resources functions through the acceptance of expanded responsibilities after exceptional performance. Knowledge of accounting theory, principles, practices, and regulations including FASB, GAAP, and SOX compliance. CPA Candidate. Analytical Problem Solving and Decision Making, Performance and Productivity improvement, Team building, Leadership, Payroll Accounting, Tax Accounting, Financial Analysis, Strategic planning, Project and Inventory Management, Staff Management.\",\n",
      "        \"experience\": [\n",
      "        {\n",
      "          \"JobTitle\": \"Accountant\",\n",
      "          \"StartDate\": \"01/2014\",\n",
      "          \"EndDate\": \"Current\",\n",
      "          \"CompanyName\": \"Company Name\",\n",
      "          \"Location\": \"City, State\",\n",
      "          \"Responsibilities\": [\n",
      "            \"Compile and analyze financial information to prepare financial statements for the formulation of corporate tax returns for private and corporate clients.\",\n",
      "            \"Maintain general ledgers including posting, adjusting, and closing journal entries.\",\n",
      "            \"Analyze financial transactions to ensure they are recorded to the appropriate general ledger accounts and make any necessary corrections to journal entries as needed to properly reflect the financial position of the company.\"\n",
      "          ]\n",
      "        },\n",
      "        {\n",
      "          \"JobTitle\": \"Accountant\",\n",
      "          \"StartDate\": \"01/1999\",\n",
      "          \"EndDate\": \"Current\",\n",
      "          \"CompanyName\": \"Company Name\",\n",
      "          \"Location\": \"City, State\",\n",
      "          \"Responsibilities\": [\n",
      "            \"Oversee all financial accounting functions for a $15 million construction company.\",\n",
      "            \"Assist with the preparation and coordination of the month/year-end closing by ensuring financial statements are accurate and in compliance with GAAP.\",\n",
      "            \"Manage full cycle of AP disbursements including bank account reconciliations, journal entries, monthly accruals, and general ledger.\",\n",
      "            \"Prepare tax returns, Sales and Use tax, quarterly and year-end corporate payroll tax returns in compliance with IRS requirements.\",\n",
      "            \"Oversee employee benefits including health, dental, vision insurance, 401k, and commercial insurance.\",\n",
      "            \"Participated in various projects to improve process efficiency, overall timeliness, and accuracy of financial information.\",\n",
      "            \"Recognized potential problems and implemented innovative solutions.\"\n",
      "          ]\n",
      "        },\n",
      "        {\n",
      "          \"JobTitle\": \"Trading Assistant\",\n",
      "          \"StartDate\": \"01/1996\",\n",
      "          \"EndDate\": \"01/1999\",\n",
      "          \"CompanyName\": \"Company Name\",\n",
      "          \"Location\": \"City, State\",\n",
      "          \"Responsibilities\": [\n",
      "            \"Prepared reports, analyzed and audited internal billing while coordinating deliveries with accuracy and great attention to detail.\",\n",
      "            \"Maintained high level of customer satisfaction through business communications with international subsidiaries in Mexico and Japan in the preparation of documentation of import and export shipments.\",\n",
      "            \"Improved customer service satisfaction annually through streamlined inventory system operations by performing thorough inventory tracking.\",\n",
      "            \"Negotiated contracts including delivery point terms, price, and export/import duties.\"\n",
      "          ]\n",
      "        }\n",
      "      ],\n",
      "      \"education\": [\n",
      "        {\n",
      "          \"Degree\": \"Master of Business Administration\",\n",
      "          \"Field\": \"Accounting\",\n",
      "          \"GraduationDate\": \"2013\",\n",
      "          \"Institution\": \"LEWIS UNIVERSITY\",\n",
      "          \"Location\": \"City, State\",\n",
      "          \"Honors\": \"Cum Laude\"\n",
      "        },\n",
      "        {\n",
      "          \"Degree\": \"Bachelor of Arts\",\n",
      "          \"Field\": \"Accounting\",\n",
      "          \"GraduationDate\": \"2013\",\n",
      "          \"Institution\": \"ROBERT MORRIS UNIVERSITY\",\n",
      "          \"Location\": \"City, State\",\n",
      "          \"Honors\": \"Magna Cum Laude\"\n",
      "        }\n",
      "      ],\n",
      "      \"additional_information\": {\n",
      "        \"Certifications\": [\n",
      "          \"H&R Block Tax Courses\",\n",
      "          \"Wiley CPA Excel Review\"\n",
      "        ],\n",
      "        \"Affiliations\": [\n",
      "          \"ACFE (Association of Certified Forensic Examiners)\"\n",
      "        ]\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "\n",
      "### Response:\n",
      "{\"work_experience\": [{\"role\": \"Accountant\", \"company\": \"Company Name\", \"location\": \"City, State\", \"from_date\": \"01/2014\", \"to_date\": \"Current\", \"description\": [\"Compiled and analyzed financial information to prepare financial statements for the formulation of corporate tax returns for private and corporate clients.\", \"Maintained general ledgers including posting, adjusting, and closing journal entries.\", \"Analyzed financial transactions to ensure they were recorded to the appropriate general ledger accounts and made any necessary corrections to journal entries as needed to properly reflect the financial position of the company.\"]}, {\"role\": \"Accountant\", \"company\": \"Company Name\", \"location\": \"City, State\", \"from_date\": \"01/1999\", \"to_date\": \"Current\", \"description\": [\"Oversaw all financial accounting functions for a $15 million construction company.\", \"Assisted with the preparation and coordination of the month/year-end closing by ensuring financial statements were accurate and in compliance with GAAP.\", \"Managed full cycle of AP disbursements including bank account reconciliations, journal entries, monthly accruals, and general ledger.\", \"Prepared tax returns, Sales and Use tax, quarterly and year-end corporate payroll tax returns in compliance with IRS requirements.\", \"Oversaw employee benefits including health, dental, vision insurance, 401k, and commercial insurance.\", \"Participated in various projects to improve process efficiency, overall timeliness, and accuracy of financial information.\", \"Recognized potential problems and implemented innovative solutions.\"]}, {\"role\": \"Trading Assistant\", \"company\": \"Company Name\", \"location\": \"City, State\", \"from_date\": \"01/1996\", \"to_date\": \"01/1999\", \"description\": [\"Prepared reports, analyzed and audited internal billing while coordinating deliveries with accuracy and great attention to detail.\", \"Maintained high level of customer satisfaction through business communications with international subsidiaries in Mexico and Japan in the preparation of documentation of import and export shipments.\", \"Improved customer service satisfaction annually through streamlined inventory system operations by performing thorough inventory tracking.\", \"Negotiated contracts including delivery point terms, price, and export/import duties.\"]}]}<eos>\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# model.save_pretrained(\"group1_finetuned_gemma2\")  # Local saving\n",
    "# tokenizer.save_pretrained(\"group1_finetuned_gemma2\")\n",
    "model.save_pretrained_gguf(\"group1_finetuned_gemma2\", tokenizer, quantization_method = \"q8_0\")\n",
    "model.push_to_hub_gguf(\"WildBurger/group1_finetuned_gemma2_v3\", tokenizer, quantization_method = \"q8_0\", token = \"\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "701ded583d78417baf61633d7dc0e71c",
      "45497f50783347349717f5022485499d",
      "d4fed4b171514f51a114dacc20b23edc",
      "6b06d13ebab54e6fb6a6a42275a6d81c",
      "1a55efc6afc2445fb7f92d10ec7f67af",
      "0bf4329a71114d8daf695908cd66680d",
      "a8c00a35351749faaddb32aadf675c2b",
      "59b46f14b2194d9dbd6cf812024a105b",
      "6b12d237b06d4f86b9e2cc95e879eb6a",
      "bac1439d6b544edc935e53e463988abb",
      "682606dc902743a0b99072dccd14c7c3",
      "b414dfb0457d477988033fe97e4d1fc6",
      "421251eccdee4c559cdcb796a69d3ac9",
      "f0866a0fcfbb457c8025a76144769819",
      "d6724e577534472eb78ad6a3bb81806b",
      "44067b13ff8942a1b3fcd2447d300554",
      "f1f08294b0c341ca87856a848448ca5f",
      "630d08330f6d42ba81dfa1dc70935289",
      "dcedd2b6a6e5474fa2e3fb9d8a13ee20",
      "eae5cfa670fb40448bace35ec4b02bd5",
      "c43c2c0150c6413086c9d9237b7b9891",
      "5da4a7f77875490386844d8da87cc9fe"
     ]
    },
    "id": "EaFTOhVIqiTY",
    "outputId": "a8704918-f897-4bf3-8a8f-7c451c341698"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Unsloth: Kaggle/Colab has limited disk space. We need to delete the downloaded\n",
      "model which will save 4-16GB of disk space, allowing you to save on Kaggle/Colab.\n",
      "Unsloth: Will remove a cached repo with size 18.5G\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Unsloth: Merging 4bit and LoRA weights to 16bit...\n",
      "Unsloth: Will use up to 55.4 out of 83.48 RAM for saving.\n",
      "Unsloth: Saving model... This might take 5 minutes ...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 86%|████████▌ | 36/42 [00:00<00:00, 75.58it/s]\n",
      "We will save to Disk and not RAM now.\n",
      "100%|██████████| 42/42 [00:01<00:00, 34.78it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Unsloth: Saving tokenizer... Done.\n",
      "Done.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Unsloth: Converting gemma2 model. Can use fast conversion = False.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "==((====))==  Unsloth: Conversion from QLoRA to GGUF information\n",
      "   \\\\   /|    [0] Installing llama.cpp might take 3 minutes.\n",
      "O^O/ \\_/ \\    [1] Converting HF to GGUF 16bits might take 3 minutes.\n",
      "\\        /    [2] Converting GGUF 16bits to ['q8_0'] might take 10 minutes each.\n",
      " \"-____-\"     In total, you will have to wait at least 16 minutes.\n",
      "\n",
      "Unsloth: Installing llama.cpp. This might take 3 minutes...\n",
      "Unsloth: CMAKE detected. Finalizing some steps for installation.\n",
      "Unsloth: [1] Converting model at WildBurger/group1_finetuned_gemma2_v3 into q8_0 GGUF format.\n",
      "The output location will be /content/WildBurger/group1_finetuned_gemma2_v3/unsloth.Q8_0.gguf\n",
      "This might take 3 minutes...\n",
      "INFO:hf-to-gguf:Loading model: group1_finetuned_gemma2_v3\n",
      "INFO:gguf.gguf_writer:gguf: This GGUF file is for Little Endian only\n",
      "INFO:hf-to-gguf:Exporting model...\n",
      "INFO:hf-to-gguf:gguf: loading model weight map from 'model.safetensors.index.json'\n",
      "INFO:hf-to-gguf:gguf: loading model part 'model-00001-of-00004.safetensors'\n",
      "INFO:hf-to-gguf:token_embd.weight,                 torch.bfloat16 --> Q8_0, shape = {3584, 256000}\n",
      "INFO:hf-to-gguf:blk.0.attn_norm.weight,            torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.0.ffn_down.weight,             torch.bfloat16 --> Q8_0, shape = {14336, 3584}\n",
      "INFO:hf-to-gguf:blk.0.ffn_gate.weight,             torch.bfloat16 --> Q8_0, shape = {3584, 14336}\n",
      "INFO:hf-to-gguf:blk.0.ffn_up.weight,               torch.bfloat16 --> Q8_0, shape = {3584, 14336}\n",
      "INFO:hf-to-gguf:blk.0.post_attention_norm.weight,  torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.0.post_ffw_norm.weight,        torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.0.ffn_norm.weight,             torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.0.attn_k.weight,               torch.bfloat16 --> Q8_0, shape = {3584, 2048}\n",
      "INFO:hf-to-gguf:blk.0.attn_output.weight,          torch.bfloat16 --> Q8_0, shape = {4096, 3584}\n",
      "INFO:hf-to-gguf:blk.0.attn_q.weight,               torch.bfloat16 --> Q8_0, shape = {3584, 4096}\n",
      "INFO:hf-to-gguf:blk.0.attn_v.weight,               torch.bfloat16 --> Q8_0, shape = {3584, 2048}\n",
      "INFO:hf-to-gguf:blk.1.attn_norm.weight,            torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.1.ffn_down.weight,             torch.bfloat16 --> Q8_0, shape = {14336, 3584}\n",
      "INFO:hf-to-gguf:blk.1.ffn_gate.weight,             torch.bfloat16 --> Q8_0, shape = {3584, 14336}\n",
      "INFO:hf-to-gguf:blk.1.ffn_up.weight,               torch.bfloat16 --> Q8_0, shape = {3584, 14336}\n",
      "INFO:hf-to-gguf:blk.1.post_attention_norm.weight,  torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.1.post_ffw_norm.weight,        torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.1.ffn_norm.weight,             torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.1.attn_k.weight,               torch.bfloat16 --> Q8_0, shape = {3584, 2048}\n",
      "INFO:hf-to-gguf:blk.1.attn_output.weight,          torch.bfloat16 --> Q8_0, shape = {4096, 3584}\n",
      "INFO:hf-to-gguf:blk.1.attn_q.weight,               torch.bfloat16 --> Q8_0, shape = {3584, 4096}\n",
      "INFO:hf-to-gguf:blk.1.attn_v.weight,               torch.bfloat16 --> Q8_0, shape = {3584, 2048}\n",
      "INFO:hf-to-gguf:blk.2.attn_norm.weight,            torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.2.ffn_down.weight,             torch.bfloat16 --> Q8_0, shape = {14336, 3584}\n",
      "INFO:hf-to-gguf:blk.2.ffn_gate.weight,             torch.bfloat16 --> Q8_0, shape = {3584, 14336}\n",
      "INFO:hf-to-gguf:blk.2.ffn_up.weight,               torch.bfloat16 --> Q8_0, shape = {3584, 14336}\n",
      "INFO:hf-to-gguf:blk.2.post_attention_norm.weight,  torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.2.post_ffw_norm.weight,        torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.2.ffn_norm.weight,             torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.2.attn_k.weight,               torch.bfloat16 --> Q8_0, shape = {3584, 2048}\n",
      "INFO:hf-to-gguf:blk.2.attn_output.weight,          torch.bfloat16 --> Q8_0, shape = {4096, 3584}\n",
      "INFO:hf-to-gguf:blk.2.attn_q.weight,               torch.bfloat16 --> Q8_0, shape = {3584, 4096}\n",
      "INFO:hf-to-gguf:blk.2.attn_v.weight,               torch.bfloat16 --> Q8_0, shape = {3584, 2048}\n",
      "INFO:hf-to-gguf:blk.3.attn_norm.weight,            torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.3.ffn_down.weight,             torch.bfloat16 --> Q8_0, shape = {14336, 3584}\n",
      "INFO:hf-to-gguf:blk.3.ffn_gate.weight,             torch.bfloat16 --> Q8_0, shape = {3584, 14336}\n",
      "INFO:hf-to-gguf:blk.3.ffn_up.weight,               torch.bfloat16 --> Q8_0, shape = {3584, 14336}\n",
      "INFO:hf-to-gguf:blk.3.post_attention_norm.weight,  torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.3.post_ffw_norm.weight,        torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.3.ffn_norm.weight,             torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.3.attn_k.weight,               torch.bfloat16 --> Q8_0, shape = {3584, 2048}\n",
      "INFO:hf-to-gguf:blk.3.attn_output.weight,          torch.bfloat16 --> Q8_0, shape = {4096, 3584}\n",
      "INFO:hf-to-gguf:blk.3.attn_q.weight,               torch.bfloat16 --> Q8_0, shape = {3584, 4096}\n",
      "INFO:hf-to-gguf:blk.3.attn_v.weight,               torch.bfloat16 --> Q8_0, shape = {3584, 2048}\n",
      "INFO:hf-to-gguf:blk.4.attn_norm.weight,            torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.4.ffn_down.weight,             torch.bfloat16 --> Q8_0, shape = {14336, 3584}\n",
      "INFO:hf-to-gguf:blk.4.ffn_gate.weight,             torch.bfloat16 --> Q8_0, shape = {3584, 14336}\n",
      "INFO:hf-to-gguf:blk.4.ffn_up.weight,               torch.bfloat16 --> Q8_0, shape = {3584, 14336}\n",
      "INFO:hf-to-gguf:blk.4.post_attention_norm.weight,  torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.4.post_ffw_norm.weight,        torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.4.ffn_norm.weight,             torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.4.attn_k.weight,               torch.bfloat16 --> Q8_0, shape = {3584, 2048}\n",
      "INFO:hf-to-gguf:blk.4.attn_output.weight,          torch.bfloat16 --> Q8_0, shape = {4096, 3584}\n",
      "INFO:hf-to-gguf:blk.4.attn_q.weight,               torch.bfloat16 --> Q8_0, shape = {3584, 4096}\n",
      "INFO:hf-to-gguf:blk.4.attn_v.weight,               torch.bfloat16 --> Q8_0, shape = {3584, 2048}\n",
      "INFO:hf-to-gguf:blk.5.attn_norm.weight,            torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.5.ffn_down.weight,             torch.bfloat16 --> Q8_0, shape = {14336, 3584}\n",
      "INFO:hf-to-gguf:blk.5.ffn_gate.weight,             torch.bfloat16 --> Q8_0, shape = {3584, 14336}\n",
      "INFO:hf-to-gguf:blk.5.ffn_up.weight,               torch.bfloat16 --> Q8_0, shape = {3584, 14336}\n",
      "INFO:hf-to-gguf:blk.5.post_attention_norm.weight,  torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.5.post_ffw_norm.weight,        torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.5.ffn_norm.weight,             torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.5.attn_k.weight,               torch.bfloat16 --> Q8_0, shape = {3584, 2048}\n",
      "INFO:hf-to-gguf:blk.5.attn_output.weight,          torch.bfloat16 --> Q8_0, shape = {4096, 3584}\n",
      "INFO:hf-to-gguf:blk.5.attn_q.weight,               torch.bfloat16 --> Q8_0, shape = {3584, 4096}\n",
      "INFO:hf-to-gguf:blk.5.attn_v.weight,               torch.bfloat16 --> Q8_0, shape = {3584, 2048}\n",
      "INFO:hf-to-gguf:blk.6.attn_norm.weight,            torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.6.ffn_down.weight,             torch.bfloat16 --> Q8_0, shape = {14336, 3584}\n",
      "INFO:hf-to-gguf:blk.6.ffn_gate.weight,             torch.bfloat16 --> Q8_0, shape = {3584, 14336}\n",
      "INFO:hf-to-gguf:blk.6.ffn_up.weight,               torch.bfloat16 --> Q8_0, shape = {3584, 14336}\n",
      "INFO:hf-to-gguf:blk.6.post_attention_norm.weight,  torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.6.post_ffw_norm.weight,        torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.6.ffn_norm.weight,             torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.6.attn_k.weight,               torch.bfloat16 --> Q8_0, shape = {3584, 2048}\n",
      "INFO:hf-to-gguf:blk.6.attn_output.weight,          torch.bfloat16 --> Q8_0, shape = {4096, 3584}\n",
      "INFO:hf-to-gguf:blk.6.attn_q.weight,               torch.bfloat16 --> Q8_0, shape = {3584, 4096}\n",
      "INFO:hf-to-gguf:blk.6.attn_v.weight,               torch.bfloat16 --> Q8_0, shape = {3584, 2048}\n",
      "INFO:hf-to-gguf:blk.7.ffn_gate.weight,             torch.bfloat16 --> Q8_0, shape = {3584, 14336}\n",
      "INFO:hf-to-gguf:blk.7.ffn_up.weight,               torch.bfloat16 --> Q8_0, shape = {3584, 14336}\n",
      "INFO:hf-to-gguf:blk.7.attn_k.weight,               torch.bfloat16 --> Q8_0, shape = {3584, 2048}\n",
      "INFO:hf-to-gguf:blk.7.attn_output.weight,          torch.bfloat16 --> Q8_0, shape = {4096, 3584}\n",
      "INFO:hf-to-gguf:blk.7.attn_q.weight,               torch.bfloat16 --> Q8_0, shape = {3584, 4096}\n",
      "INFO:hf-to-gguf:blk.7.attn_v.weight,               torch.bfloat16 --> Q8_0, shape = {3584, 2048}\n",
      "INFO:hf-to-gguf:gguf: loading model part 'model-00002-of-00004.safetensors'\n",
      "INFO:hf-to-gguf:blk.10.attn_norm.weight,           torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.10.ffn_down.weight,            torch.bfloat16 --> Q8_0, shape = {14336, 3584}\n",
      "INFO:hf-to-gguf:blk.10.ffn_gate.weight,            torch.bfloat16 --> Q8_0, shape = {3584, 14336}\n",
      "INFO:hf-to-gguf:blk.10.ffn_up.weight,              torch.bfloat16 --> Q8_0, shape = {3584, 14336}\n",
      "INFO:hf-to-gguf:blk.10.post_attention_norm.weight, torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.10.post_ffw_norm.weight,       torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.10.ffn_norm.weight,            torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.10.attn_k.weight,              torch.bfloat16 --> Q8_0, shape = {3584, 2048}\n",
      "INFO:hf-to-gguf:blk.10.attn_output.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 3584}\n",
      "INFO:hf-to-gguf:blk.10.attn_q.weight,              torch.bfloat16 --> Q8_0, shape = {3584, 4096}\n",
      "INFO:hf-to-gguf:blk.10.attn_v.weight,              torch.bfloat16 --> Q8_0, shape = {3584, 2048}\n",
      "INFO:hf-to-gguf:blk.11.attn_norm.weight,           torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.11.ffn_down.weight,            torch.bfloat16 --> Q8_0, shape = {14336, 3584}\n",
      "INFO:hf-to-gguf:blk.11.ffn_gate.weight,            torch.bfloat16 --> Q8_0, shape = {3584, 14336}\n",
      "INFO:hf-to-gguf:blk.11.ffn_up.weight,              torch.bfloat16 --> Q8_0, shape = {3584, 14336}\n",
      "INFO:hf-to-gguf:blk.11.post_attention_norm.weight, torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.11.post_ffw_norm.weight,       torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.11.ffn_norm.weight,            torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.11.attn_k.weight,              torch.bfloat16 --> Q8_0, shape = {3584, 2048}\n",
      "INFO:hf-to-gguf:blk.11.attn_output.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 3584}\n",
      "INFO:hf-to-gguf:blk.11.attn_q.weight,              torch.bfloat16 --> Q8_0, shape = {3584, 4096}\n",
      "INFO:hf-to-gguf:blk.11.attn_v.weight,              torch.bfloat16 --> Q8_0, shape = {3584, 2048}\n",
      "INFO:hf-to-gguf:blk.12.attn_norm.weight,           torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.12.ffn_down.weight,            torch.bfloat16 --> Q8_0, shape = {14336, 3584}\n",
      "INFO:hf-to-gguf:blk.12.ffn_gate.weight,            torch.bfloat16 --> Q8_0, shape = {3584, 14336}\n",
      "INFO:hf-to-gguf:blk.12.ffn_up.weight,              torch.bfloat16 --> Q8_0, shape = {3584, 14336}\n",
      "INFO:hf-to-gguf:blk.12.post_attention_norm.weight, torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.12.post_ffw_norm.weight,       torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.12.ffn_norm.weight,            torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.12.attn_k.weight,              torch.bfloat16 --> Q8_0, shape = {3584, 2048}\n",
      "INFO:hf-to-gguf:blk.12.attn_output.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 3584}\n",
      "INFO:hf-to-gguf:blk.12.attn_q.weight,              torch.bfloat16 --> Q8_0, shape = {3584, 4096}\n",
      "INFO:hf-to-gguf:blk.12.attn_v.weight,              torch.bfloat16 --> Q8_0, shape = {3584, 2048}\n",
      "INFO:hf-to-gguf:blk.13.attn_norm.weight,           torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.13.ffn_down.weight,            torch.bfloat16 --> Q8_0, shape = {14336, 3584}\n",
      "INFO:hf-to-gguf:blk.13.ffn_gate.weight,            torch.bfloat16 --> Q8_0, shape = {3584, 14336}\n",
      "INFO:hf-to-gguf:blk.13.ffn_up.weight,              torch.bfloat16 --> Q8_0, shape = {3584, 14336}\n",
      "INFO:hf-to-gguf:blk.13.post_attention_norm.weight, torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.13.post_ffw_norm.weight,       torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.13.ffn_norm.weight,            torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.13.attn_k.weight,              torch.bfloat16 --> Q8_0, shape = {3584, 2048}\n",
      "INFO:hf-to-gguf:blk.13.attn_output.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 3584}\n",
      "INFO:hf-to-gguf:blk.13.attn_q.weight,              torch.bfloat16 --> Q8_0, shape = {3584, 4096}\n",
      "INFO:hf-to-gguf:blk.13.attn_v.weight,              torch.bfloat16 --> Q8_0, shape = {3584, 2048}\n",
      "INFO:hf-to-gguf:blk.14.attn_norm.weight,           torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.14.ffn_down.weight,            torch.bfloat16 --> Q8_0, shape = {14336, 3584}\n",
      "INFO:hf-to-gguf:blk.14.ffn_gate.weight,            torch.bfloat16 --> Q8_0, shape = {3584, 14336}\n",
      "INFO:hf-to-gguf:blk.14.ffn_up.weight,              torch.bfloat16 --> Q8_0, shape = {3584, 14336}\n",
      "INFO:hf-to-gguf:blk.14.post_attention_norm.weight, torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.14.post_ffw_norm.weight,       torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.14.ffn_norm.weight,            torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.14.attn_k.weight,              torch.bfloat16 --> Q8_0, shape = {3584, 2048}\n",
      "INFO:hf-to-gguf:blk.14.attn_output.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 3584}\n",
      "INFO:hf-to-gguf:blk.14.attn_q.weight,              torch.bfloat16 --> Q8_0, shape = {3584, 4096}\n",
      "INFO:hf-to-gguf:blk.14.attn_v.weight,              torch.bfloat16 --> Q8_0, shape = {3584, 2048}\n",
      "INFO:hf-to-gguf:blk.15.attn_norm.weight,           torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.15.ffn_down.weight,            torch.bfloat16 --> Q8_0, shape = {14336, 3584}\n",
      "INFO:hf-to-gguf:blk.15.ffn_gate.weight,            torch.bfloat16 --> Q8_0, shape = {3584, 14336}\n",
      "INFO:hf-to-gguf:blk.15.ffn_up.weight,              torch.bfloat16 --> Q8_0, shape = {3584, 14336}\n",
      "INFO:hf-to-gguf:blk.15.post_attention_norm.weight, torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.15.post_ffw_norm.weight,       torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.15.ffn_norm.weight,            torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.15.attn_k.weight,              torch.bfloat16 --> Q8_0, shape = {3584, 2048}\n",
      "INFO:hf-to-gguf:blk.15.attn_output.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 3584}\n",
      "INFO:hf-to-gguf:blk.15.attn_q.weight,              torch.bfloat16 --> Q8_0, shape = {3584, 4096}\n",
      "INFO:hf-to-gguf:blk.15.attn_v.weight,              torch.bfloat16 --> Q8_0, shape = {3584, 2048}\n",
      "INFO:hf-to-gguf:blk.16.attn_norm.weight,           torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.16.ffn_down.weight,            torch.bfloat16 --> Q8_0, shape = {14336, 3584}\n",
      "INFO:hf-to-gguf:blk.16.ffn_gate.weight,            torch.bfloat16 --> Q8_0, shape = {3584, 14336}\n",
      "INFO:hf-to-gguf:blk.16.ffn_up.weight,              torch.bfloat16 --> Q8_0, shape = {3584, 14336}\n",
      "INFO:hf-to-gguf:blk.16.post_attention_norm.weight, torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.16.post_ffw_norm.weight,       torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.16.ffn_norm.weight,            torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.16.attn_k.weight,              torch.bfloat16 --> Q8_0, shape = {3584, 2048}\n",
      "INFO:hf-to-gguf:blk.16.attn_output.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 3584}\n",
      "INFO:hf-to-gguf:blk.16.attn_q.weight,              torch.bfloat16 --> Q8_0, shape = {3584, 4096}\n",
      "INFO:hf-to-gguf:blk.16.attn_v.weight,              torch.bfloat16 --> Q8_0, shape = {3584, 2048}\n",
      "INFO:hf-to-gguf:blk.17.attn_norm.weight,           torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.17.ffn_down.weight,            torch.bfloat16 --> Q8_0, shape = {14336, 3584}\n",
      "INFO:hf-to-gguf:blk.17.ffn_gate.weight,            torch.bfloat16 --> Q8_0, shape = {3584, 14336}\n",
      "INFO:hf-to-gguf:blk.17.ffn_up.weight,              torch.bfloat16 --> Q8_0, shape = {3584, 14336}\n",
      "INFO:hf-to-gguf:blk.17.post_attention_norm.weight, torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.17.post_ffw_norm.weight,       torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.17.ffn_norm.weight,            torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.17.attn_k.weight,              torch.bfloat16 --> Q8_0, shape = {3584, 2048}\n",
      "INFO:hf-to-gguf:blk.17.attn_output.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 3584}\n",
      "INFO:hf-to-gguf:blk.17.attn_q.weight,              torch.bfloat16 --> Q8_0, shape = {3584, 4096}\n",
      "INFO:hf-to-gguf:blk.17.attn_v.weight,              torch.bfloat16 --> Q8_0, shape = {3584, 2048}\n",
      "INFO:hf-to-gguf:blk.18.attn_norm.weight,           torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.18.ffn_down.weight,            torch.bfloat16 --> Q8_0, shape = {14336, 3584}\n",
      "INFO:hf-to-gguf:blk.18.ffn_gate.weight,            torch.bfloat16 --> Q8_0, shape = {3584, 14336}\n",
      "INFO:hf-to-gguf:blk.18.ffn_up.weight,              torch.bfloat16 --> Q8_0, shape = {3584, 14336}\n",
      "INFO:hf-to-gguf:blk.18.post_attention_norm.weight, torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.18.post_ffw_norm.weight,       torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.18.ffn_norm.weight,            torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.18.attn_k.weight,              torch.bfloat16 --> Q8_0, shape = {3584, 2048}\n",
      "INFO:hf-to-gguf:blk.18.attn_output.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 3584}\n",
      "INFO:hf-to-gguf:blk.18.attn_q.weight,              torch.bfloat16 --> Q8_0, shape = {3584, 4096}\n",
      "INFO:hf-to-gguf:blk.18.attn_v.weight,              torch.bfloat16 --> Q8_0, shape = {3584, 2048}\n",
      "INFO:hf-to-gguf:blk.19.attn_norm.weight,           torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.19.ffn_down.weight,            torch.bfloat16 --> Q8_0, shape = {14336, 3584}\n",
      "INFO:hf-to-gguf:blk.19.ffn_gate.weight,            torch.bfloat16 --> Q8_0, shape = {3584, 14336}\n",
      "INFO:hf-to-gguf:blk.19.ffn_up.weight,              torch.bfloat16 --> Q8_0, shape = {3584, 14336}\n",
      "INFO:hf-to-gguf:blk.19.post_attention_norm.weight, torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.19.post_ffw_norm.weight,       torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.19.ffn_norm.weight,            torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.19.attn_k.weight,              torch.bfloat16 --> Q8_0, shape = {3584, 2048}\n",
      "INFO:hf-to-gguf:blk.19.attn_output.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 3584}\n",
      "INFO:hf-to-gguf:blk.19.attn_q.weight,              torch.bfloat16 --> Q8_0, shape = {3584, 4096}\n",
      "INFO:hf-to-gguf:blk.19.attn_v.weight,              torch.bfloat16 --> Q8_0, shape = {3584, 2048}\n",
      "INFO:hf-to-gguf:blk.20.attn_k.weight,              torch.bfloat16 --> Q8_0, shape = {3584, 2048}\n",
      "INFO:hf-to-gguf:blk.20.attn_output.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 3584}\n",
      "INFO:hf-to-gguf:blk.20.attn_q.weight,              torch.bfloat16 --> Q8_0, shape = {3584, 4096}\n",
      "INFO:hf-to-gguf:blk.20.attn_v.weight,              torch.bfloat16 --> Q8_0, shape = {3584, 2048}\n",
      "INFO:hf-to-gguf:blk.7.attn_norm.weight,            torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.7.ffn_down.weight,             torch.bfloat16 --> Q8_0, shape = {14336, 3584}\n",
      "INFO:hf-to-gguf:blk.7.post_attention_norm.weight,  torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.7.post_ffw_norm.weight,        torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.7.ffn_norm.weight,             torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.8.attn_norm.weight,            torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.8.ffn_down.weight,             torch.bfloat16 --> Q8_0, shape = {14336, 3584}\n",
      "INFO:hf-to-gguf:blk.8.ffn_gate.weight,             torch.bfloat16 --> Q8_0, shape = {3584, 14336}\n",
      "INFO:hf-to-gguf:blk.8.ffn_up.weight,               torch.bfloat16 --> Q8_0, shape = {3584, 14336}\n",
      "INFO:hf-to-gguf:blk.8.post_attention_norm.weight,  torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.8.post_ffw_norm.weight,        torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.8.ffn_norm.weight,             torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.8.attn_k.weight,               torch.bfloat16 --> Q8_0, shape = {3584, 2048}\n",
      "INFO:hf-to-gguf:blk.8.attn_output.weight,          torch.bfloat16 --> Q8_0, shape = {4096, 3584}\n",
      "INFO:hf-to-gguf:blk.8.attn_q.weight,               torch.bfloat16 --> Q8_0, shape = {3584, 4096}\n",
      "INFO:hf-to-gguf:blk.8.attn_v.weight,               torch.bfloat16 --> Q8_0, shape = {3584, 2048}\n",
      "INFO:hf-to-gguf:blk.9.attn_norm.weight,            torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.9.ffn_down.weight,             torch.bfloat16 --> Q8_0, shape = {14336, 3584}\n",
      "INFO:hf-to-gguf:blk.9.ffn_gate.weight,             torch.bfloat16 --> Q8_0, shape = {3584, 14336}\n",
      "INFO:hf-to-gguf:blk.9.ffn_up.weight,               torch.bfloat16 --> Q8_0, shape = {3584, 14336}\n",
      "INFO:hf-to-gguf:blk.9.post_attention_norm.weight,  torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.9.post_ffw_norm.weight,        torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.9.ffn_norm.weight,             torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.9.attn_k.weight,               torch.bfloat16 --> Q8_0, shape = {3584, 2048}\n",
      "INFO:hf-to-gguf:blk.9.attn_output.weight,          torch.bfloat16 --> Q8_0, shape = {4096, 3584}\n",
      "INFO:hf-to-gguf:blk.9.attn_q.weight,               torch.bfloat16 --> Q8_0, shape = {3584, 4096}\n",
      "INFO:hf-to-gguf:blk.9.attn_v.weight,               torch.bfloat16 --> Q8_0, shape = {3584, 2048}\n",
      "INFO:hf-to-gguf:gguf: loading model part 'model-00003-of-00004.safetensors'\n",
      "INFO:hf-to-gguf:blk.20.attn_norm.weight,           torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.20.ffn_down.weight,            torch.bfloat16 --> Q8_0, shape = {14336, 3584}\n",
      "INFO:hf-to-gguf:blk.20.ffn_gate.weight,            torch.bfloat16 --> Q8_0, shape = {3584, 14336}\n",
      "INFO:hf-to-gguf:blk.20.ffn_up.weight,              torch.bfloat16 --> Q8_0, shape = {3584, 14336}\n",
      "INFO:hf-to-gguf:blk.20.post_attention_norm.weight, torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.20.post_ffw_norm.weight,       torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.20.ffn_norm.weight,            torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.21.attn_norm.weight,           torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.21.ffn_down.weight,            torch.bfloat16 --> Q8_0, shape = {14336, 3584}\n",
      "INFO:hf-to-gguf:blk.21.ffn_gate.weight,            torch.bfloat16 --> Q8_0, shape = {3584, 14336}\n",
      "INFO:hf-to-gguf:blk.21.ffn_up.weight,              torch.bfloat16 --> Q8_0, shape = {3584, 14336}\n",
      "INFO:hf-to-gguf:blk.21.post_attention_norm.weight, torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.21.post_ffw_norm.weight,       torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.21.ffn_norm.weight,            torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.21.attn_k.weight,              torch.bfloat16 --> Q8_0, shape = {3584, 2048}\n",
      "INFO:hf-to-gguf:blk.21.attn_output.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 3584}\n",
      "INFO:hf-to-gguf:blk.21.attn_q.weight,              torch.bfloat16 --> Q8_0, shape = {3584, 4096}\n",
      "INFO:hf-to-gguf:blk.21.attn_v.weight,              torch.bfloat16 --> Q8_0, shape = {3584, 2048}\n",
      "INFO:hf-to-gguf:blk.22.attn_norm.weight,           torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.22.ffn_down.weight,            torch.bfloat16 --> Q8_0, shape = {14336, 3584}\n",
      "INFO:hf-to-gguf:blk.22.ffn_gate.weight,            torch.bfloat16 --> Q8_0, shape = {3584, 14336}\n",
      "INFO:hf-to-gguf:blk.22.ffn_up.weight,              torch.bfloat16 --> Q8_0, shape = {3584, 14336}\n",
      "INFO:hf-to-gguf:blk.22.post_attention_norm.weight, torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.22.post_ffw_norm.weight,       torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.22.ffn_norm.weight,            torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.22.attn_k.weight,              torch.bfloat16 --> Q8_0, shape = {3584, 2048}\n",
      "INFO:hf-to-gguf:blk.22.attn_output.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 3584}\n",
      "INFO:hf-to-gguf:blk.22.attn_q.weight,              torch.bfloat16 --> Q8_0, shape = {3584, 4096}\n",
      "INFO:hf-to-gguf:blk.22.attn_v.weight,              torch.bfloat16 --> Q8_0, shape = {3584, 2048}\n",
      "INFO:hf-to-gguf:blk.23.attn_norm.weight,           torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.23.ffn_down.weight,            torch.bfloat16 --> Q8_0, shape = {14336, 3584}\n",
      "INFO:hf-to-gguf:blk.23.ffn_gate.weight,            torch.bfloat16 --> Q8_0, shape = {3584, 14336}\n",
      "INFO:hf-to-gguf:blk.23.ffn_up.weight,              torch.bfloat16 --> Q8_0, shape = {3584, 14336}\n",
      "INFO:hf-to-gguf:blk.23.post_attention_norm.weight, torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.23.post_ffw_norm.weight,       torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.23.ffn_norm.weight,            torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.23.attn_k.weight,              torch.bfloat16 --> Q8_0, shape = {3584, 2048}\n",
      "INFO:hf-to-gguf:blk.23.attn_output.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 3584}\n",
      "INFO:hf-to-gguf:blk.23.attn_q.weight,              torch.bfloat16 --> Q8_0, shape = {3584, 4096}\n",
      "INFO:hf-to-gguf:blk.23.attn_v.weight,              torch.bfloat16 --> Q8_0, shape = {3584, 2048}\n",
      "INFO:hf-to-gguf:blk.24.attn_norm.weight,           torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.24.ffn_down.weight,            torch.bfloat16 --> Q8_0, shape = {14336, 3584}\n",
      "INFO:hf-to-gguf:blk.24.ffn_gate.weight,            torch.bfloat16 --> Q8_0, shape = {3584, 14336}\n",
      "INFO:hf-to-gguf:blk.24.ffn_up.weight,              torch.bfloat16 --> Q8_0, shape = {3584, 14336}\n",
      "INFO:hf-to-gguf:blk.24.post_attention_norm.weight, torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.24.post_ffw_norm.weight,       torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.24.ffn_norm.weight,            torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.24.attn_k.weight,              torch.bfloat16 --> Q8_0, shape = {3584, 2048}\n",
      "INFO:hf-to-gguf:blk.24.attn_output.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 3584}\n",
      "INFO:hf-to-gguf:blk.24.attn_q.weight,              torch.bfloat16 --> Q8_0, shape = {3584, 4096}\n",
      "INFO:hf-to-gguf:blk.24.attn_v.weight,              torch.bfloat16 --> Q8_0, shape = {3584, 2048}\n",
      "INFO:hf-to-gguf:blk.25.attn_norm.weight,           torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.25.ffn_down.weight,            torch.bfloat16 --> Q8_0, shape = {14336, 3584}\n",
      "INFO:hf-to-gguf:blk.25.ffn_gate.weight,            torch.bfloat16 --> Q8_0, shape = {3584, 14336}\n",
      "INFO:hf-to-gguf:blk.25.ffn_up.weight,              torch.bfloat16 --> Q8_0, shape = {3584, 14336}\n",
      "INFO:hf-to-gguf:blk.25.post_attention_norm.weight, torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.25.post_ffw_norm.weight,       torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.25.ffn_norm.weight,            torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.25.attn_k.weight,              torch.bfloat16 --> Q8_0, shape = {3584, 2048}\n",
      "INFO:hf-to-gguf:blk.25.attn_output.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 3584}\n",
      "INFO:hf-to-gguf:blk.25.attn_q.weight,              torch.bfloat16 --> Q8_0, shape = {3584, 4096}\n",
      "INFO:hf-to-gguf:blk.25.attn_v.weight,              torch.bfloat16 --> Q8_0, shape = {3584, 2048}\n",
      "INFO:hf-to-gguf:blk.26.attn_norm.weight,           torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.26.ffn_down.weight,            torch.bfloat16 --> Q8_0, shape = {14336, 3584}\n",
      "INFO:hf-to-gguf:blk.26.ffn_gate.weight,            torch.bfloat16 --> Q8_0, shape = {3584, 14336}\n",
      "INFO:hf-to-gguf:blk.26.ffn_up.weight,              torch.bfloat16 --> Q8_0, shape = {3584, 14336}\n",
      "INFO:hf-to-gguf:blk.26.post_attention_norm.weight, torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.26.post_ffw_norm.weight,       torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.26.ffn_norm.weight,            torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.26.attn_k.weight,              torch.bfloat16 --> Q8_0, shape = {3584, 2048}\n",
      "INFO:hf-to-gguf:blk.26.attn_output.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 3584}\n",
      "INFO:hf-to-gguf:blk.26.attn_q.weight,              torch.bfloat16 --> Q8_0, shape = {3584, 4096}\n",
      "INFO:hf-to-gguf:blk.26.attn_v.weight,              torch.bfloat16 --> Q8_0, shape = {3584, 2048}\n",
      "INFO:hf-to-gguf:blk.27.attn_norm.weight,           torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.27.ffn_down.weight,            torch.bfloat16 --> Q8_0, shape = {14336, 3584}\n",
      "INFO:hf-to-gguf:blk.27.ffn_gate.weight,            torch.bfloat16 --> Q8_0, shape = {3584, 14336}\n",
      "INFO:hf-to-gguf:blk.27.ffn_up.weight,              torch.bfloat16 --> Q8_0, shape = {3584, 14336}\n",
      "INFO:hf-to-gguf:blk.27.post_attention_norm.weight, torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.27.post_ffw_norm.weight,       torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.27.ffn_norm.weight,            torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.27.attn_k.weight,              torch.bfloat16 --> Q8_0, shape = {3584, 2048}\n",
      "INFO:hf-to-gguf:blk.27.attn_output.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 3584}\n",
      "INFO:hf-to-gguf:blk.27.attn_q.weight,              torch.bfloat16 --> Q8_0, shape = {3584, 4096}\n",
      "INFO:hf-to-gguf:blk.27.attn_v.weight,              torch.bfloat16 --> Q8_0, shape = {3584, 2048}\n",
      "INFO:hf-to-gguf:blk.28.attn_norm.weight,           torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.28.ffn_down.weight,            torch.bfloat16 --> Q8_0, shape = {14336, 3584}\n",
      "INFO:hf-to-gguf:blk.28.ffn_gate.weight,            torch.bfloat16 --> Q8_0, shape = {3584, 14336}\n",
      "INFO:hf-to-gguf:blk.28.ffn_up.weight,              torch.bfloat16 --> Q8_0, shape = {3584, 14336}\n",
      "INFO:hf-to-gguf:blk.28.post_attention_norm.weight, torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.28.post_ffw_norm.weight,       torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.28.ffn_norm.weight,            torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.28.attn_k.weight,              torch.bfloat16 --> Q8_0, shape = {3584, 2048}\n",
      "INFO:hf-to-gguf:blk.28.attn_output.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 3584}\n",
      "INFO:hf-to-gguf:blk.28.attn_q.weight,              torch.bfloat16 --> Q8_0, shape = {3584, 4096}\n",
      "INFO:hf-to-gguf:blk.28.attn_v.weight,              torch.bfloat16 --> Q8_0, shape = {3584, 2048}\n",
      "INFO:hf-to-gguf:blk.29.attn_norm.weight,           torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.29.ffn_down.weight,            torch.bfloat16 --> Q8_0, shape = {14336, 3584}\n",
      "INFO:hf-to-gguf:blk.29.ffn_gate.weight,            torch.bfloat16 --> Q8_0, shape = {3584, 14336}\n",
      "INFO:hf-to-gguf:blk.29.ffn_up.weight,              torch.bfloat16 --> Q8_0, shape = {3584, 14336}\n",
      "INFO:hf-to-gguf:blk.29.post_attention_norm.weight, torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.29.post_ffw_norm.weight,       torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.29.ffn_norm.weight,            torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.29.attn_k.weight,              torch.bfloat16 --> Q8_0, shape = {3584, 2048}\n",
      "INFO:hf-to-gguf:blk.29.attn_output.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 3584}\n",
      "INFO:hf-to-gguf:blk.29.attn_q.weight,              torch.bfloat16 --> Q8_0, shape = {3584, 4096}\n",
      "INFO:hf-to-gguf:blk.29.attn_v.weight,              torch.bfloat16 --> Q8_0, shape = {3584, 2048}\n",
      "INFO:hf-to-gguf:blk.30.attn_norm.weight,           torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.30.ffn_down.weight,            torch.bfloat16 --> Q8_0, shape = {14336, 3584}\n",
      "INFO:hf-to-gguf:blk.30.ffn_gate.weight,            torch.bfloat16 --> Q8_0, shape = {3584, 14336}\n",
      "INFO:hf-to-gguf:blk.30.ffn_up.weight,              torch.bfloat16 --> Q8_0, shape = {3584, 14336}\n",
      "INFO:hf-to-gguf:blk.30.post_attention_norm.weight, torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.30.post_ffw_norm.weight,       torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.30.ffn_norm.weight,            torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.30.attn_k.weight,              torch.bfloat16 --> Q8_0, shape = {3584, 2048}\n",
      "INFO:hf-to-gguf:blk.30.attn_output.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 3584}\n",
      "INFO:hf-to-gguf:blk.30.attn_q.weight,              torch.bfloat16 --> Q8_0, shape = {3584, 4096}\n",
      "INFO:hf-to-gguf:blk.30.attn_v.weight,              torch.bfloat16 --> Q8_0, shape = {3584, 2048}\n",
      "INFO:hf-to-gguf:blk.31.attn_norm.weight,           torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.31.ffn_down.weight,            torch.bfloat16 --> Q8_0, shape = {14336, 3584}\n",
      "INFO:hf-to-gguf:blk.31.ffn_gate.weight,            torch.bfloat16 --> Q8_0, shape = {3584, 14336}\n",
      "INFO:hf-to-gguf:blk.31.ffn_up.weight,              torch.bfloat16 --> Q8_0, shape = {3584, 14336}\n",
      "INFO:hf-to-gguf:blk.31.post_attention_norm.weight, torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.31.post_ffw_norm.weight,       torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.31.ffn_norm.weight,            torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.31.attn_k.weight,              torch.bfloat16 --> Q8_0, shape = {3584, 2048}\n",
      "INFO:hf-to-gguf:blk.31.attn_output.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 3584}\n",
      "INFO:hf-to-gguf:blk.31.attn_q.weight,              torch.bfloat16 --> Q8_0, shape = {3584, 4096}\n",
      "INFO:hf-to-gguf:blk.31.attn_v.weight,              torch.bfloat16 --> Q8_0, shape = {3584, 2048}\n",
      "INFO:hf-to-gguf:blk.32.ffn_gate.weight,            torch.bfloat16 --> Q8_0, shape = {3584, 14336}\n",
      "INFO:hf-to-gguf:blk.32.ffn_up.weight,              torch.bfloat16 --> Q8_0, shape = {3584, 14336}\n",
      "INFO:hf-to-gguf:blk.32.attn_k.weight,              torch.bfloat16 --> Q8_0, shape = {3584, 2048}\n",
      "INFO:hf-to-gguf:blk.32.attn_output.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 3584}\n",
      "INFO:hf-to-gguf:blk.32.attn_q.weight,              torch.bfloat16 --> Q8_0, shape = {3584, 4096}\n",
      "INFO:hf-to-gguf:blk.32.attn_v.weight,              torch.bfloat16 --> Q8_0, shape = {3584, 2048}\n",
      "INFO:hf-to-gguf:gguf: loading model part 'model-00004-of-00004.safetensors'\n",
      "INFO:hf-to-gguf:blk.32.attn_norm.weight,           torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.32.ffn_down.weight,            torch.bfloat16 --> Q8_0, shape = {14336, 3584}\n",
      "INFO:hf-to-gguf:blk.32.post_attention_norm.weight, torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.32.post_ffw_norm.weight,       torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.32.ffn_norm.weight,            torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.33.attn_norm.weight,           torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.33.ffn_down.weight,            torch.bfloat16 --> Q8_0, shape = {14336, 3584}\n",
      "INFO:hf-to-gguf:blk.33.ffn_gate.weight,            torch.bfloat16 --> Q8_0, shape = {3584, 14336}\n",
      "INFO:hf-to-gguf:blk.33.ffn_up.weight,              torch.bfloat16 --> Q8_0, shape = {3584, 14336}\n",
      "INFO:hf-to-gguf:blk.33.post_attention_norm.weight, torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.33.post_ffw_norm.weight,       torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.33.ffn_norm.weight,            torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.33.attn_k.weight,              torch.bfloat16 --> Q8_0, shape = {3584, 2048}\n",
      "INFO:hf-to-gguf:blk.33.attn_output.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 3584}\n",
      "INFO:hf-to-gguf:blk.33.attn_q.weight,              torch.bfloat16 --> Q8_0, shape = {3584, 4096}\n",
      "INFO:hf-to-gguf:blk.33.attn_v.weight,              torch.bfloat16 --> Q8_0, shape = {3584, 2048}\n",
      "INFO:hf-to-gguf:blk.34.attn_norm.weight,           torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.34.ffn_down.weight,            torch.bfloat16 --> Q8_0, shape = {14336, 3584}\n",
      "INFO:hf-to-gguf:blk.34.ffn_gate.weight,            torch.bfloat16 --> Q8_0, shape = {3584, 14336}\n",
      "INFO:hf-to-gguf:blk.34.ffn_up.weight,              torch.bfloat16 --> Q8_0, shape = {3584, 14336}\n",
      "INFO:hf-to-gguf:blk.34.post_attention_norm.weight, torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.34.post_ffw_norm.weight,       torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.34.ffn_norm.weight,            torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.34.attn_k.weight,              torch.bfloat16 --> Q8_0, shape = {3584, 2048}\n",
      "INFO:hf-to-gguf:blk.34.attn_output.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 3584}\n",
      "INFO:hf-to-gguf:blk.34.attn_q.weight,              torch.bfloat16 --> Q8_0, shape = {3584, 4096}\n",
      "INFO:hf-to-gguf:blk.34.attn_v.weight,              torch.bfloat16 --> Q8_0, shape = {3584, 2048}\n",
      "INFO:hf-to-gguf:blk.35.attn_norm.weight,           torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.35.ffn_down.weight,            torch.bfloat16 --> Q8_0, shape = {14336, 3584}\n",
      "INFO:hf-to-gguf:blk.35.ffn_gate.weight,            torch.bfloat16 --> Q8_0, shape = {3584, 14336}\n",
      "INFO:hf-to-gguf:blk.35.ffn_up.weight,              torch.bfloat16 --> Q8_0, shape = {3584, 14336}\n",
      "INFO:hf-to-gguf:blk.35.post_attention_norm.weight, torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.35.post_ffw_norm.weight,       torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.35.ffn_norm.weight,            torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.35.attn_k.weight,              torch.bfloat16 --> Q8_0, shape = {3584, 2048}\n",
      "INFO:hf-to-gguf:blk.35.attn_output.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 3584}\n",
      "INFO:hf-to-gguf:blk.35.attn_q.weight,              torch.bfloat16 --> Q8_0, shape = {3584, 4096}\n",
      "INFO:hf-to-gguf:blk.35.attn_v.weight,              torch.bfloat16 --> Q8_0, shape = {3584, 2048}\n",
      "INFO:hf-to-gguf:blk.36.attn_norm.weight,           torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.36.ffn_down.weight,            torch.bfloat16 --> Q8_0, shape = {14336, 3584}\n",
      "INFO:hf-to-gguf:blk.36.ffn_gate.weight,            torch.bfloat16 --> Q8_0, shape = {3584, 14336}\n",
      "INFO:hf-to-gguf:blk.36.ffn_up.weight,              torch.bfloat16 --> Q8_0, shape = {3584, 14336}\n",
      "INFO:hf-to-gguf:blk.36.post_attention_norm.weight, torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.36.post_ffw_norm.weight,       torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.36.ffn_norm.weight,            torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.36.attn_k.weight,              torch.bfloat16 --> Q8_0, shape = {3584, 2048}\n",
      "INFO:hf-to-gguf:blk.36.attn_output.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 3584}\n",
      "INFO:hf-to-gguf:blk.36.attn_q.weight,              torch.bfloat16 --> Q8_0, shape = {3584, 4096}\n",
      "INFO:hf-to-gguf:blk.36.attn_v.weight,              torch.bfloat16 --> Q8_0, shape = {3584, 2048}\n",
      "INFO:hf-to-gguf:blk.37.attn_norm.weight,           torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.37.ffn_down.weight,            torch.bfloat16 --> Q8_0, shape = {14336, 3584}\n",
      "INFO:hf-to-gguf:blk.37.ffn_gate.weight,            torch.bfloat16 --> Q8_0, shape = {3584, 14336}\n",
      "INFO:hf-to-gguf:blk.37.ffn_up.weight,              torch.bfloat16 --> Q8_0, shape = {3584, 14336}\n",
      "INFO:hf-to-gguf:blk.37.post_attention_norm.weight, torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.37.post_ffw_norm.weight,       torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.37.ffn_norm.weight,            torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.37.attn_k.weight,              torch.bfloat16 --> Q8_0, shape = {3584, 2048}\n",
      "INFO:hf-to-gguf:blk.37.attn_output.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 3584}\n",
      "INFO:hf-to-gguf:blk.37.attn_q.weight,              torch.bfloat16 --> Q8_0, shape = {3584, 4096}\n",
      "INFO:hf-to-gguf:blk.37.attn_v.weight,              torch.bfloat16 --> Q8_0, shape = {3584, 2048}\n",
      "INFO:hf-to-gguf:blk.38.attn_norm.weight,           torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.38.ffn_down.weight,            torch.bfloat16 --> Q8_0, shape = {14336, 3584}\n",
      "INFO:hf-to-gguf:blk.38.ffn_gate.weight,            torch.bfloat16 --> Q8_0, shape = {3584, 14336}\n",
      "INFO:hf-to-gguf:blk.38.ffn_up.weight,              torch.bfloat16 --> Q8_0, shape = {3584, 14336}\n",
      "INFO:hf-to-gguf:blk.38.post_attention_norm.weight, torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.38.post_ffw_norm.weight,       torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.38.ffn_norm.weight,            torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.38.attn_k.weight,              torch.bfloat16 --> Q8_0, shape = {3584, 2048}\n",
      "INFO:hf-to-gguf:blk.38.attn_output.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 3584}\n",
      "INFO:hf-to-gguf:blk.38.attn_q.weight,              torch.bfloat16 --> Q8_0, shape = {3584, 4096}\n",
      "INFO:hf-to-gguf:blk.38.attn_v.weight,              torch.bfloat16 --> Q8_0, shape = {3584, 2048}\n",
      "INFO:hf-to-gguf:blk.39.attn_norm.weight,           torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.39.ffn_down.weight,            torch.bfloat16 --> Q8_0, shape = {14336, 3584}\n",
      "INFO:hf-to-gguf:blk.39.ffn_gate.weight,            torch.bfloat16 --> Q8_0, shape = {3584, 14336}\n",
      "INFO:hf-to-gguf:blk.39.ffn_up.weight,              torch.bfloat16 --> Q8_0, shape = {3584, 14336}\n",
      "INFO:hf-to-gguf:blk.39.post_attention_norm.weight, torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.39.post_ffw_norm.weight,       torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.39.ffn_norm.weight,            torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.39.attn_k.weight,              torch.bfloat16 --> Q8_0, shape = {3584, 2048}\n",
      "INFO:hf-to-gguf:blk.39.attn_output.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 3584}\n",
      "INFO:hf-to-gguf:blk.39.attn_q.weight,              torch.bfloat16 --> Q8_0, shape = {3584, 4096}\n",
      "INFO:hf-to-gguf:blk.39.attn_v.weight,              torch.bfloat16 --> Q8_0, shape = {3584, 2048}\n",
      "INFO:hf-to-gguf:blk.40.attn_norm.weight,           torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.40.ffn_down.weight,            torch.bfloat16 --> Q8_0, shape = {14336, 3584}\n",
      "INFO:hf-to-gguf:blk.40.ffn_gate.weight,            torch.bfloat16 --> Q8_0, shape = {3584, 14336}\n",
      "INFO:hf-to-gguf:blk.40.ffn_up.weight,              torch.bfloat16 --> Q8_0, shape = {3584, 14336}\n",
      "INFO:hf-to-gguf:blk.40.post_attention_norm.weight, torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.40.post_ffw_norm.weight,       torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.40.ffn_norm.weight,            torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.40.attn_k.weight,              torch.bfloat16 --> Q8_0, shape = {3584, 2048}\n",
      "INFO:hf-to-gguf:blk.40.attn_output.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 3584}\n",
      "INFO:hf-to-gguf:blk.40.attn_q.weight,              torch.bfloat16 --> Q8_0, shape = {3584, 4096}\n",
      "INFO:hf-to-gguf:blk.40.attn_v.weight,              torch.bfloat16 --> Q8_0, shape = {3584, 2048}\n",
      "INFO:hf-to-gguf:blk.41.attn_norm.weight,           torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.41.ffn_down.weight,            torch.bfloat16 --> Q8_0, shape = {14336, 3584}\n",
      "INFO:hf-to-gguf:blk.41.ffn_gate.weight,            torch.bfloat16 --> Q8_0, shape = {3584, 14336}\n",
      "INFO:hf-to-gguf:blk.41.ffn_up.weight,              torch.bfloat16 --> Q8_0, shape = {3584, 14336}\n",
      "INFO:hf-to-gguf:blk.41.post_attention_norm.weight, torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.41.post_ffw_norm.weight,       torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.41.ffn_norm.weight,            torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.41.attn_k.weight,              torch.bfloat16 --> Q8_0, shape = {3584, 2048}\n",
      "INFO:hf-to-gguf:blk.41.attn_output.weight,         torch.bfloat16 --> Q8_0, shape = {4096, 3584}\n",
      "INFO:hf-to-gguf:blk.41.attn_q.weight,              torch.bfloat16 --> Q8_0, shape = {3584, 4096}\n",
      "INFO:hf-to-gguf:blk.41.attn_v.weight,              torch.bfloat16 --> Q8_0, shape = {3584, 2048}\n",
      "INFO:hf-to-gguf:output_norm.weight,                torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:Set meta model\n",
      "INFO:hf-to-gguf:Set model parameters\n",
      "INFO:hf-to-gguf:Set model tokenizer\n",
      "INFO:gguf.vocab:Setting special token type bos to 2\n",
      "INFO:gguf.vocab:Setting special token type eos to 1\n",
      "INFO:gguf.vocab:Setting special token type unk to 3\n",
      "INFO:gguf.vocab:Setting special token type pad to 0\n",
      "INFO:gguf.vocab:Setting add_bos_token to True\n",
      "INFO:gguf.vocab:Setting add_eos_token to False\n",
      "INFO:hf-to-gguf:Set model quantization version\n",
      "INFO:gguf.gguf_writer:Writing the following files:\n",
      "INFO:gguf.gguf_writer:/content/WildBurger/group1_finetuned_gemma2_v3/unsloth.Q8_0.gguf: n_tensors = 464, total_size = 9.8G\n",
      "Writing: 100%|██████████| 9.82G/9.82G [01:50<00:00, 88.7Mbyte/s]\n",
      "INFO:hf-to-gguf:Model successfully exported to /content/WildBurger/group1_finetuned_gemma2_v3/unsloth.Q8_0.gguf\n",
      "Unsloth: Conversion completed! Output location: /content/WildBurger/group1_finetuned_gemma2_v3/unsloth.Q8_0.gguf\n",
      "Unsloth: Uploading GGUF to Huggingface Hub...\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "701ded583d78417baf61633d7dc0e71c"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "unsloth.Q8_0.gguf:   0%|          | 0.00/9.83G [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b414dfb0457d477988033fe97e4d1fc6"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Saved GGUF to https://huggingface.co/WildBurger/group1_finetuned_gemma2_v3\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": "model.push_to_hub_gguf(\"WildBurger/group1_finetuned_gemma2_v3\", tokenizer, quantization_method = \"q4_1\", token = \"\")",
   "metadata": {
    "id": "c73x6GLoVM-o",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "d00dbff7a4b04ca3bdc40aa74b01fe57",
      "ecd93aa09b104ebeb1a9f8abb5ce832e",
      "924446feeac444809846c4b8cc4772ec",
      "59ad1421227a4049a645d1bfa3c6e496",
      "dc33e26fff804b69bed80b7a258e0658",
      "35a74584417a4eec9a9001e34b2fcfb2",
      "a2d9f584ea694f9da723588d3851dfca",
      "f62c093297e44b4d96ffd7a1bea90c1f",
      "af7cd6c59c984d90b08e193942e50113",
      "f4e62442a670401f97fd2cf217a807c1",
      "9d3ebc1d42de46df8898ae52716836d4",
      "64c85b6218b044f0811c7af2b2bd2a2d",
      "824c1737562f4c2caff110c1e9cb9793",
      "4ad9a932964d4b0baa9998fce8ca4264",
      "d437a62deade44108bfdc6c5365141ab",
      "c70f3097e04541039184400aabb4caa0",
      "033a452869cf4391aa110b863d3b7c71",
      "219ac65b85504b0984b06c67944b2ea2",
      "d8bfb69c96f2499286bced5b96d28710",
      "83924fd6ba7348e8b7edc34bad4da41e",
      "48d7e78993db4c7b82e3e23cf1d7b8da",
      "5d858730982d45ad9092e0ca9df9fcb7"
     ]
    },
    "outputId": "0cb4dd24-1fcc-4452-a3ab-e4033c124d94"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Unsloth: Merging 4bit and LoRA weights to 16bit...\n",
      "Unsloth: Will use up to 54.47 out of 83.48 RAM for saving.\n",
      "Unsloth: Saving model... This might take 5 minutes ...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 42/42 [00:00<00:00, 45.39it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Unsloth: Saving tokenizer... Done.\n",
      "Done.\n",
      "==((====))==  Unsloth: Conversion from QLoRA to GGUF information\n",
      "   \\\\   /|    [0] Installing llama.cpp might take 3 minutes.\n",
      "O^O/ \\_/ \\    [1] Converting HF to GGUF 16bits might take 3 minutes.\n",
      "\\        /    [2] Converting GGUF 16bits to ['q4_1'] might take 10 minutes each.\n",
      " \"-____-\"     In total, you will have to wait at least 16 minutes.\n",
      "\n",
      "Unsloth: Installing llama.cpp. This might take 3 minutes...\n",
      "Unsloth: [1] Converting model at WildBurger/group1_finetuned_gemma2_v3 into bf16 GGUF format.\n",
      "The output location will be /content/WildBurger/group1_finetuned_gemma2_v3/unsloth.BF16.gguf\n",
      "This might take 3 minutes...\n",
      "INFO:hf-to-gguf:Loading model: group1_finetuned_gemma2_v3\n",
      "INFO:gguf.gguf_writer:gguf: This GGUF file is for Little Endian only\n",
      "INFO:hf-to-gguf:Exporting model...\n",
      "INFO:hf-to-gguf:gguf: loading model weight map from 'model.safetensors.index.json'\n",
      "INFO:hf-to-gguf:gguf: loading model part 'model-00001-of-00004.safetensors'\n",
      "INFO:hf-to-gguf:token_embd.weight,                 torch.bfloat16 --> BF16, shape = {3584, 256000}\n",
      "INFO:hf-to-gguf:blk.0.attn_norm.weight,            torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.0.ffn_down.weight,             torch.bfloat16 --> BF16, shape = {14336, 3584}\n",
      "INFO:hf-to-gguf:blk.0.ffn_gate.weight,             torch.bfloat16 --> BF16, shape = {3584, 14336}\n",
      "INFO:hf-to-gguf:blk.0.ffn_up.weight,               torch.bfloat16 --> BF16, shape = {3584, 14336}\n",
      "INFO:hf-to-gguf:blk.0.post_attention_norm.weight,  torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.0.post_ffw_norm.weight,        torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.0.ffn_norm.weight,             torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.0.attn_k.weight,               torch.bfloat16 --> BF16, shape = {3584, 2048}\n",
      "INFO:hf-to-gguf:blk.0.attn_output.weight,          torch.bfloat16 --> BF16, shape = {4096, 3584}\n",
      "INFO:hf-to-gguf:blk.0.attn_q.weight,               torch.bfloat16 --> BF16, shape = {3584, 4096}\n",
      "INFO:hf-to-gguf:blk.0.attn_v.weight,               torch.bfloat16 --> BF16, shape = {3584, 2048}\n",
      "INFO:hf-to-gguf:blk.1.attn_norm.weight,            torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.1.ffn_down.weight,             torch.bfloat16 --> BF16, shape = {14336, 3584}\n",
      "INFO:hf-to-gguf:blk.1.ffn_gate.weight,             torch.bfloat16 --> BF16, shape = {3584, 14336}\n",
      "INFO:hf-to-gguf:blk.1.ffn_up.weight,               torch.bfloat16 --> BF16, shape = {3584, 14336}\n",
      "INFO:hf-to-gguf:blk.1.post_attention_norm.weight,  torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.1.post_ffw_norm.weight,        torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.1.ffn_norm.weight,             torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.1.attn_k.weight,               torch.bfloat16 --> BF16, shape = {3584, 2048}\n",
      "INFO:hf-to-gguf:blk.1.attn_output.weight,          torch.bfloat16 --> BF16, shape = {4096, 3584}\n",
      "INFO:hf-to-gguf:blk.1.attn_q.weight,               torch.bfloat16 --> BF16, shape = {3584, 4096}\n",
      "INFO:hf-to-gguf:blk.1.attn_v.weight,               torch.bfloat16 --> BF16, shape = {3584, 2048}\n",
      "INFO:hf-to-gguf:blk.2.attn_norm.weight,            torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.2.ffn_down.weight,             torch.bfloat16 --> BF16, shape = {14336, 3584}\n",
      "INFO:hf-to-gguf:blk.2.ffn_gate.weight,             torch.bfloat16 --> BF16, shape = {3584, 14336}\n",
      "INFO:hf-to-gguf:blk.2.ffn_up.weight,               torch.bfloat16 --> BF16, shape = {3584, 14336}\n",
      "INFO:hf-to-gguf:blk.2.post_attention_norm.weight,  torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.2.post_ffw_norm.weight,        torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.2.ffn_norm.weight,             torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.2.attn_k.weight,               torch.bfloat16 --> BF16, shape = {3584, 2048}\n",
      "INFO:hf-to-gguf:blk.2.attn_output.weight,          torch.bfloat16 --> BF16, shape = {4096, 3584}\n",
      "INFO:hf-to-gguf:blk.2.attn_q.weight,               torch.bfloat16 --> BF16, shape = {3584, 4096}\n",
      "INFO:hf-to-gguf:blk.2.attn_v.weight,               torch.bfloat16 --> BF16, shape = {3584, 2048}\n",
      "INFO:hf-to-gguf:blk.3.attn_norm.weight,            torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.3.ffn_down.weight,             torch.bfloat16 --> BF16, shape = {14336, 3584}\n",
      "INFO:hf-to-gguf:blk.3.ffn_gate.weight,             torch.bfloat16 --> BF16, shape = {3584, 14336}\n",
      "INFO:hf-to-gguf:blk.3.ffn_up.weight,               torch.bfloat16 --> BF16, shape = {3584, 14336}\n",
      "INFO:hf-to-gguf:blk.3.post_attention_norm.weight,  torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.3.post_ffw_norm.weight,        torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.3.ffn_norm.weight,             torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.3.attn_k.weight,               torch.bfloat16 --> BF16, shape = {3584, 2048}\n",
      "INFO:hf-to-gguf:blk.3.attn_output.weight,          torch.bfloat16 --> BF16, shape = {4096, 3584}\n",
      "INFO:hf-to-gguf:blk.3.attn_q.weight,               torch.bfloat16 --> BF16, shape = {3584, 4096}\n",
      "INFO:hf-to-gguf:blk.3.attn_v.weight,               torch.bfloat16 --> BF16, shape = {3584, 2048}\n",
      "INFO:hf-to-gguf:blk.4.attn_norm.weight,            torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.4.ffn_down.weight,             torch.bfloat16 --> BF16, shape = {14336, 3584}\n",
      "INFO:hf-to-gguf:blk.4.ffn_gate.weight,             torch.bfloat16 --> BF16, shape = {3584, 14336}\n",
      "INFO:hf-to-gguf:blk.4.ffn_up.weight,               torch.bfloat16 --> BF16, shape = {3584, 14336}\n",
      "INFO:hf-to-gguf:blk.4.post_attention_norm.weight,  torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.4.post_ffw_norm.weight,        torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.4.ffn_norm.weight,             torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.4.attn_k.weight,               torch.bfloat16 --> BF16, shape = {3584, 2048}\n",
      "INFO:hf-to-gguf:blk.4.attn_output.weight,          torch.bfloat16 --> BF16, shape = {4096, 3584}\n",
      "INFO:hf-to-gguf:blk.4.attn_q.weight,               torch.bfloat16 --> BF16, shape = {3584, 4096}\n",
      "INFO:hf-to-gguf:blk.4.attn_v.weight,               torch.bfloat16 --> BF16, shape = {3584, 2048}\n",
      "INFO:hf-to-gguf:blk.5.attn_norm.weight,            torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.5.ffn_down.weight,             torch.bfloat16 --> BF16, shape = {14336, 3584}\n",
      "INFO:hf-to-gguf:blk.5.ffn_gate.weight,             torch.bfloat16 --> BF16, shape = {3584, 14336}\n",
      "INFO:hf-to-gguf:blk.5.ffn_up.weight,               torch.bfloat16 --> BF16, shape = {3584, 14336}\n",
      "INFO:hf-to-gguf:blk.5.post_attention_norm.weight,  torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.5.post_ffw_norm.weight,        torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.5.ffn_norm.weight,             torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.5.attn_k.weight,               torch.bfloat16 --> BF16, shape = {3584, 2048}\n",
      "INFO:hf-to-gguf:blk.5.attn_output.weight,          torch.bfloat16 --> BF16, shape = {4096, 3584}\n",
      "INFO:hf-to-gguf:blk.5.attn_q.weight,               torch.bfloat16 --> BF16, shape = {3584, 4096}\n",
      "INFO:hf-to-gguf:blk.5.attn_v.weight,               torch.bfloat16 --> BF16, shape = {3584, 2048}\n",
      "INFO:hf-to-gguf:blk.6.attn_norm.weight,            torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.6.ffn_down.weight,             torch.bfloat16 --> BF16, shape = {14336, 3584}\n",
      "INFO:hf-to-gguf:blk.6.ffn_gate.weight,             torch.bfloat16 --> BF16, shape = {3584, 14336}\n",
      "INFO:hf-to-gguf:blk.6.ffn_up.weight,               torch.bfloat16 --> BF16, shape = {3584, 14336}\n",
      "INFO:hf-to-gguf:blk.6.post_attention_norm.weight,  torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.6.post_ffw_norm.weight,        torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.6.ffn_norm.weight,             torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.6.attn_k.weight,               torch.bfloat16 --> BF16, shape = {3584, 2048}\n",
      "INFO:hf-to-gguf:blk.6.attn_output.weight,          torch.bfloat16 --> BF16, shape = {4096, 3584}\n",
      "INFO:hf-to-gguf:blk.6.attn_q.weight,               torch.bfloat16 --> BF16, shape = {3584, 4096}\n",
      "INFO:hf-to-gguf:blk.6.attn_v.weight,               torch.bfloat16 --> BF16, shape = {3584, 2048}\n",
      "INFO:hf-to-gguf:blk.7.ffn_gate.weight,             torch.bfloat16 --> BF16, shape = {3584, 14336}\n",
      "INFO:hf-to-gguf:blk.7.ffn_up.weight,               torch.bfloat16 --> BF16, shape = {3584, 14336}\n",
      "INFO:hf-to-gguf:blk.7.attn_k.weight,               torch.bfloat16 --> BF16, shape = {3584, 2048}\n",
      "INFO:hf-to-gguf:blk.7.attn_output.weight,          torch.bfloat16 --> BF16, shape = {4096, 3584}\n",
      "INFO:hf-to-gguf:blk.7.attn_q.weight,               torch.bfloat16 --> BF16, shape = {3584, 4096}\n",
      "INFO:hf-to-gguf:blk.7.attn_v.weight,               torch.bfloat16 --> BF16, shape = {3584, 2048}\n",
      "INFO:hf-to-gguf:gguf: loading model part 'model-00002-of-00004.safetensors'\n",
      "INFO:hf-to-gguf:blk.10.attn_norm.weight,           torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.10.ffn_down.weight,            torch.bfloat16 --> BF16, shape = {14336, 3584}\n",
      "INFO:hf-to-gguf:blk.10.ffn_gate.weight,            torch.bfloat16 --> BF16, shape = {3584, 14336}\n",
      "INFO:hf-to-gguf:blk.10.ffn_up.weight,              torch.bfloat16 --> BF16, shape = {3584, 14336}\n",
      "INFO:hf-to-gguf:blk.10.post_attention_norm.weight, torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.10.post_ffw_norm.weight,       torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.10.ffn_norm.weight,            torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.10.attn_k.weight,              torch.bfloat16 --> BF16, shape = {3584, 2048}\n",
      "INFO:hf-to-gguf:blk.10.attn_output.weight,         torch.bfloat16 --> BF16, shape = {4096, 3584}\n",
      "INFO:hf-to-gguf:blk.10.attn_q.weight,              torch.bfloat16 --> BF16, shape = {3584, 4096}\n",
      "INFO:hf-to-gguf:blk.10.attn_v.weight,              torch.bfloat16 --> BF16, shape = {3584, 2048}\n",
      "INFO:hf-to-gguf:blk.11.attn_norm.weight,           torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.11.ffn_down.weight,            torch.bfloat16 --> BF16, shape = {14336, 3584}\n",
      "INFO:hf-to-gguf:blk.11.ffn_gate.weight,            torch.bfloat16 --> BF16, shape = {3584, 14336}\n",
      "INFO:hf-to-gguf:blk.11.ffn_up.weight,              torch.bfloat16 --> BF16, shape = {3584, 14336}\n",
      "INFO:hf-to-gguf:blk.11.post_attention_norm.weight, torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.11.post_ffw_norm.weight,       torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.11.ffn_norm.weight,            torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.11.attn_k.weight,              torch.bfloat16 --> BF16, shape = {3584, 2048}\n",
      "INFO:hf-to-gguf:blk.11.attn_output.weight,         torch.bfloat16 --> BF16, shape = {4096, 3584}\n",
      "INFO:hf-to-gguf:blk.11.attn_q.weight,              torch.bfloat16 --> BF16, shape = {3584, 4096}\n",
      "INFO:hf-to-gguf:blk.11.attn_v.weight,              torch.bfloat16 --> BF16, shape = {3584, 2048}\n",
      "INFO:hf-to-gguf:blk.12.attn_norm.weight,           torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.12.ffn_down.weight,            torch.bfloat16 --> BF16, shape = {14336, 3584}\n",
      "INFO:hf-to-gguf:blk.12.ffn_gate.weight,            torch.bfloat16 --> BF16, shape = {3584, 14336}\n",
      "INFO:hf-to-gguf:blk.12.ffn_up.weight,              torch.bfloat16 --> BF16, shape = {3584, 14336}\n",
      "INFO:hf-to-gguf:blk.12.post_attention_norm.weight, torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.12.post_ffw_norm.weight,       torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.12.ffn_norm.weight,            torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.12.attn_k.weight,              torch.bfloat16 --> BF16, shape = {3584, 2048}\n",
      "INFO:hf-to-gguf:blk.12.attn_output.weight,         torch.bfloat16 --> BF16, shape = {4096, 3584}\n",
      "INFO:hf-to-gguf:blk.12.attn_q.weight,              torch.bfloat16 --> BF16, shape = {3584, 4096}\n",
      "INFO:hf-to-gguf:blk.12.attn_v.weight,              torch.bfloat16 --> BF16, shape = {3584, 2048}\n",
      "INFO:hf-to-gguf:blk.13.attn_norm.weight,           torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.13.ffn_down.weight,            torch.bfloat16 --> BF16, shape = {14336, 3584}\n",
      "INFO:hf-to-gguf:blk.13.ffn_gate.weight,            torch.bfloat16 --> BF16, shape = {3584, 14336}\n",
      "INFO:hf-to-gguf:blk.13.ffn_up.weight,              torch.bfloat16 --> BF16, shape = {3584, 14336}\n",
      "INFO:hf-to-gguf:blk.13.post_attention_norm.weight, torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.13.post_ffw_norm.weight,       torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.13.ffn_norm.weight,            torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.13.attn_k.weight,              torch.bfloat16 --> BF16, shape = {3584, 2048}\n",
      "INFO:hf-to-gguf:blk.13.attn_output.weight,         torch.bfloat16 --> BF16, shape = {4096, 3584}\n",
      "INFO:hf-to-gguf:blk.13.attn_q.weight,              torch.bfloat16 --> BF16, shape = {3584, 4096}\n",
      "INFO:hf-to-gguf:blk.13.attn_v.weight,              torch.bfloat16 --> BF16, shape = {3584, 2048}\n",
      "INFO:hf-to-gguf:blk.14.attn_norm.weight,           torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.14.ffn_down.weight,            torch.bfloat16 --> BF16, shape = {14336, 3584}\n",
      "INFO:hf-to-gguf:blk.14.ffn_gate.weight,            torch.bfloat16 --> BF16, shape = {3584, 14336}\n",
      "INFO:hf-to-gguf:blk.14.ffn_up.weight,              torch.bfloat16 --> BF16, shape = {3584, 14336}\n",
      "INFO:hf-to-gguf:blk.14.post_attention_norm.weight, torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.14.post_ffw_norm.weight,       torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.14.ffn_norm.weight,            torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.14.attn_k.weight,              torch.bfloat16 --> BF16, shape = {3584, 2048}\n",
      "INFO:hf-to-gguf:blk.14.attn_output.weight,         torch.bfloat16 --> BF16, shape = {4096, 3584}\n",
      "INFO:hf-to-gguf:blk.14.attn_q.weight,              torch.bfloat16 --> BF16, shape = {3584, 4096}\n",
      "INFO:hf-to-gguf:blk.14.attn_v.weight,              torch.bfloat16 --> BF16, shape = {3584, 2048}\n",
      "INFO:hf-to-gguf:blk.15.attn_norm.weight,           torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.15.ffn_down.weight,            torch.bfloat16 --> BF16, shape = {14336, 3584}\n",
      "INFO:hf-to-gguf:blk.15.ffn_gate.weight,            torch.bfloat16 --> BF16, shape = {3584, 14336}\n",
      "INFO:hf-to-gguf:blk.15.ffn_up.weight,              torch.bfloat16 --> BF16, shape = {3584, 14336}\n",
      "INFO:hf-to-gguf:blk.15.post_attention_norm.weight, torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.15.post_ffw_norm.weight,       torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.15.ffn_norm.weight,            torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.15.attn_k.weight,              torch.bfloat16 --> BF16, shape = {3584, 2048}\n",
      "INFO:hf-to-gguf:blk.15.attn_output.weight,         torch.bfloat16 --> BF16, shape = {4096, 3584}\n",
      "INFO:hf-to-gguf:blk.15.attn_q.weight,              torch.bfloat16 --> BF16, shape = {3584, 4096}\n",
      "INFO:hf-to-gguf:blk.15.attn_v.weight,              torch.bfloat16 --> BF16, shape = {3584, 2048}\n",
      "INFO:hf-to-gguf:blk.16.attn_norm.weight,           torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.16.ffn_down.weight,            torch.bfloat16 --> BF16, shape = {14336, 3584}\n",
      "INFO:hf-to-gguf:blk.16.ffn_gate.weight,            torch.bfloat16 --> BF16, shape = {3584, 14336}\n",
      "INFO:hf-to-gguf:blk.16.ffn_up.weight,              torch.bfloat16 --> BF16, shape = {3584, 14336}\n",
      "INFO:hf-to-gguf:blk.16.post_attention_norm.weight, torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.16.post_ffw_norm.weight,       torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.16.ffn_norm.weight,            torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.16.attn_k.weight,              torch.bfloat16 --> BF16, shape = {3584, 2048}\n",
      "INFO:hf-to-gguf:blk.16.attn_output.weight,         torch.bfloat16 --> BF16, shape = {4096, 3584}\n",
      "INFO:hf-to-gguf:blk.16.attn_q.weight,              torch.bfloat16 --> BF16, shape = {3584, 4096}\n",
      "INFO:hf-to-gguf:blk.16.attn_v.weight,              torch.bfloat16 --> BF16, shape = {3584, 2048}\n",
      "INFO:hf-to-gguf:blk.17.attn_norm.weight,           torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.17.ffn_down.weight,            torch.bfloat16 --> BF16, shape = {14336, 3584}\n",
      "INFO:hf-to-gguf:blk.17.ffn_gate.weight,            torch.bfloat16 --> BF16, shape = {3584, 14336}\n",
      "INFO:hf-to-gguf:blk.17.ffn_up.weight,              torch.bfloat16 --> BF16, shape = {3584, 14336}\n",
      "INFO:hf-to-gguf:blk.17.post_attention_norm.weight, torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.17.post_ffw_norm.weight,       torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.17.ffn_norm.weight,            torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.17.attn_k.weight,              torch.bfloat16 --> BF16, shape = {3584, 2048}\n",
      "INFO:hf-to-gguf:blk.17.attn_output.weight,         torch.bfloat16 --> BF16, shape = {4096, 3584}\n",
      "INFO:hf-to-gguf:blk.17.attn_q.weight,              torch.bfloat16 --> BF16, shape = {3584, 4096}\n",
      "INFO:hf-to-gguf:blk.17.attn_v.weight,              torch.bfloat16 --> BF16, shape = {3584, 2048}\n",
      "INFO:hf-to-gguf:blk.18.attn_norm.weight,           torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.18.ffn_down.weight,            torch.bfloat16 --> BF16, shape = {14336, 3584}\n",
      "INFO:hf-to-gguf:blk.18.ffn_gate.weight,            torch.bfloat16 --> BF16, shape = {3584, 14336}\n",
      "INFO:hf-to-gguf:blk.18.ffn_up.weight,              torch.bfloat16 --> BF16, shape = {3584, 14336}\n",
      "INFO:hf-to-gguf:blk.18.post_attention_norm.weight, torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.18.post_ffw_norm.weight,       torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.18.ffn_norm.weight,            torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.18.attn_k.weight,              torch.bfloat16 --> BF16, shape = {3584, 2048}\n",
      "INFO:hf-to-gguf:blk.18.attn_output.weight,         torch.bfloat16 --> BF16, shape = {4096, 3584}\n",
      "INFO:hf-to-gguf:blk.18.attn_q.weight,              torch.bfloat16 --> BF16, shape = {3584, 4096}\n",
      "INFO:hf-to-gguf:blk.18.attn_v.weight,              torch.bfloat16 --> BF16, shape = {3584, 2048}\n",
      "INFO:hf-to-gguf:blk.19.attn_norm.weight,           torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.19.ffn_down.weight,            torch.bfloat16 --> BF16, shape = {14336, 3584}\n",
      "INFO:hf-to-gguf:blk.19.ffn_gate.weight,            torch.bfloat16 --> BF16, shape = {3584, 14336}\n",
      "INFO:hf-to-gguf:blk.19.ffn_up.weight,              torch.bfloat16 --> BF16, shape = {3584, 14336}\n",
      "INFO:hf-to-gguf:blk.19.post_attention_norm.weight, torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.19.post_ffw_norm.weight,       torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.19.ffn_norm.weight,            torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.19.attn_k.weight,              torch.bfloat16 --> BF16, shape = {3584, 2048}\n",
      "INFO:hf-to-gguf:blk.19.attn_output.weight,         torch.bfloat16 --> BF16, shape = {4096, 3584}\n",
      "INFO:hf-to-gguf:blk.19.attn_q.weight,              torch.bfloat16 --> BF16, shape = {3584, 4096}\n",
      "INFO:hf-to-gguf:blk.19.attn_v.weight,              torch.bfloat16 --> BF16, shape = {3584, 2048}\n",
      "INFO:hf-to-gguf:blk.20.attn_k.weight,              torch.bfloat16 --> BF16, shape = {3584, 2048}\n",
      "INFO:hf-to-gguf:blk.20.attn_output.weight,         torch.bfloat16 --> BF16, shape = {4096, 3584}\n",
      "INFO:hf-to-gguf:blk.20.attn_q.weight,              torch.bfloat16 --> BF16, shape = {3584, 4096}\n",
      "INFO:hf-to-gguf:blk.20.attn_v.weight,              torch.bfloat16 --> BF16, shape = {3584, 2048}\n",
      "INFO:hf-to-gguf:blk.7.attn_norm.weight,            torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.7.ffn_down.weight,             torch.bfloat16 --> BF16, shape = {14336, 3584}\n",
      "INFO:hf-to-gguf:blk.7.post_attention_norm.weight,  torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.7.post_ffw_norm.weight,        torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.7.ffn_norm.weight,             torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.8.attn_norm.weight,            torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.8.ffn_down.weight,             torch.bfloat16 --> BF16, shape = {14336, 3584}\n",
      "INFO:hf-to-gguf:blk.8.ffn_gate.weight,             torch.bfloat16 --> BF16, shape = {3584, 14336}\n",
      "INFO:hf-to-gguf:blk.8.ffn_up.weight,               torch.bfloat16 --> BF16, shape = {3584, 14336}\n",
      "INFO:hf-to-gguf:blk.8.post_attention_norm.weight,  torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.8.post_ffw_norm.weight,        torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.8.ffn_norm.weight,             torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.8.attn_k.weight,               torch.bfloat16 --> BF16, shape = {3584, 2048}\n",
      "INFO:hf-to-gguf:blk.8.attn_output.weight,          torch.bfloat16 --> BF16, shape = {4096, 3584}\n",
      "INFO:hf-to-gguf:blk.8.attn_q.weight,               torch.bfloat16 --> BF16, shape = {3584, 4096}\n",
      "INFO:hf-to-gguf:blk.8.attn_v.weight,               torch.bfloat16 --> BF16, shape = {3584, 2048}\n",
      "INFO:hf-to-gguf:blk.9.attn_norm.weight,            torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.9.ffn_down.weight,             torch.bfloat16 --> BF16, shape = {14336, 3584}\n",
      "INFO:hf-to-gguf:blk.9.ffn_gate.weight,             torch.bfloat16 --> BF16, shape = {3584, 14336}\n",
      "INFO:hf-to-gguf:blk.9.ffn_up.weight,               torch.bfloat16 --> BF16, shape = {3584, 14336}\n",
      "INFO:hf-to-gguf:blk.9.post_attention_norm.weight,  torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.9.post_ffw_norm.weight,        torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.9.ffn_norm.weight,             torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.9.attn_k.weight,               torch.bfloat16 --> BF16, shape = {3584, 2048}\n",
      "INFO:hf-to-gguf:blk.9.attn_output.weight,          torch.bfloat16 --> BF16, shape = {4096, 3584}\n",
      "INFO:hf-to-gguf:blk.9.attn_q.weight,               torch.bfloat16 --> BF16, shape = {3584, 4096}\n",
      "INFO:hf-to-gguf:blk.9.attn_v.weight,               torch.bfloat16 --> BF16, shape = {3584, 2048}\n",
      "INFO:hf-to-gguf:gguf: loading model part 'model-00003-of-00004.safetensors'\n",
      "INFO:hf-to-gguf:blk.20.attn_norm.weight,           torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.20.ffn_down.weight,            torch.bfloat16 --> BF16, shape = {14336, 3584}\n",
      "INFO:hf-to-gguf:blk.20.ffn_gate.weight,            torch.bfloat16 --> BF16, shape = {3584, 14336}\n",
      "INFO:hf-to-gguf:blk.20.ffn_up.weight,              torch.bfloat16 --> BF16, shape = {3584, 14336}\n",
      "INFO:hf-to-gguf:blk.20.post_attention_norm.weight, torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.20.post_ffw_norm.weight,       torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.20.ffn_norm.weight,            torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.21.attn_norm.weight,           torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.21.ffn_down.weight,            torch.bfloat16 --> BF16, shape = {14336, 3584}\n",
      "INFO:hf-to-gguf:blk.21.ffn_gate.weight,            torch.bfloat16 --> BF16, shape = {3584, 14336}\n",
      "INFO:hf-to-gguf:blk.21.ffn_up.weight,              torch.bfloat16 --> BF16, shape = {3584, 14336}\n",
      "INFO:hf-to-gguf:blk.21.post_attention_norm.weight, torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.21.post_ffw_norm.weight,       torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.21.ffn_norm.weight,            torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.21.attn_k.weight,              torch.bfloat16 --> BF16, shape = {3584, 2048}\n",
      "INFO:hf-to-gguf:blk.21.attn_output.weight,         torch.bfloat16 --> BF16, shape = {4096, 3584}\n",
      "INFO:hf-to-gguf:blk.21.attn_q.weight,              torch.bfloat16 --> BF16, shape = {3584, 4096}\n",
      "INFO:hf-to-gguf:blk.21.attn_v.weight,              torch.bfloat16 --> BF16, shape = {3584, 2048}\n",
      "INFO:hf-to-gguf:blk.22.attn_norm.weight,           torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.22.ffn_down.weight,            torch.bfloat16 --> BF16, shape = {14336, 3584}\n",
      "INFO:hf-to-gguf:blk.22.ffn_gate.weight,            torch.bfloat16 --> BF16, shape = {3584, 14336}\n",
      "INFO:hf-to-gguf:blk.22.ffn_up.weight,              torch.bfloat16 --> BF16, shape = {3584, 14336}\n",
      "INFO:hf-to-gguf:blk.22.post_attention_norm.weight, torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.22.post_ffw_norm.weight,       torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.22.ffn_norm.weight,            torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.22.attn_k.weight,              torch.bfloat16 --> BF16, shape = {3584, 2048}\n",
      "INFO:hf-to-gguf:blk.22.attn_output.weight,         torch.bfloat16 --> BF16, shape = {4096, 3584}\n",
      "INFO:hf-to-gguf:blk.22.attn_q.weight,              torch.bfloat16 --> BF16, shape = {3584, 4096}\n",
      "INFO:hf-to-gguf:blk.22.attn_v.weight,              torch.bfloat16 --> BF16, shape = {3584, 2048}\n",
      "INFO:hf-to-gguf:blk.23.attn_norm.weight,           torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.23.ffn_down.weight,            torch.bfloat16 --> BF16, shape = {14336, 3584}\n",
      "INFO:hf-to-gguf:blk.23.ffn_gate.weight,            torch.bfloat16 --> BF16, shape = {3584, 14336}\n",
      "INFO:hf-to-gguf:blk.23.ffn_up.weight,              torch.bfloat16 --> BF16, shape = {3584, 14336}\n",
      "INFO:hf-to-gguf:blk.23.post_attention_norm.weight, torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.23.post_ffw_norm.weight,       torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.23.ffn_norm.weight,            torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.23.attn_k.weight,              torch.bfloat16 --> BF16, shape = {3584, 2048}\n",
      "INFO:hf-to-gguf:blk.23.attn_output.weight,         torch.bfloat16 --> BF16, shape = {4096, 3584}\n",
      "INFO:hf-to-gguf:blk.23.attn_q.weight,              torch.bfloat16 --> BF16, shape = {3584, 4096}\n",
      "INFO:hf-to-gguf:blk.23.attn_v.weight,              torch.bfloat16 --> BF16, shape = {3584, 2048}\n",
      "INFO:hf-to-gguf:blk.24.attn_norm.weight,           torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.24.ffn_down.weight,            torch.bfloat16 --> BF16, shape = {14336, 3584}\n",
      "INFO:hf-to-gguf:blk.24.ffn_gate.weight,            torch.bfloat16 --> BF16, shape = {3584, 14336}\n",
      "INFO:hf-to-gguf:blk.24.ffn_up.weight,              torch.bfloat16 --> BF16, shape = {3584, 14336}\n",
      "INFO:hf-to-gguf:blk.24.post_attention_norm.weight, torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.24.post_ffw_norm.weight,       torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.24.ffn_norm.weight,            torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.24.attn_k.weight,              torch.bfloat16 --> BF16, shape = {3584, 2048}\n",
      "INFO:hf-to-gguf:blk.24.attn_output.weight,         torch.bfloat16 --> BF16, shape = {4096, 3584}\n",
      "INFO:hf-to-gguf:blk.24.attn_q.weight,              torch.bfloat16 --> BF16, shape = {3584, 4096}\n",
      "INFO:hf-to-gguf:blk.24.attn_v.weight,              torch.bfloat16 --> BF16, shape = {3584, 2048}\n",
      "INFO:hf-to-gguf:blk.25.attn_norm.weight,           torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.25.ffn_down.weight,            torch.bfloat16 --> BF16, shape = {14336, 3584}\n",
      "INFO:hf-to-gguf:blk.25.ffn_gate.weight,            torch.bfloat16 --> BF16, shape = {3584, 14336}\n",
      "INFO:hf-to-gguf:blk.25.ffn_up.weight,              torch.bfloat16 --> BF16, shape = {3584, 14336}\n",
      "INFO:hf-to-gguf:blk.25.post_attention_norm.weight, torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.25.post_ffw_norm.weight,       torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.25.ffn_norm.weight,            torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.25.attn_k.weight,              torch.bfloat16 --> BF16, shape = {3584, 2048}\n",
      "INFO:hf-to-gguf:blk.25.attn_output.weight,         torch.bfloat16 --> BF16, shape = {4096, 3584}\n",
      "INFO:hf-to-gguf:blk.25.attn_q.weight,              torch.bfloat16 --> BF16, shape = {3584, 4096}\n",
      "INFO:hf-to-gguf:blk.25.attn_v.weight,              torch.bfloat16 --> BF16, shape = {3584, 2048}\n",
      "INFO:hf-to-gguf:blk.26.attn_norm.weight,           torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.26.ffn_down.weight,            torch.bfloat16 --> BF16, shape = {14336, 3584}\n",
      "INFO:hf-to-gguf:blk.26.ffn_gate.weight,            torch.bfloat16 --> BF16, shape = {3584, 14336}\n",
      "INFO:hf-to-gguf:blk.26.ffn_up.weight,              torch.bfloat16 --> BF16, shape = {3584, 14336}\n",
      "INFO:hf-to-gguf:blk.26.post_attention_norm.weight, torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.26.post_ffw_norm.weight,       torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.26.ffn_norm.weight,            torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.26.attn_k.weight,              torch.bfloat16 --> BF16, shape = {3584, 2048}\n",
      "INFO:hf-to-gguf:blk.26.attn_output.weight,         torch.bfloat16 --> BF16, shape = {4096, 3584}\n",
      "INFO:hf-to-gguf:blk.26.attn_q.weight,              torch.bfloat16 --> BF16, shape = {3584, 4096}\n",
      "INFO:hf-to-gguf:blk.26.attn_v.weight,              torch.bfloat16 --> BF16, shape = {3584, 2048}\n",
      "INFO:hf-to-gguf:blk.27.attn_norm.weight,           torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.27.ffn_down.weight,            torch.bfloat16 --> BF16, shape = {14336, 3584}\n",
      "INFO:hf-to-gguf:blk.27.ffn_gate.weight,            torch.bfloat16 --> BF16, shape = {3584, 14336}\n",
      "INFO:hf-to-gguf:blk.27.ffn_up.weight,              torch.bfloat16 --> BF16, shape = {3584, 14336}\n",
      "INFO:hf-to-gguf:blk.27.post_attention_norm.weight, torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.27.post_ffw_norm.weight,       torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.27.ffn_norm.weight,            torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.27.attn_k.weight,              torch.bfloat16 --> BF16, shape = {3584, 2048}\n",
      "INFO:hf-to-gguf:blk.27.attn_output.weight,         torch.bfloat16 --> BF16, shape = {4096, 3584}\n",
      "INFO:hf-to-gguf:blk.27.attn_q.weight,              torch.bfloat16 --> BF16, shape = {3584, 4096}\n",
      "INFO:hf-to-gguf:blk.27.attn_v.weight,              torch.bfloat16 --> BF16, shape = {3584, 2048}\n",
      "INFO:hf-to-gguf:blk.28.attn_norm.weight,           torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.28.ffn_down.weight,            torch.bfloat16 --> BF16, shape = {14336, 3584}\n",
      "INFO:hf-to-gguf:blk.28.ffn_gate.weight,            torch.bfloat16 --> BF16, shape = {3584, 14336}\n",
      "INFO:hf-to-gguf:blk.28.ffn_up.weight,              torch.bfloat16 --> BF16, shape = {3584, 14336}\n",
      "INFO:hf-to-gguf:blk.28.post_attention_norm.weight, torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.28.post_ffw_norm.weight,       torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.28.ffn_norm.weight,            torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.28.attn_k.weight,              torch.bfloat16 --> BF16, shape = {3584, 2048}\n",
      "INFO:hf-to-gguf:blk.28.attn_output.weight,         torch.bfloat16 --> BF16, shape = {4096, 3584}\n",
      "INFO:hf-to-gguf:blk.28.attn_q.weight,              torch.bfloat16 --> BF16, shape = {3584, 4096}\n",
      "INFO:hf-to-gguf:blk.28.attn_v.weight,              torch.bfloat16 --> BF16, shape = {3584, 2048}\n",
      "INFO:hf-to-gguf:blk.29.attn_norm.weight,           torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.29.ffn_down.weight,            torch.bfloat16 --> BF16, shape = {14336, 3584}\n",
      "INFO:hf-to-gguf:blk.29.ffn_gate.weight,            torch.bfloat16 --> BF16, shape = {3584, 14336}\n",
      "INFO:hf-to-gguf:blk.29.ffn_up.weight,              torch.bfloat16 --> BF16, shape = {3584, 14336}\n",
      "INFO:hf-to-gguf:blk.29.post_attention_norm.weight, torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.29.post_ffw_norm.weight,       torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.29.ffn_norm.weight,            torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.29.attn_k.weight,              torch.bfloat16 --> BF16, shape = {3584, 2048}\n",
      "INFO:hf-to-gguf:blk.29.attn_output.weight,         torch.bfloat16 --> BF16, shape = {4096, 3584}\n",
      "INFO:hf-to-gguf:blk.29.attn_q.weight,              torch.bfloat16 --> BF16, shape = {3584, 4096}\n",
      "INFO:hf-to-gguf:blk.29.attn_v.weight,              torch.bfloat16 --> BF16, shape = {3584, 2048}\n",
      "INFO:hf-to-gguf:blk.30.attn_norm.weight,           torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.30.ffn_down.weight,            torch.bfloat16 --> BF16, shape = {14336, 3584}\n",
      "INFO:hf-to-gguf:blk.30.ffn_gate.weight,            torch.bfloat16 --> BF16, shape = {3584, 14336}\n",
      "INFO:hf-to-gguf:blk.30.ffn_up.weight,              torch.bfloat16 --> BF16, shape = {3584, 14336}\n",
      "INFO:hf-to-gguf:blk.30.post_attention_norm.weight, torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.30.post_ffw_norm.weight,       torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.30.ffn_norm.weight,            torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.30.attn_k.weight,              torch.bfloat16 --> BF16, shape = {3584, 2048}\n",
      "INFO:hf-to-gguf:blk.30.attn_output.weight,         torch.bfloat16 --> BF16, shape = {4096, 3584}\n",
      "INFO:hf-to-gguf:blk.30.attn_q.weight,              torch.bfloat16 --> BF16, shape = {3584, 4096}\n",
      "INFO:hf-to-gguf:blk.30.attn_v.weight,              torch.bfloat16 --> BF16, shape = {3584, 2048}\n",
      "INFO:hf-to-gguf:blk.31.attn_norm.weight,           torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.31.ffn_down.weight,            torch.bfloat16 --> BF16, shape = {14336, 3584}\n",
      "INFO:hf-to-gguf:blk.31.ffn_gate.weight,            torch.bfloat16 --> BF16, shape = {3584, 14336}\n",
      "INFO:hf-to-gguf:blk.31.ffn_up.weight,              torch.bfloat16 --> BF16, shape = {3584, 14336}\n",
      "INFO:hf-to-gguf:blk.31.post_attention_norm.weight, torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.31.post_ffw_norm.weight,       torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.31.ffn_norm.weight,            torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.31.attn_k.weight,              torch.bfloat16 --> BF16, shape = {3584, 2048}\n",
      "INFO:hf-to-gguf:blk.31.attn_output.weight,         torch.bfloat16 --> BF16, shape = {4096, 3584}\n",
      "INFO:hf-to-gguf:blk.31.attn_q.weight,              torch.bfloat16 --> BF16, shape = {3584, 4096}\n",
      "INFO:hf-to-gguf:blk.31.attn_v.weight,              torch.bfloat16 --> BF16, shape = {3584, 2048}\n",
      "INFO:hf-to-gguf:blk.32.ffn_gate.weight,            torch.bfloat16 --> BF16, shape = {3584, 14336}\n",
      "INFO:hf-to-gguf:blk.32.ffn_up.weight,              torch.bfloat16 --> BF16, shape = {3584, 14336}\n",
      "INFO:hf-to-gguf:blk.32.attn_k.weight,              torch.bfloat16 --> BF16, shape = {3584, 2048}\n",
      "INFO:hf-to-gguf:blk.32.attn_output.weight,         torch.bfloat16 --> BF16, shape = {4096, 3584}\n",
      "INFO:hf-to-gguf:blk.32.attn_q.weight,              torch.bfloat16 --> BF16, shape = {3584, 4096}\n",
      "INFO:hf-to-gguf:blk.32.attn_v.weight,              torch.bfloat16 --> BF16, shape = {3584, 2048}\n",
      "INFO:hf-to-gguf:gguf: loading model part 'model-00004-of-00004.safetensors'\n",
      "INFO:hf-to-gguf:blk.32.attn_norm.weight,           torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.32.ffn_down.weight,            torch.bfloat16 --> BF16, shape = {14336, 3584}\n",
      "INFO:hf-to-gguf:blk.32.post_attention_norm.weight, torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.32.post_ffw_norm.weight,       torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.32.ffn_norm.weight,            torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.33.attn_norm.weight,           torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.33.ffn_down.weight,            torch.bfloat16 --> BF16, shape = {14336, 3584}\n",
      "INFO:hf-to-gguf:blk.33.ffn_gate.weight,            torch.bfloat16 --> BF16, shape = {3584, 14336}\n",
      "INFO:hf-to-gguf:blk.33.ffn_up.weight,              torch.bfloat16 --> BF16, shape = {3584, 14336}\n",
      "INFO:hf-to-gguf:blk.33.post_attention_norm.weight, torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.33.post_ffw_norm.weight,       torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.33.ffn_norm.weight,            torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.33.attn_k.weight,              torch.bfloat16 --> BF16, shape = {3584, 2048}\n",
      "INFO:hf-to-gguf:blk.33.attn_output.weight,         torch.bfloat16 --> BF16, shape = {4096, 3584}\n",
      "INFO:hf-to-gguf:blk.33.attn_q.weight,              torch.bfloat16 --> BF16, shape = {3584, 4096}\n",
      "INFO:hf-to-gguf:blk.33.attn_v.weight,              torch.bfloat16 --> BF16, shape = {3584, 2048}\n",
      "INFO:hf-to-gguf:blk.34.attn_norm.weight,           torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.34.ffn_down.weight,            torch.bfloat16 --> BF16, shape = {14336, 3584}\n",
      "INFO:hf-to-gguf:blk.34.ffn_gate.weight,            torch.bfloat16 --> BF16, shape = {3584, 14336}\n",
      "INFO:hf-to-gguf:blk.34.ffn_up.weight,              torch.bfloat16 --> BF16, shape = {3584, 14336}\n",
      "INFO:hf-to-gguf:blk.34.post_attention_norm.weight, torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.34.post_ffw_norm.weight,       torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.34.ffn_norm.weight,            torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.34.attn_k.weight,              torch.bfloat16 --> BF16, shape = {3584, 2048}\n",
      "INFO:hf-to-gguf:blk.34.attn_output.weight,         torch.bfloat16 --> BF16, shape = {4096, 3584}\n",
      "INFO:hf-to-gguf:blk.34.attn_q.weight,              torch.bfloat16 --> BF16, shape = {3584, 4096}\n",
      "INFO:hf-to-gguf:blk.34.attn_v.weight,              torch.bfloat16 --> BF16, shape = {3584, 2048}\n",
      "INFO:hf-to-gguf:blk.35.attn_norm.weight,           torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.35.ffn_down.weight,            torch.bfloat16 --> BF16, shape = {14336, 3584}\n",
      "INFO:hf-to-gguf:blk.35.ffn_gate.weight,            torch.bfloat16 --> BF16, shape = {3584, 14336}\n",
      "INFO:hf-to-gguf:blk.35.ffn_up.weight,              torch.bfloat16 --> BF16, shape = {3584, 14336}\n",
      "INFO:hf-to-gguf:blk.35.post_attention_norm.weight, torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.35.post_ffw_norm.weight,       torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.35.ffn_norm.weight,            torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.35.attn_k.weight,              torch.bfloat16 --> BF16, shape = {3584, 2048}\n",
      "INFO:hf-to-gguf:blk.35.attn_output.weight,         torch.bfloat16 --> BF16, shape = {4096, 3584}\n",
      "INFO:hf-to-gguf:blk.35.attn_q.weight,              torch.bfloat16 --> BF16, shape = {3584, 4096}\n",
      "INFO:hf-to-gguf:blk.35.attn_v.weight,              torch.bfloat16 --> BF16, shape = {3584, 2048}\n",
      "INFO:hf-to-gguf:blk.36.attn_norm.weight,           torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.36.ffn_down.weight,            torch.bfloat16 --> BF16, shape = {14336, 3584}\n",
      "INFO:hf-to-gguf:blk.36.ffn_gate.weight,            torch.bfloat16 --> BF16, shape = {3584, 14336}\n",
      "INFO:hf-to-gguf:blk.36.ffn_up.weight,              torch.bfloat16 --> BF16, shape = {3584, 14336}\n",
      "INFO:hf-to-gguf:blk.36.post_attention_norm.weight, torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.36.post_ffw_norm.weight,       torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.36.ffn_norm.weight,            torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.36.attn_k.weight,              torch.bfloat16 --> BF16, shape = {3584, 2048}\n",
      "INFO:hf-to-gguf:blk.36.attn_output.weight,         torch.bfloat16 --> BF16, shape = {4096, 3584}\n",
      "INFO:hf-to-gguf:blk.36.attn_q.weight,              torch.bfloat16 --> BF16, shape = {3584, 4096}\n",
      "INFO:hf-to-gguf:blk.36.attn_v.weight,              torch.bfloat16 --> BF16, shape = {3584, 2048}\n",
      "INFO:hf-to-gguf:blk.37.attn_norm.weight,           torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.37.ffn_down.weight,            torch.bfloat16 --> BF16, shape = {14336, 3584}\n",
      "INFO:hf-to-gguf:blk.37.ffn_gate.weight,            torch.bfloat16 --> BF16, shape = {3584, 14336}\n",
      "INFO:hf-to-gguf:blk.37.ffn_up.weight,              torch.bfloat16 --> BF16, shape = {3584, 14336}\n",
      "INFO:hf-to-gguf:blk.37.post_attention_norm.weight, torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.37.post_ffw_norm.weight,       torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.37.ffn_norm.weight,            torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.37.attn_k.weight,              torch.bfloat16 --> BF16, shape = {3584, 2048}\n",
      "INFO:hf-to-gguf:blk.37.attn_output.weight,         torch.bfloat16 --> BF16, shape = {4096, 3584}\n",
      "INFO:hf-to-gguf:blk.37.attn_q.weight,              torch.bfloat16 --> BF16, shape = {3584, 4096}\n",
      "INFO:hf-to-gguf:blk.37.attn_v.weight,              torch.bfloat16 --> BF16, shape = {3584, 2048}\n",
      "INFO:hf-to-gguf:blk.38.attn_norm.weight,           torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.38.ffn_down.weight,            torch.bfloat16 --> BF16, shape = {14336, 3584}\n",
      "INFO:hf-to-gguf:blk.38.ffn_gate.weight,            torch.bfloat16 --> BF16, shape = {3584, 14336}\n",
      "INFO:hf-to-gguf:blk.38.ffn_up.weight,              torch.bfloat16 --> BF16, shape = {3584, 14336}\n",
      "INFO:hf-to-gguf:blk.38.post_attention_norm.weight, torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.38.post_ffw_norm.weight,       torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.38.ffn_norm.weight,            torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.38.attn_k.weight,              torch.bfloat16 --> BF16, shape = {3584, 2048}\n",
      "INFO:hf-to-gguf:blk.38.attn_output.weight,         torch.bfloat16 --> BF16, shape = {4096, 3584}\n",
      "INFO:hf-to-gguf:blk.38.attn_q.weight,              torch.bfloat16 --> BF16, shape = {3584, 4096}\n",
      "INFO:hf-to-gguf:blk.38.attn_v.weight,              torch.bfloat16 --> BF16, shape = {3584, 2048}\n",
      "INFO:hf-to-gguf:blk.39.attn_norm.weight,           torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.39.ffn_down.weight,            torch.bfloat16 --> BF16, shape = {14336, 3584}\n",
      "INFO:hf-to-gguf:blk.39.ffn_gate.weight,            torch.bfloat16 --> BF16, shape = {3584, 14336}\n",
      "INFO:hf-to-gguf:blk.39.ffn_up.weight,              torch.bfloat16 --> BF16, shape = {3584, 14336}\n",
      "INFO:hf-to-gguf:blk.39.post_attention_norm.weight, torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.39.post_ffw_norm.weight,       torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.39.ffn_norm.weight,            torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.39.attn_k.weight,              torch.bfloat16 --> BF16, shape = {3584, 2048}\n",
      "INFO:hf-to-gguf:blk.39.attn_output.weight,         torch.bfloat16 --> BF16, shape = {4096, 3584}\n",
      "INFO:hf-to-gguf:blk.39.attn_q.weight,              torch.bfloat16 --> BF16, shape = {3584, 4096}\n",
      "INFO:hf-to-gguf:blk.39.attn_v.weight,              torch.bfloat16 --> BF16, shape = {3584, 2048}\n",
      "INFO:hf-to-gguf:blk.40.attn_norm.weight,           torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.40.ffn_down.weight,            torch.bfloat16 --> BF16, shape = {14336, 3584}\n",
      "INFO:hf-to-gguf:blk.40.ffn_gate.weight,            torch.bfloat16 --> BF16, shape = {3584, 14336}\n",
      "INFO:hf-to-gguf:blk.40.ffn_up.weight,              torch.bfloat16 --> BF16, shape = {3584, 14336}\n",
      "INFO:hf-to-gguf:blk.40.post_attention_norm.weight, torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.40.post_ffw_norm.weight,       torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.40.ffn_norm.weight,            torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.40.attn_k.weight,              torch.bfloat16 --> BF16, shape = {3584, 2048}\n",
      "INFO:hf-to-gguf:blk.40.attn_output.weight,         torch.bfloat16 --> BF16, shape = {4096, 3584}\n",
      "INFO:hf-to-gguf:blk.40.attn_q.weight,              torch.bfloat16 --> BF16, shape = {3584, 4096}\n",
      "INFO:hf-to-gguf:blk.40.attn_v.weight,              torch.bfloat16 --> BF16, shape = {3584, 2048}\n",
      "INFO:hf-to-gguf:blk.41.attn_norm.weight,           torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.41.ffn_down.weight,            torch.bfloat16 --> BF16, shape = {14336, 3584}\n",
      "INFO:hf-to-gguf:blk.41.ffn_gate.weight,            torch.bfloat16 --> BF16, shape = {3584, 14336}\n",
      "INFO:hf-to-gguf:blk.41.ffn_up.weight,              torch.bfloat16 --> BF16, shape = {3584, 14336}\n",
      "INFO:hf-to-gguf:blk.41.post_attention_norm.weight, torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.41.post_ffw_norm.weight,       torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.41.ffn_norm.weight,            torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:blk.41.attn_k.weight,              torch.bfloat16 --> BF16, shape = {3584, 2048}\n",
      "INFO:hf-to-gguf:blk.41.attn_output.weight,         torch.bfloat16 --> BF16, shape = {4096, 3584}\n",
      "INFO:hf-to-gguf:blk.41.attn_q.weight,              torch.bfloat16 --> BF16, shape = {3584, 4096}\n",
      "INFO:hf-to-gguf:blk.41.attn_v.weight,              torch.bfloat16 --> BF16, shape = {3584, 2048}\n",
      "INFO:hf-to-gguf:output_norm.weight,                torch.bfloat16 --> F32, shape = {3584}\n",
      "INFO:hf-to-gguf:Set meta model\n",
      "INFO:hf-to-gguf:Set model parameters\n",
      "INFO:hf-to-gguf:Set model tokenizer\n",
      "INFO:gguf.vocab:Setting special token type bos to 2\n",
      "INFO:gguf.vocab:Setting special token type eos to 1\n",
      "INFO:gguf.vocab:Setting special token type unk to 3\n",
      "INFO:gguf.vocab:Setting special token type pad to 0\n",
      "INFO:gguf.vocab:Setting add_bos_token to True\n",
      "INFO:gguf.vocab:Setting add_eos_token to False\n",
      "INFO:hf-to-gguf:Set model quantization version\n",
      "INFO:gguf.gguf_writer:Writing the following files:\n",
      "INFO:gguf.gguf_writer:/content/WildBurger/group1_finetuned_gemma2_v3/unsloth.BF16.gguf: n_tensors = 464, total_size = 18.5G\n",
      "Writing: 100%|██████████| 18.5G/18.5G [01:36<00:00, 192Mbyte/s]\n",
      "INFO:hf-to-gguf:Model successfully exported to /content/WildBurger/group1_finetuned_gemma2_v3/unsloth.BF16.gguf\n",
      "Unsloth: Conversion completed! Output location: /content/WildBurger/group1_finetuned_gemma2_v3/unsloth.BF16.gguf\n",
      "Unsloth: [2] Converting GGUF 16bit into q4_1. This might take 20 minutes...\n",
      "main: build = 4925 (a9b59288)\n",
      "main: built with cc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0 for x86_64-linux-gnu\n",
      "main: quantizing '/content/WildBurger/group1_finetuned_gemma2_v3/unsloth.BF16.gguf' to '/content/WildBurger/group1_finetuned_gemma2_v3/unsloth.Q4_1.gguf' as Q4_1 using 24 threads\n",
      "llama_model_loader: loaded meta data with 32 key-value pairs and 464 tensors from /content/WildBurger/group1_finetuned_gemma2_v3/unsloth.BF16.gguf (version GGUF V3 (latest))\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = gemma2\n",
      "llama_model_loader: - kv   1:                               general.type str              = model\n",
      "llama_model_loader: - kv   2:                               general.name str              = Gemma 2 9b\n",
      "llama_model_loader: - kv   3:                       general.organization str              = Unsloth\n",
      "llama_model_loader: - kv   4:                           general.basename str              = gemma-2\n",
      "llama_model_loader: - kv   5:                         general.size_label str              = 9B\n",
      "llama_model_loader: - kv   6:                      gemma2.context_length u32              = 8192\n",
      "llama_model_loader: - kv   7:                    gemma2.embedding_length u32              = 3584\n",
      "llama_model_loader: - kv   8:                         gemma2.block_count u32              = 42\n",
      "llama_model_loader: - kv   9:                 gemma2.feed_forward_length u32              = 14336\n",
      "llama_model_loader: - kv  10:                gemma2.attention.head_count u32              = 16\n",
      "llama_model_loader: - kv  11:             gemma2.attention.head_count_kv u32              = 8\n",
      "llama_model_loader: - kv  12:    gemma2.attention.layer_norm_rms_epsilon f32              = 0.000001\n",
      "llama_model_loader: - kv  13:                gemma2.attention.key_length u32              = 256\n",
      "llama_model_loader: - kv  14:              gemma2.attention.value_length u32              = 256\n",
      "llama_model_loader: - kv  15:                          general.file_type u32              = 32\n",
      "llama_model_loader: - kv  16:              gemma2.attn_logit_softcapping f32              = 50.000000\n",
      "llama_model_loader: - kv  17:             gemma2.final_logit_softcapping f32              = 30.000000\n",
      "llama_model_loader: - kv  18:            gemma2.attention.sliding_window u32              = 4096\n",
      "llama_model_loader: - kv  19:                       tokenizer.ggml.model str              = llama\n",
      "llama_model_loader: - kv  20:                         tokenizer.ggml.pre str              = default\n",
      "llama_model_loader: - kv  21:                      tokenizer.ggml.tokens arr[str,256000]  = [\"<pad>\", \"<eos>\", \"<bos>\", \"<unk>\", ...\n",
      "llama_model_loader: - kv  22:                      tokenizer.ggml.scores arr[f32,256000]  = [-1000.000000, -1000.000000, -1000.00...\n",
      "llama_model_loader: - kv  23:                  tokenizer.ggml.token_type arr[i32,256000]  = [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, ...\n",
      "llama_model_loader: - kv  24:                tokenizer.ggml.bos_token_id u32              = 2\n",
      "llama_model_loader: - kv  25:                tokenizer.ggml.eos_token_id u32              = 1\n",
      "llama_model_loader: - kv  26:            tokenizer.ggml.unknown_token_id u32              = 3\n",
      "llama_model_loader: - kv  27:            tokenizer.ggml.padding_token_id u32              = 0\n",
      "llama_model_loader: - kv  28:               tokenizer.ggml.add_bos_token bool             = true\n",
      "llama_model_loader: - kv  29:               tokenizer.ggml.add_eos_token bool             = false\n",
      "llama_model_loader: - kv  30:            tokenizer.ggml.add_space_prefix bool             = false\n",
      "llama_model_loader: - kv  31:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - type  f32:  169 tensors\n",
      "llama_model_loader: - type bf16:  295 tensors\n",
      "[   1/ 464]                   output_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
      "[   2/ 464]                    token_embd.weight - [ 3584, 256000,     1,     1], type =   bf16, converting to q6_K .. size =  1750.00 MiB ->   717.77 MiB\n",
      "[   3/ 464]                  blk.0.attn_k.weight - [ 3584,  2048,     1,     1], type =   bf16, converting to q4_1 .. size =    14.00 MiB ->     4.38 MiB\n",
      "[   4/ 464]               blk.0.attn_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
      "[   5/ 464]             blk.0.attn_output.weight - [ 4096,  3584,     1,     1], type =   bf16, converting to q4_1 .. size =    28.00 MiB ->     8.75 MiB\n",
      "[   6/ 464]                  blk.0.attn_q.weight - [ 3584,  4096,     1,     1], type =   bf16, converting to q4_1 .. size =    28.00 MiB ->     8.75 MiB\n",
      "[   7/ 464]                  blk.0.attn_v.weight - [ 3584,  2048,     1,     1], type =   bf16, converting to q4_1 .. size =    14.00 MiB ->     4.38 MiB\n",
      "[   8/ 464]                blk.0.ffn_down.weight - [14336,  3584,     1,     1], type =   bf16, converting to q4_1 .. size =    98.00 MiB ->    30.62 MiB\n",
      "[   9/ 464]                blk.0.ffn_gate.weight - [ 3584, 14336,     1,     1], type =   bf16, converting to q4_1 .. size =    98.00 MiB ->    30.62 MiB\n",
      "[  10/ 464]                blk.0.ffn_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
      "[  11/ 464]                  blk.0.ffn_up.weight - [ 3584, 14336,     1,     1], type =   bf16, converting to q4_1 .. size =    98.00 MiB ->    30.62 MiB\n",
      "[  12/ 464]     blk.0.post_attention_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
      "[  13/ 464]           blk.0.post_ffw_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
      "[  14/ 464]                  blk.1.attn_k.weight - [ 3584,  2048,     1,     1], type =   bf16, converting to q4_1 .. size =    14.00 MiB ->     4.38 MiB\n",
      "[  15/ 464]               blk.1.attn_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
      "[  16/ 464]             blk.1.attn_output.weight - [ 4096,  3584,     1,     1], type =   bf16, converting to q4_1 .. size =    28.00 MiB ->     8.75 MiB\n",
      "[  17/ 464]                  blk.1.attn_q.weight - [ 3584,  4096,     1,     1], type =   bf16, converting to q4_1 .. size =    28.00 MiB ->     8.75 MiB\n",
      "[  18/ 464]                  blk.1.attn_v.weight - [ 3584,  2048,     1,     1], type =   bf16, converting to q4_1 .. size =    14.00 MiB ->     4.38 MiB\n",
      "[  19/ 464]                blk.1.ffn_down.weight - [14336,  3584,     1,     1], type =   bf16, converting to q4_1 .. size =    98.00 MiB ->    30.62 MiB\n",
      "[  20/ 464]                blk.1.ffn_gate.weight - [ 3584, 14336,     1,     1], type =   bf16, converting to q4_1 .. size =    98.00 MiB ->    30.62 MiB\n",
      "[  21/ 464]                blk.1.ffn_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
      "[  22/ 464]                  blk.1.ffn_up.weight - [ 3584, 14336,     1,     1], type =   bf16, converting to q4_1 .. size =    98.00 MiB ->    30.62 MiB\n",
      "[  23/ 464]     blk.1.post_attention_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
      "[  24/ 464]           blk.1.post_ffw_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
      "[  25/ 464]                  blk.2.attn_k.weight - [ 3584,  2048,     1,     1], type =   bf16, converting to q4_1 .. size =    14.00 MiB ->     4.38 MiB\n",
      "[  26/ 464]               blk.2.attn_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
      "[  27/ 464]             blk.2.attn_output.weight - [ 4096,  3584,     1,     1], type =   bf16, converting to q4_1 .. size =    28.00 MiB ->     8.75 MiB\n",
      "[  28/ 464]                  blk.2.attn_q.weight - [ 3584,  4096,     1,     1], type =   bf16, converting to q4_1 .. size =    28.00 MiB ->     8.75 MiB\n",
      "[  29/ 464]                  blk.2.attn_v.weight - [ 3584,  2048,     1,     1], type =   bf16, converting to q4_1 .. size =    14.00 MiB ->     4.38 MiB\n",
      "[  30/ 464]                blk.2.ffn_down.weight - [14336,  3584,     1,     1], type =   bf16, converting to q4_1 .. size =    98.00 MiB ->    30.62 MiB\n",
      "[  31/ 464]                blk.2.ffn_gate.weight - [ 3584, 14336,     1,     1], type =   bf16, converting to q4_1 .. size =    98.00 MiB ->    30.62 MiB\n",
      "[  32/ 464]                blk.2.ffn_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
      "[  33/ 464]                  blk.2.ffn_up.weight - [ 3584, 14336,     1,     1], type =   bf16, converting to q4_1 .. size =    98.00 MiB ->    30.62 MiB\n",
      "[  34/ 464]     blk.2.post_attention_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
      "[  35/ 464]           blk.2.post_ffw_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
      "[  36/ 464]                  blk.3.attn_k.weight - [ 3584,  2048,     1,     1], type =   bf16, converting to q4_1 .. size =    14.00 MiB ->     4.38 MiB\n",
      "[  37/ 464]               blk.3.attn_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
      "[  38/ 464]             blk.3.attn_output.weight - [ 4096,  3584,     1,     1], type =   bf16, converting to q4_1 .. size =    28.00 MiB ->     8.75 MiB\n",
      "[  39/ 464]                  blk.3.attn_q.weight - [ 3584,  4096,     1,     1], type =   bf16, converting to q4_1 .. size =    28.00 MiB ->     8.75 MiB\n",
      "[  40/ 464]                  blk.3.attn_v.weight - [ 3584,  2048,     1,     1], type =   bf16, converting to q4_1 .. size =    14.00 MiB ->     4.38 MiB\n",
      "[  41/ 464]                blk.3.ffn_down.weight - [14336,  3584,     1,     1], type =   bf16, converting to q4_1 .. size =    98.00 MiB ->    30.62 MiB\n",
      "[  42/ 464]                blk.3.ffn_gate.weight - [ 3584, 14336,     1,     1], type =   bf16, converting to q4_1 .. size =    98.00 MiB ->    30.62 MiB\n",
      "[  43/ 464]                blk.3.ffn_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
      "[  44/ 464]                  blk.3.ffn_up.weight - [ 3584, 14336,     1,     1], type =   bf16, converting to q4_1 .. size =    98.00 MiB ->    30.62 MiB\n",
      "[  45/ 464]     blk.3.post_attention_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
      "[  46/ 464]           blk.3.post_ffw_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
      "[  47/ 464]                  blk.4.attn_k.weight - [ 3584,  2048,     1,     1], type =   bf16, converting to q4_1 .. size =    14.00 MiB ->     4.38 MiB\n",
      "[  48/ 464]               blk.4.attn_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
      "[  49/ 464]             blk.4.attn_output.weight - [ 4096,  3584,     1,     1], type =   bf16, converting to q4_1 .. size =    28.00 MiB ->     8.75 MiB\n",
      "[  50/ 464]                  blk.4.attn_q.weight - [ 3584,  4096,     1,     1], type =   bf16, converting to q4_1 .. size =    28.00 MiB ->     8.75 MiB\n",
      "[  51/ 464]                  blk.4.attn_v.weight - [ 3584,  2048,     1,     1], type =   bf16, converting to q4_1 .. size =    14.00 MiB ->     4.38 MiB\n",
      "[  52/ 464]                blk.4.ffn_down.weight - [14336,  3584,     1,     1], type =   bf16, converting to q4_1 .. size =    98.00 MiB ->    30.62 MiB\n",
      "[  53/ 464]                blk.4.ffn_gate.weight - [ 3584, 14336,     1,     1], type =   bf16, converting to q4_1 .. size =    98.00 MiB ->    30.62 MiB\n",
      "[  54/ 464]                blk.4.ffn_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
      "[  55/ 464]                  blk.4.ffn_up.weight - [ 3584, 14336,     1,     1], type =   bf16, converting to q4_1 .. size =    98.00 MiB ->    30.62 MiB\n",
      "[  56/ 464]     blk.4.post_attention_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
      "[  57/ 464]           blk.4.post_ffw_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
      "[  58/ 464]                  blk.5.attn_k.weight - [ 3584,  2048,     1,     1], type =   bf16, converting to q4_1 .. size =    14.00 MiB ->     4.38 MiB\n",
      "[  59/ 464]               blk.5.attn_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
      "[  60/ 464]             blk.5.attn_output.weight - [ 4096,  3584,     1,     1], type =   bf16, converting to q4_1 .. size =    28.00 MiB ->     8.75 MiB\n",
      "[  61/ 464]                  blk.5.attn_q.weight - [ 3584,  4096,     1,     1], type =   bf16, converting to q4_1 .. size =    28.00 MiB ->     8.75 MiB\n",
      "[  62/ 464]                  blk.5.attn_v.weight - [ 3584,  2048,     1,     1], type =   bf16, converting to q4_1 .. size =    14.00 MiB ->     4.38 MiB\n",
      "[  63/ 464]                blk.5.ffn_down.weight - [14336,  3584,     1,     1], type =   bf16, converting to q4_1 .. size =    98.00 MiB ->    30.62 MiB\n",
      "[  64/ 464]                blk.5.ffn_gate.weight - [ 3584, 14336,     1,     1], type =   bf16, converting to q4_1 .. size =    98.00 MiB ->    30.62 MiB\n",
      "[  65/ 464]                blk.5.ffn_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
      "[  66/ 464]                  blk.5.ffn_up.weight - [ 3584, 14336,     1,     1], type =   bf16, converting to q4_1 .. size =    98.00 MiB ->    30.62 MiB\n",
      "[  67/ 464]     blk.5.post_attention_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
      "[  68/ 464]           blk.5.post_ffw_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
      "[  69/ 464]                  blk.6.attn_k.weight - [ 3584,  2048,     1,     1], type =   bf16, converting to q4_1 .. size =    14.00 MiB ->     4.38 MiB\n",
      "[  70/ 464]               blk.6.attn_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
      "[  71/ 464]             blk.6.attn_output.weight - [ 4096,  3584,     1,     1], type =   bf16, converting to q4_1 .. size =    28.00 MiB ->     8.75 MiB\n",
      "[  72/ 464]                  blk.6.attn_q.weight - [ 3584,  4096,     1,     1], type =   bf16, converting to q4_1 .. size =    28.00 MiB ->     8.75 MiB\n",
      "[  73/ 464]                  blk.6.attn_v.weight - [ 3584,  2048,     1,     1], type =   bf16, converting to q4_1 .. size =    14.00 MiB ->     4.38 MiB\n",
      "[  74/ 464]                blk.6.ffn_down.weight - [14336,  3584,     1,     1], type =   bf16, converting to q4_1 .. size =    98.00 MiB ->    30.62 MiB\n",
      "[  75/ 464]                blk.6.ffn_gate.weight - [ 3584, 14336,     1,     1], type =   bf16, converting to q4_1 .. size =    98.00 MiB ->    30.62 MiB\n",
      "[  76/ 464]                blk.6.ffn_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
      "[  77/ 464]                  blk.6.ffn_up.weight - [ 3584, 14336,     1,     1], type =   bf16, converting to q4_1 .. size =    98.00 MiB ->    30.62 MiB\n",
      "[  78/ 464]     blk.6.post_attention_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
      "[  79/ 464]           blk.6.post_ffw_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
      "[  80/ 464]                  blk.7.attn_k.weight - [ 3584,  2048,     1,     1], type =   bf16, converting to q4_1 .. size =    14.00 MiB ->     4.38 MiB\n",
      "[  81/ 464]               blk.7.attn_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
      "[  82/ 464]             blk.7.attn_output.weight - [ 4096,  3584,     1,     1], type =   bf16, converting to q4_1 .. size =    28.00 MiB ->     8.75 MiB\n",
      "[  83/ 464]                  blk.7.attn_q.weight - [ 3584,  4096,     1,     1], type =   bf16, converting to q4_1 .. size =    28.00 MiB ->     8.75 MiB\n",
      "[  84/ 464]                  blk.7.attn_v.weight - [ 3584,  2048,     1,     1], type =   bf16, converting to q4_1 .. size =    14.00 MiB ->     4.38 MiB\n",
      "[  85/ 464]                blk.7.ffn_down.weight - [14336,  3584,     1,     1], type =   bf16, converting to q4_1 .. size =    98.00 MiB ->    30.62 MiB\n",
      "[  86/ 464]                blk.7.ffn_gate.weight - [ 3584, 14336,     1,     1], type =   bf16, converting to q4_1 .. size =    98.00 MiB ->    30.62 MiB\n",
      "[  87/ 464]                blk.7.ffn_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
      "[  88/ 464]                  blk.7.ffn_up.weight - [ 3584, 14336,     1,     1], type =   bf16, converting to q4_1 .. size =    98.00 MiB ->    30.62 MiB\n",
      "[  89/ 464]     blk.7.post_attention_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
      "[  90/ 464]           blk.7.post_ffw_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
      "[  91/ 464]                  blk.8.attn_k.weight - [ 3584,  2048,     1,     1], type =   bf16, converting to q4_1 .. size =    14.00 MiB ->     4.38 MiB\n",
      "[  92/ 464]               blk.8.attn_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
      "[  93/ 464]             blk.8.attn_output.weight - [ 4096,  3584,     1,     1], type =   bf16, converting to q4_1 .. size =    28.00 MiB ->     8.75 MiB\n",
      "[  94/ 464]                  blk.8.attn_q.weight - [ 3584,  4096,     1,     1], type =   bf16, converting to q4_1 .. size =    28.00 MiB ->     8.75 MiB\n",
      "[  95/ 464]                  blk.8.attn_v.weight - [ 3584,  2048,     1,     1], type =   bf16, converting to q4_1 .. size =    14.00 MiB ->     4.38 MiB\n",
      "[  96/ 464]                blk.8.ffn_down.weight - [14336,  3584,     1,     1], type =   bf16, converting to q4_1 .. size =    98.00 MiB ->    30.62 MiB\n",
      "[  97/ 464]                blk.8.ffn_gate.weight - [ 3584, 14336,     1,     1], type =   bf16, converting to q4_1 .. size =    98.00 MiB ->    30.62 MiB\n",
      "[  98/ 464]                blk.8.ffn_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
      "[  99/ 464]                  blk.8.ffn_up.weight - [ 3584, 14336,     1,     1], type =   bf16, converting to q4_1 .. size =    98.00 MiB ->    30.62 MiB\n",
      "[ 100/ 464]     blk.8.post_attention_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
      "[ 101/ 464]           blk.8.post_ffw_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
      "[ 102/ 464]                  blk.9.attn_k.weight - [ 3584,  2048,     1,     1], type =   bf16, converting to q4_1 .. size =    14.00 MiB ->     4.38 MiB\n",
      "[ 103/ 464]               blk.9.attn_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
      "[ 104/ 464]             blk.9.attn_output.weight - [ 4096,  3584,     1,     1], type =   bf16, converting to q4_1 .. size =    28.00 MiB ->     8.75 MiB\n",
      "[ 105/ 464]                  blk.9.attn_q.weight - [ 3584,  4096,     1,     1], type =   bf16, converting to q4_1 .. size =    28.00 MiB ->     8.75 MiB\n",
      "[ 106/ 464]                  blk.9.attn_v.weight - [ 3584,  2048,     1,     1], type =   bf16, converting to q4_1 .. size =    14.00 MiB ->     4.38 MiB\n",
      "[ 107/ 464]                blk.9.ffn_down.weight - [14336,  3584,     1,     1], type =   bf16, converting to q4_1 .. size =    98.00 MiB ->    30.62 MiB\n",
      "[ 108/ 464]                blk.9.ffn_gate.weight - [ 3584, 14336,     1,     1], type =   bf16, converting to q4_1 .. size =    98.00 MiB ->    30.62 MiB\n",
      "[ 109/ 464]                blk.9.ffn_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
      "[ 110/ 464]                  blk.9.ffn_up.weight - [ 3584, 14336,     1,     1], type =   bf16, converting to q4_1 .. size =    98.00 MiB ->    30.62 MiB\n",
      "[ 111/ 464]     blk.9.post_attention_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
      "[ 112/ 464]           blk.9.post_ffw_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
      "[ 113/ 464]                 blk.10.attn_k.weight - [ 3584,  2048,     1,     1], type =   bf16, converting to q4_1 .. size =    14.00 MiB ->     4.38 MiB\n",
      "[ 114/ 464]              blk.10.attn_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
      "[ 115/ 464]            blk.10.attn_output.weight - [ 4096,  3584,     1,     1], type =   bf16, converting to q4_1 .. size =    28.00 MiB ->     8.75 MiB\n",
      "[ 116/ 464]                 blk.10.attn_q.weight - [ 3584,  4096,     1,     1], type =   bf16, converting to q4_1 .. size =    28.00 MiB ->     8.75 MiB\n",
      "[ 117/ 464]                 blk.10.attn_v.weight - [ 3584,  2048,     1,     1], type =   bf16, converting to q4_1 .. size =    14.00 MiB ->     4.38 MiB\n",
      "[ 118/ 464]               blk.10.ffn_down.weight - [14336,  3584,     1,     1], type =   bf16, converting to q4_1 .. size =    98.00 MiB ->    30.62 MiB\n",
      "[ 119/ 464]               blk.10.ffn_gate.weight - [ 3584, 14336,     1,     1], type =   bf16, converting to q4_1 .. size =    98.00 MiB ->    30.62 MiB\n",
      "[ 120/ 464]               blk.10.ffn_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
      "[ 121/ 464]                 blk.10.ffn_up.weight - [ 3584, 14336,     1,     1], type =   bf16, converting to q4_1 .. size =    98.00 MiB ->    30.62 MiB\n",
      "[ 122/ 464]    blk.10.post_attention_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
      "[ 123/ 464]          blk.10.post_ffw_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
      "[ 124/ 464]                 blk.11.attn_k.weight - [ 3584,  2048,     1,     1], type =   bf16, converting to q4_1 .. size =    14.00 MiB ->     4.38 MiB\n",
      "[ 125/ 464]              blk.11.attn_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
      "[ 126/ 464]            blk.11.attn_output.weight - [ 4096,  3584,     1,     1], type =   bf16, converting to q4_1 .. size =    28.00 MiB ->     8.75 MiB\n",
      "[ 127/ 464]                 blk.11.attn_q.weight - [ 3584,  4096,     1,     1], type =   bf16, converting to q4_1 .. size =    28.00 MiB ->     8.75 MiB\n",
      "[ 128/ 464]                 blk.11.attn_v.weight - [ 3584,  2048,     1,     1], type =   bf16, converting to q4_1 .. size =    14.00 MiB ->     4.38 MiB\n",
      "[ 129/ 464]               blk.11.ffn_down.weight - [14336,  3584,     1,     1], type =   bf16, converting to q4_1 .. size =    98.00 MiB ->    30.62 MiB\n",
      "[ 130/ 464]               blk.11.ffn_gate.weight - [ 3584, 14336,     1,     1], type =   bf16, converting to q4_1 .. size =    98.00 MiB ->    30.62 MiB\n",
      "[ 131/ 464]               blk.11.ffn_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
      "[ 132/ 464]                 blk.11.ffn_up.weight - [ 3584, 14336,     1,     1], type =   bf16, converting to q4_1 .. size =    98.00 MiB ->    30.62 MiB\n",
      "[ 133/ 464]    blk.11.post_attention_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
      "[ 134/ 464]          blk.11.post_ffw_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
      "[ 135/ 464]                 blk.12.attn_k.weight - [ 3584,  2048,     1,     1], type =   bf16, converting to q4_1 .. size =    14.00 MiB ->     4.38 MiB\n",
      "[ 136/ 464]              blk.12.attn_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
      "[ 137/ 464]            blk.12.attn_output.weight - [ 4096,  3584,     1,     1], type =   bf16, converting to q4_1 .. size =    28.00 MiB ->     8.75 MiB\n",
      "[ 138/ 464]                 blk.12.attn_q.weight - [ 3584,  4096,     1,     1], type =   bf16, converting to q4_1 .. size =    28.00 MiB ->     8.75 MiB\n",
      "[ 139/ 464]                 blk.12.attn_v.weight - [ 3584,  2048,     1,     1], type =   bf16, converting to q4_1 .. size =    14.00 MiB ->     4.38 MiB\n",
      "[ 140/ 464]               blk.12.ffn_down.weight - [14336,  3584,     1,     1], type =   bf16, converting to q4_1 .. size =    98.00 MiB ->    30.62 MiB\n",
      "[ 141/ 464]               blk.12.ffn_gate.weight - [ 3584, 14336,     1,     1], type =   bf16, converting to q4_1 .. size =    98.00 MiB ->    30.62 MiB\n",
      "[ 142/ 464]               blk.12.ffn_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
      "[ 143/ 464]                 blk.12.ffn_up.weight - [ 3584, 14336,     1,     1], type =   bf16, converting to q4_1 .. size =    98.00 MiB ->    30.62 MiB\n",
      "[ 144/ 464]    blk.12.post_attention_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
      "[ 145/ 464]          blk.12.post_ffw_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
      "[ 146/ 464]                 blk.13.attn_k.weight - [ 3584,  2048,     1,     1], type =   bf16, converting to q4_1 .. size =    14.00 MiB ->     4.38 MiB\n",
      "[ 147/ 464]              blk.13.attn_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
      "[ 148/ 464]            blk.13.attn_output.weight - [ 4096,  3584,     1,     1], type =   bf16, converting to q4_1 .. size =    28.00 MiB ->     8.75 MiB\n",
      "[ 149/ 464]                 blk.13.attn_q.weight - [ 3584,  4096,     1,     1], type =   bf16, converting to q4_1 .. size =    28.00 MiB ->     8.75 MiB\n",
      "[ 150/ 464]                 blk.13.attn_v.weight - [ 3584,  2048,     1,     1], type =   bf16, converting to q4_1 .. size =    14.00 MiB ->     4.38 MiB\n",
      "[ 151/ 464]               blk.13.ffn_down.weight - [14336,  3584,     1,     1], type =   bf16, converting to q4_1 .. size =    98.00 MiB ->    30.62 MiB\n",
      "[ 152/ 464]               blk.13.ffn_gate.weight - [ 3584, 14336,     1,     1], type =   bf16, converting to q4_1 .. size =    98.00 MiB ->    30.62 MiB\n",
      "[ 153/ 464]               blk.13.ffn_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
      "[ 154/ 464]                 blk.13.ffn_up.weight - [ 3584, 14336,     1,     1], type =   bf16, converting to q4_1 .. size =    98.00 MiB ->    30.62 MiB\n",
      "[ 155/ 464]    blk.13.post_attention_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
      "[ 156/ 464]          blk.13.post_ffw_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
      "[ 157/ 464]                 blk.14.attn_k.weight - [ 3584,  2048,     1,     1], type =   bf16, converting to q4_1 .. size =    14.00 MiB ->     4.38 MiB\n",
      "[ 158/ 464]              blk.14.attn_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
      "[ 159/ 464]            blk.14.attn_output.weight - [ 4096,  3584,     1,     1], type =   bf16, converting to q4_1 .. size =    28.00 MiB ->     8.75 MiB\n",
      "[ 160/ 464]                 blk.14.attn_q.weight - [ 3584,  4096,     1,     1], type =   bf16, converting to q4_1 .. size =    28.00 MiB ->     8.75 MiB\n",
      "[ 161/ 464]                 blk.14.attn_v.weight - [ 3584,  2048,     1,     1], type =   bf16, converting to q4_1 .. size =    14.00 MiB ->     4.38 MiB\n",
      "[ 162/ 464]               blk.14.ffn_down.weight - [14336,  3584,     1,     1], type =   bf16, converting to q4_1 .. size =    98.00 MiB ->    30.62 MiB\n",
      "[ 163/ 464]               blk.14.ffn_gate.weight - [ 3584, 14336,     1,     1], type =   bf16, converting to q4_1 .. size =    98.00 MiB ->    30.62 MiB\n",
      "[ 164/ 464]               blk.14.ffn_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
      "[ 165/ 464]                 blk.14.ffn_up.weight - [ 3584, 14336,     1,     1], type =   bf16, converting to q4_1 .. size =    98.00 MiB ->    30.62 MiB\n",
      "[ 166/ 464]    blk.14.post_attention_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
      "[ 167/ 464]          blk.14.post_ffw_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
      "[ 168/ 464]                 blk.15.attn_k.weight - [ 3584,  2048,     1,     1], type =   bf16, converting to q4_1 .. size =    14.00 MiB ->     4.38 MiB\n",
      "[ 169/ 464]              blk.15.attn_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
      "[ 170/ 464]            blk.15.attn_output.weight - [ 4096,  3584,     1,     1], type =   bf16, converting to q4_1 .. size =    28.00 MiB ->     8.75 MiB\n",
      "[ 171/ 464]                 blk.15.attn_q.weight - [ 3584,  4096,     1,     1], type =   bf16, converting to q4_1 .. size =    28.00 MiB ->     8.75 MiB\n",
      "[ 172/ 464]                 blk.15.attn_v.weight - [ 3584,  2048,     1,     1], type =   bf16, converting to q4_1 .. size =    14.00 MiB ->     4.38 MiB\n",
      "[ 173/ 464]               blk.15.ffn_down.weight - [14336,  3584,     1,     1], type =   bf16, converting to q4_1 .. size =    98.00 MiB ->    30.62 MiB\n",
      "[ 174/ 464]               blk.15.ffn_gate.weight - [ 3584, 14336,     1,     1], type =   bf16, converting to q4_1 .. size =    98.00 MiB ->    30.62 MiB\n",
      "[ 175/ 464]               blk.15.ffn_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
      "[ 176/ 464]                 blk.15.ffn_up.weight - [ 3584, 14336,     1,     1], type =   bf16, converting to q4_1 .. size =    98.00 MiB ->    30.62 MiB\n",
      "[ 177/ 464]    blk.15.post_attention_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
      "[ 178/ 464]          blk.15.post_ffw_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
      "[ 179/ 464]                 blk.16.attn_k.weight - [ 3584,  2048,     1,     1], type =   bf16, converting to q4_1 .. size =    14.00 MiB ->     4.38 MiB\n",
      "[ 180/ 464]              blk.16.attn_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
      "[ 181/ 464]            blk.16.attn_output.weight - [ 4096,  3584,     1,     1], type =   bf16, converting to q4_1 .. size =    28.00 MiB ->     8.75 MiB\n",
      "[ 182/ 464]                 blk.16.attn_q.weight - [ 3584,  4096,     1,     1], type =   bf16, converting to q4_1 .. size =    28.00 MiB ->     8.75 MiB\n",
      "[ 183/ 464]                 blk.16.attn_v.weight - [ 3584,  2048,     1,     1], type =   bf16, converting to q4_1 .. size =    14.00 MiB ->     4.38 MiB\n",
      "[ 184/ 464]               blk.16.ffn_down.weight - [14336,  3584,     1,     1], type =   bf16, converting to q4_1 .. size =    98.00 MiB ->    30.62 MiB\n",
      "[ 185/ 464]               blk.16.ffn_gate.weight - [ 3584, 14336,     1,     1], type =   bf16, converting to q4_1 .. size =    98.00 MiB ->    30.62 MiB\n",
      "[ 186/ 464]               blk.16.ffn_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
      "[ 187/ 464]                 blk.16.ffn_up.weight - [ 3584, 14336,     1,     1], type =   bf16, converting to q4_1 .. size =    98.00 MiB ->    30.62 MiB\n",
      "[ 188/ 464]    blk.16.post_attention_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
      "[ 189/ 464]          blk.16.post_ffw_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
      "[ 190/ 464]                 blk.17.attn_k.weight - [ 3584,  2048,     1,     1], type =   bf16, converting to q4_1 .. size =    14.00 MiB ->     4.38 MiB\n",
      "[ 191/ 464]              blk.17.attn_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
      "[ 192/ 464]            blk.17.attn_output.weight - [ 4096,  3584,     1,     1], type =   bf16, converting to q4_1 .. size =    28.00 MiB ->     8.75 MiB\n",
      "[ 193/ 464]                 blk.17.attn_q.weight - [ 3584,  4096,     1,     1], type =   bf16, converting to q4_1 .. size =    28.00 MiB ->     8.75 MiB\n",
      "[ 194/ 464]                 blk.17.attn_v.weight - [ 3584,  2048,     1,     1], type =   bf16, converting to q4_1 .. size =    14.00 MiB ->     4.38 MiB\n",
      "[ 195/ 464]               blk.17.ffn_down.weight - [14336,  3584,     1,     1], type =   bf16, converting to q4_1 .. size =    98.00 MiB ->    30.62 MiB\n",
      "[ 196/ 464]               blk.17.ffn_gate.weight - [ 3584, 14336,     1,     1], type =   bf16, converting to q4_1 .. size =    98.00 MiB ->    30.62 MiB\n",
      "[ 197/ 464]               blk.17.ffn_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
      "[ 198/ 464]                 blk.17.ffn_up.weight - [ 3584, 14336,     1,     1], type =   bf16, converting to q4_1 .. size =    98.00 MiB ->    30.62 MiB\n",
      "[ 199/ 464]    blk.17.post_attention_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
      "[ 200/ 464]          blk.17.post_ffw_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
      "[ 201/ 464]                 blk.18.attn_k.weight - [ 3584,  2048,     1,     1], type =   bf16, converting to q4_1 .. size =    14.00 MiB ->     4.38 MiB\n",
      "[ 202/ 464]              blk.18.attn_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
      "[ 203/ 464]            blk.18.attn_output.weight - [ 4096,  3584,     1,     1], type =   bf16, converting to q4_1 .. size =    28.00 MiB ->     8.75 MiB\n",
      "[ 204/ 464]                 blk.18.attn_q.weight - [ 3584,  4096,     1,     1], type =   bf16, converting to q4_1 .. size =    28.00 MiB ->     8.75 MiB\n",
      "[ 205/ 464]                 blk.18.attn_v.weight - [ 3584,  2048,     1,     1], type =   bf16, converting to q4_1 .. size =    14.00 MiB ->     4.38 MiB\n",
      "[ 206/ 464]               blk.18.ffn_down.weight - [14336,  3584,     1,     1], type =   bf16, converting to q4_1 .. size =    98.00 MiB ->    30.62 MiB\n",
      "[ 207/ 464]               blk.18.ffn_gate.weight - [ 3584, 14336,     1,     1], type =   bf16, converting to q4_1 .. size =    98.00 MiB ->    30.62 MiB\n",
      "[ 208/ 464]               blk.18.ffn_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
      "[ 209/ 464]                 blk.18.ffn_up.weight - [ 3584, 14336,     1,     1], type =   bf16, converting to q4_1 .. size =    98.00 MiB ->    30.62 MiB\n",
      "[ 210/ 464]    blk.18.post_attention_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
      "[ 211/ 464]          blk.18.post_ffw_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
      "[ 212/ 464]                 blk.19.attn_k.weight - [ 3584,  2048,     1,     1], type =   bf16, converting to q4_1 .. size =    14.00 MiB ->     4.38 MiB\n",
      "[ 213/ 464]              blk.19.attn_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
      "[ 214/ 464]            blk.19.attn_output.weight - [ 4096,  3584,     1,     1], type =   bf16, converting to q4_1 .. size =    28.00 MiB ->     8.75 MiB\n",
      "[ 215/ 464]                 blk.19.attn_q.weight - [ 3584,  4096,     1,     1], type =   bf16, converting to q4_1 .. size =    28.00 MiB ->     8.75 MiB\n",
      "[ 216/ 464]                 blk.19.attn_v.weight - [ 3584,  2048,     1,     1], type =   bf16, converting to q4_1 .. size =    14.00 MiB ->     4.38 MiB\n",
      "[ 217/ 464]               blk.19.ffn_down.weight - [14336,  3584,     1,     1], type =   bf16, converting to q4_1 .. size =    98.00 MiB ->    30.62 MiB\n",
      "[ 218/ 464]               blk.19.ffn_gate.weight - [ 3584, 14336,     1,     1], type =   bf16, converting to q4_1 .. size =    98.00 MiB ->    30.62 MiB\n",
      "[ 219/ 464]               blk.19.ffn_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
      "[ 220/ 464]                 blk.19.ffn_up.weight - [ 3584, 14336,     1,     1], type =   bf16, converting to q4_1 .. size =    98.00 MiB ->    30.62 MiB\n",
      "[ 221/ 464]    blk.19.post_attention_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
      "[ 222/ 464]          blk.19.post_ffw_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
      "[ 223/ 464]                 blk.20.attn_k.weight - [ 3584,  2048,     1,     1], type =   bf16, converting to q4_1 .. size =    14.00 MiB ->     4.38 MiB\n",
      "[ 224/ 464]              blk.20.attn_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
      "[ 225/ 464]            blk.20.attn_output.weight - [ 4096,  3584,     1,     1], type =   bf16, converting to q4_1 .. size =    28.00 MiB ->     8.75 MiB\n",
      "[ 226/ 464]                 blk.20.attn_q.weight - [ 3584,  4096,     1,     1], type =   bf16, converting to q4_1 .. size =    28.00 MiB ->     8.75 MiB\n",
      "[ 227/ 464]                 blk.20.attn_v.weight - [ 3584,  2048,     1,     1], type =   bf16, converting to q4_1 .. size =    14.00 MiB ->     4.38 MiB\n",
      "[ 228/ 464]               blk.20.ffn_down.weight - [14336,  3584,     1,     1], type =   bf16, converting to q4_1 .. size =    98.00 MiB ->    30.62 MiB\n",
      "[ 229/ 464]               blk.20.ffn_gate.weight - [ 3584, 14336,     1,     1], type =   bf16, converting to q4_1 .. size =    98.00 MiB ->    30.62 MiB\n",
      "[ 230/ 464]               blk.20.ffn_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
      "[ 231/ 464]                 blk.20.ffn_up.weight - [ 3584, 14336,     1,     1], type =   bf16, converting to q4_1 .. size =    98.00 MiB ->    30.62 MiB\n",
      "[ 232/ 464]    blk.20.post_attention_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
      "[ 233/ 464]          blk.20.post_ffw_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
      "[ 234/ 464]                 blk.21.attn_k.weight - [ 3584,  2048,     1,     1], type =   bf16, converting to q4_1 .. size =    14.00 MiB ->     4.38 MiB\n",
      "[ 235/ 464]              blk.21.attn_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
      "[ 236/ 464]            blk.21.attn_output.weight - [ 4096,  3584,     1,     1], type =   bf16, converting to q4_1 .. size =    28.00 MiB ->     8.75 MiB\n",
      "[ 237/ 464]                 blk.21.attn_q.weight - [ 3584,  4096,     1,     1], type =   bf16, converting to q4_1 .. size =    28.00 MiB ->     8.75 MiB\n",
      "[ 238/ 464]                 blk.21.attn_v.weight - [ 3584,  2048,     1,     1], type =   bf16, converting to q4_1 .. size =    14.00 MiB ->     4.38 MiB\n",
      "[ 239/ 464]               blk.21.ffn_down.weight - [14336,  3584,     1,     1], type =   bf16, converting to q4_1 .. size =    98.00 MiB ->    30.62 MiB\n",
      "[ 240/ 464]               blk.21.ffn_gate.weight - [ 3584, 14336,     1,     1], type =   bf16, converting to q4_1 .. size =    98.00 MiB ->    30.62 MiB\n",
      "[ 241/ 464]               blk.21.ffn_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
      "[ 242/ 464]                 blk.21.ffn_up.weight - [ 3584, 14336,     1,     1], type =   bf16, converting to q4_1 .. size =    98.00 MiB ->    30.62 MiB\n",
      "[ 243/ 464]    blk.21.post_attention_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
      "[ 244/ 464]          blk.21.post_ffw_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
      "[ 245/ 464]                 blk.22.attn_k.weight - [ 3584,  2048,     1,     1], type =   bf16, converting to q4_1 .. size =    14.00 MiB ->     4.38 MiB\n",
      "[ 246/ 464]              blk.22.attn_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
      "[ 247/ 464]            blk.22.attn_output.weight - [ 4096,  3584,     1,     1], type =   bf16, converting to q4_1 .. size =    28.00 MiB ->     8.75 MiB\n",
      "[ 248/ 464]                 blk.22.attn_q.weight - [ 3584,  4096,     1,     1], type =   bf16, converting to q4_1 .. size =    28.00 MiB ->     8.75 MiB\n",
      "[ 249/ 464]                 blk.22.attn_v.weight - [ 3584,  2048,     1,     1], type =   bf16, converting to q4_1 .. size =    14.00 MiB ->     4.38 MiB\n",
      "[ 250/ 464]               blk.22.ffn_down.weight - [14336,  3584,     1,     1], type =   bf16, converting to q4_1 .. size =    98.00 MiB ->    30.62 MiB\n",
      "[ 251/ 464]               blk.22.ffn_gate.weight - [ 3584, 14336,     1,     1], type =   bf16, converting to q4_1 .. size =    98.00 MiB ->    30.62 MiB\n",
      "[ 252/ 464]               blk.22.ffn_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
      "[ 253/ 464]                 blk.22.ffn_up.weight - [ 3584, 14336,     1,     1], type =   bf16, converting to q4_1 .. size =    98.00 MiB ->    30.62 MiB\n",
      "[ 254/ 464]    blk.22.post_attention_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
      "[ 255/ 464]          blk.22.post_ffw_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
      "[ 256/ 464]                 blk.23.attn_k.weight - [ 3584,  2048,     1,     1], type =   bf16, converting to q4_1 .. size =    14.00 MiB ->     4.38 MiB\n",
      "[ 257/ 464]              blk.23.attn_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
      "[ 258/ 464]            blk.23.attn_output.weight - [ 4096,  3584,     1,     1], type =   bf16, converting to q4_1 .. size =    28.00 MiB ->     8.75 MiB\n",
      "[ 259/ 464]                 blk.23.attn_q.weight - [ 3584,  4096,     1,     1], type =   bf16, converting to q4_1 .. size =    28.00 MiB ->     8.75 MiB\n",
      "[ 260/ 464]                 blk.23.attn_v.weight - [ 3584,  2048,     1,     1], type =   bf16, converting to q4_1 .. size =    14.00 MiB ->     4.38 MiB\n",
      "[ 261/ 464]               blk.23.ffn_down.weight - [14336,  3584,     1,     1], type =   bf16, converting to q4_1 .. size =    98.00 MiB ->    30.62 MiB\n",
      "[ 262/ 464]               blk.23.ffn_gate.weight - [ 3584, 14336,     1,     1], type =   bf16, converting to q4_1 .. size =    98.00 MiB ->    30.62 MiB\n",
      "[ 263/ 464]               blk.23.ffn_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
      "[ 264/ 464]                 blk.23.ffn_up.weight - [ 3584, 14336,     1,     1], type =   bf16, converting to q4_1 .. size =    98.00 MiB ->    30.62 MiB\n",
      "[ 265/ 464]    blk.23.post_attention_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
      "[ 266/ 464]          blk.23.post_ffw_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
      "[ 267/ 464]                 blk.24.attn_k.weight - [ 3584,  2048,     1,     1], type =   bf16, converting to q4_1 .. size =    14.00 MiB ->     4.38 MiB\n",
      "[ 268/ 464]              blk.24.attn_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
      "[ 269/ 464]            blk.24.attn_output.weight - [ 4096,  3584,     1,     1], type =   bf16, converting to q4_1 .. size =    28.00 MiB ->     8.75 MiB\n",
      "[ 270/ 464]                 blk.24.attn_q.weight - [ 3584,  4096,     1,     1], type =   bf16, converting to q4_1 .. size =    28.00 MiB ->     8.75 MiB\n",
      "[ 271/ 464]                 blk.24.attn_v.weight - [ 3584,  2048,     1,     1], type =   bf16, converting to q4_1 .. size =    14.00 MiB ->     4.38 MiB\n",
      "[ 272/ 464]               blk.24.ffn_down.weight - [14336,  3584,     1,     1], type =   bf16, converting to q4_1 .. size =    98.00 MiB ->    30.62 MiB\n",
      "[ 273/ 464]               blk.24.ffn_gate.weight - [ 3584, 14336,     1,     1], type =   bf16, converting to q4_1 .. size =    98.00 MiB ->    30.62 MiB\n",
      "[ 274/ 464]               blk.24.ffn_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
      "[ 275/ 464]                 blk.24.ffn_up.weight - [ 3584, 14336,     1,     1], type =   bf16, converting to q4_1 .. size =    98.00 MiB ->    30.62 MiB\n",
      "[ 276/ 464]    blk.24.post_attention_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
      "[ 277/ 464]          blk.24.post_ffw_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
      "[ 278/ 464]                 blk.25.attn_k.weight - [ 3584,  2048,     1,     1], type =   bf16, converting to q4_1 .. size =    14.00 MiB ->     4.38 MiB\n",
      "[ 279/ 464]              blk.25.attn_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
      "[ 280/ 464]            blk.25.attn_output.weight - [ 4096,  3584,     1,     1], type =   bf16, converting to q4_1 .. size =    28.00 MiB ->     8.75 MiB\n",
      "[ 281/ 464]                 blk.25.attn_q.weight - [ 3584,  4096,     1,     1], type =   bf16, converting to q4_1 .. size =    28.00 MiB ->     8.75 MiB\n",
      "[ 282/ 464]                 blk.25.attn_v.weight - [ 3584,  2048,     1,     1], type =   bf16, converting to q4_1 .. size =    14.00 MiB ->     4.38 MiB\n",
      "[ 283/ 464]               blk.25.ffn_down.weight - [14336,  3584,     1,     1], type =   bf16, converting to q4_1 .. size =    98.00 MiB ->    30.62 MiB\n",
      "[ 284/ 464]               blk.25.ffn_gate.weight - [ 3584, 14336,     1,     1], type =   bf16, converting to q4_1 .. size =    98.00 MiB ->    30.62 MiB\n",
      "[ 285/ 464]               blk.25.ffn_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
      "[ 286/ 464]                 blk.25.ffn_up.weight - [ 3584, 14336,     1,     1], type =   bf16, converting to q4_1 .. size =    98.00 MiB ->    30.62 MiB\n",
      "[ 287/ 464]    blk.25.post_attention_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
      "[ 288/ 464]          blk.25.post_ffw_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
      "[ 289/ 464]                 blk.26.attn_k.weight - [ 3584,  2048,     1,     1], type =   bf16, converting to q4_1 .. size =    14.00 MiB ->     4.38 MiB\n",
      "[ 290/ 464]              blk.26.attn_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
      "[ 291/ 464]            blk.26.attn_output.weight - [ 4096,  3584,     1,     1], type =   bf16, converting to q4_1 .. size =    28.00 MiB ->     8.75 MiB\n",
      "[ 292/ 464]                 blk.26.attn_q.weight - [ 3584,  4096,     1,     1], type =   bf16, converting to q4_1 .. size =    28.00 MiB ->     8.75 MiB\n",
      "[ 293/ 464]                 blk.26.attn_v.weight - [ 3584,  2048,     1,     1], type =   bf16, converting to q4_1 .. size =    14.00 MiB ->     4.38 MiB\n",
      "[ 294/ 464]               blk.26.ffn_down.weight - [14336,  3584,     1,     1], type =   bf16, converting to q4_1 .. size =    98.00 MiB ->    30.62 MiB\n",
      "[ 295/ 464]               blk.26.ffn_gate.weight - [ 3584, 14336,     1,     1], type =   bf16, converting to q4_1 .. size =    98.00 MiB ->    30.62 MiB\n",
      "[ 296/ 464]               blk.26.ffn_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
      "[ 297/ 464]                 blk.26.ffn_up.weight - [ 3584, 14336,     1,     1], type =   bf16, converting to q4_1 .. size =    98.00 MiB ->    30.62 MiB\n",
      "[ 298/ 464]    blk.26.post_attention_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
      "[ 299/ 464]          blk.26.post_ffw_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
      "[ 300/ 464]                 blk.27.attn_k.weight - [ 3584,  2048,     1,     1], type =   bf16, converting to q4_1 .. size =    14.00 MiB ->     4.38 MiB\n",
      "[ 301/ 464]              blk.27.attn_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
      "[ 302/ 464]            blk.27.attn_output.weight - [ 4096,  3584,     1,     1], type =   bf16, converting to q4_1 .. size =    28.00 MiB ->     8.75 MiB\n",
      "[ 303/ 464]                 blk.27.attn_q.weight - [ 3584,  4096,     1,     1], type =   bf16, converting to q4_1 .. size =    28.00 MiB ->     8.75 MiB\n",
      "[ 304/ 464]                 blk.27.attn_v.weight - [ 3584,  2048,     1,     1], type =   bf16, converting to q4_1 .. size =    14.00 MiB ->     4.38 MiB\n",
      "[ 305/ 464]               blk.27.ffn_down.weight - [14336,  3584,     1,     1], type =   bf16, converting to q4_1 .. size =    98.00 MiB ->    30.62 MiB\n",
      "[ 306/ 464]               blk.27.ffn_gate.weight - [ 3584, 14336,     1,     1], type =   bf16, converting to q4_1 .. size =    98.00 MiB ->    30.62 MiB\n",
      "[ 307/ 464]               blk.27.ffn_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
      "[ 308/ 464]                 blk.27.ffn_up.weight - [ 3584, 14336,     1,     1], type =   bf16, converting to q4_1 .. size =    98.00 MiB ->    30.62 MiB\n",
      "[ 309/ 464]    blk.27.post_attention_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
      "[ 310/ 464]          blk.27.post_ffw_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
      "[ 311/ 464]                 blk.28.attn_k.weight - [ 3584,  2048,     1,     1], type =   bf16, converting to q4_1 .. size =    14.00 MiB ->     4.38 MiB\n",
      "[ 312/ 464]              blk.28.attn_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
      "[ 313/ 464]            blk.28.attn_output.weight - [ 4096,  3584,     1,     1], type =   bf16, converting to q4_1 .. size =    28.00 MiB ->     8.75 MiB\n",
      "[ 314/ 464]                 blk.28.attn_q.weight - [ 3584,  4096,     1,     1], type =   bf16, converting to q4_1 .. size =    28.00 MiB ->     8.75 MiB\n",
      "[ 315/ 464]                 blk.28.attn_v.weight - [ 3584,  2048,     1,     1], type =   bf16, converting to q4_1 .. size =    14.00 MiB ->     4.38 MiB\n",
      "[ 316/ 464]               blk.28.ffn_down.weight - [14336,  3584,     1,     1], type =   bf16, converting to q4_1 .. size =    98.00 MiB ->    30.62 MiB\n",
      "[ 317/ 464]               blk.28.ffn_gate.weight - [ 3584, 14336,     1,     1], type =   bf16, converting to q4_1 .. size =    98.00 MiB ->    30.62 MiB\n",
      "[ 318/ 464]               blk.28.ffn_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
      "[ 319/ 464]                 blk.28.ffn_up.weight - [ 3584, 14336,     1,     1], type =   bf16, converting to q4_1 .. size =    98.00 MiB ->    30.62 MiB\n",
      "[ 320/ 464]    blk.28.post_attention_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
      "[ 321/ 464]          blk.28.post_ffw_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
      "[ 322/ 464]                 blk.29.attn_k.weight - [ 3584,  2048,     1,     1], type =   bf16, converting to q4_1 .. size =    14.00 MiB ->     4.38 MiB\n",
      "[ 323/ 464]              blk.29.attn_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
      "[ 324/ 464]            blk.29.attn_output.weight - [ 4096,  3584,     1,     1], type =   bf16, converting to q4_1 .. size =    28.00 MiB ->     8.75 MiB\n",
      "[ 325/ 464]                 blk.29.attn_q.weight - [ 3584,  4096,     1,     1], type =   bf16, converting to q4_1 .. size =    28.00 MiB ->     8.75 MiB\n",
      "[ 326/ 464]                 blk.29.attn_v.weight - [ 3584,  2048,     1,     1], type =   bf16, converting to q4_1 .. size =    14.00 MiB ->     4.38 MiB\n",
      "[ 327/ 464]               blk.29.ffn_down.weight - [14336,  3584,     1,     1], type =   bf16, converting to q4_1 .. size =    98.00 MiB ->    30.62 MiB\n",
      "[ 328/ 464]               blk.29.ffn_gate.weight - [ 3584, 14336,     1,     1], type =   bf16, converting to q4_1 .. size =    98.00 MiB ->    30.62 MiB\n",
      "[ 329/ 464]               blk.29.ffn_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
      "[ 330/ 464]                 blk.29.ffn_up.weight - [ 3584, 14336,     1,     1], type =   bf16, converting to q4_1 .. size =    98.00 MiB ->    30.62 MiB\n",
      "[ 331/ 464]    blk.29.post_attention_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
      "[ 332/ 464]          blk.29.post_ffw_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
      "[ 333/ 464]                 blk.30.attn_k.weight - [ 3584,  2048,     1,     1], type =   bf16, converting to q4_1 .. size =    14.00 MiB ->     4.38 MiB\n",
      "[ 334/ 464]              blk.30.attn_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
      "[ 335/ 464]            blk.30.attn_output.weight - [ 4096,  3584,     1,     1], type =   bf16, converting to q4_1 .. size =    28.00 MiB ->     8.75 MiB\n",
      "[ 336/ 464]                 blk.30.attn_q.weight - [ 3584,  4096,     1,     1], type =   bf16, converting to q4_1 .. size =    28.00 MiB ->     8.75 MiB\n",
      "[ 337/ 464]                 blk.30.attn_v.weight - [ 3584,  2048,     1,     1], type =   bf16, converting to q4_1 .. size =    14.00 MiB ->     4.38 MiB\n",
      "[ 338/ 464]               blk.30.ffn_down.weight - [14336,  3584,     1,     1], type =   bf16, converting to q4_1 .. size =    98.00 MiB ->    30.62 MiB\n",
      "[ 339/ 464]               blk.30.ffn_gate.weight - [ 3584, 14336,     1,     1], type =   bf16, converting to q4_1 .. size =    98.00 MiB ->    30.62 MiB\n",
      "[ 340/ 464]               blk.30.ffn_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
      "[ 341/ 464]                 blk.30.ffn_up.weight - [ 3584, 14336,     1,     1], type =   bf16, converting to q4_1 .. size =    98.00 MiB ->    30.62 MiB\n",
      "[ 342/ 464]    blk.30.post_attention_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
      "[ 343/ 464]          blk.30.post_ffw_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
      "[ 344/ 464]                 blk.31.attn_k.weight - [ 3584,  2048,     1,     1], type =   bf16, converting to q4_1 .. size =    14.00 MiB ->     4.38 MiB\n",
      "[ 345/ 464]              blk.31.attn_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
      "[ 346/ 464]            blk.31.attn_output.weight - [ 4096,  3584,     1,     1], type =   bf16, converting to q4_1 .. size =    28.00 MiB ->     8.75 MiB\n",
      "[ 347/ 464]                 blk.31.attn_q.weight - [ 3584,  4096,     1,     1], type =   bf16, converting to q4_1 .. size =    28.00 MiB ->     8.75 MiB\n",
      "[ 348/ 464]                 blk.31.attn_v.weight - [ 3584,  2048,     1,     1], type =   bf16, converting to q4_1 .. size =    14.00 MiB ->     4.38 MiB\n",
      "[ 349/ 464]               blk.31.ffn_down.weight - [14336,  3584,     1,     1], type =   bf16, converting to q4_1 .. size =    98.00 MiB ->    30.62 MiB\n",
      "[ 350/ 464]               blk.31.ffn_gate.weight - [ 3584, 14336,     1,     1], type =   bf16, converting to q4_1 .. size =    98.00 MiB ->    30.62 MiB\n",
      "[ 351/ 464]               blk.31.ffn_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
      "[ 352/ 464]                 blk.31.ffn_up.weight - [ 3584, 14336,     1,     1], type =   bf16, converting to q4_1 .. size =    98.00 MiB ->    30.62 MiB\n",
      "[ 353/ 464]    blk.31.post_attention_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
      "[ 354/ 464]          blk.31.post_ffw_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
      "[ 355/ 464]                 blk.32.attn_k.weight - [ 3584,  2048,     1,     1], type =   bf16, converting to q4_1 .. size =    14.00 MiB ->     4.38 MiB\n",
      "[ 356/ 464]              blk.32.attn_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
      "[ 357/ 464]            blk.32.attn_output.weight - [ 4096,  3584,     1,     1], type =   bf16, converting to q4_1 .. size =    28.00 MiB ->     8.75 MiB\n",
      "[ 358/ 464]                 blk.32.attn_q.weight - [ 3584,  4096,     1,     1], type =   bf16, converting to q4_1 .. size =    28.00 MiB ->     8.75 MiB\n",
      "[ 359/ 464]                 blk.32.attn_v.weight - [ 3584,  2048,     1,     1], type =   bf16, converting to q4_1 .. size =    14.00 MiB ->     4.38 MiB\n",
      "[ 360/ 464]               blk.32.ffn_down.weight - [14336,  3584,     1,     1], type =   bf16, converting to q4_1 .. size =    98.00 MiB ->    30.62 MiB\n",
      "[ 361/ 464]               blk.32.ffn_gate.weight - [ 3584, 14336,     1,     1], type =   bf16, converting to q4_1 .. size =    98.00 MiB ->    30.62 MiB\n",
      "[ 362/ 464]               blk.32.ffn_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
      "[ 363/ 464]                 blk.32.ffn_up.weight - [ 3584, 14336,     1,     1], type =   bf16, converting to q4_1 .. size =    98.00 MiB ->    30.62 MiB\n",
      "[ 364/ 464]    blk.32.post_attention_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
      "[ 365/ 464]          blk.32.post_ffw_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
      "[ 366/ 464]                 blk.33.attn_k.weight - [ 3584,  2048,     1,     1], type =   bf16, converting to q4_1 .. size =    14.00 MiB ->     4.38 MiB\n",
      "[ 367/ 464]              blk.33.attn_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
      "[ 368/ 464]            blk.33.attn_output.weight - [ 4096,  3584,     1,     1], type =   bf16, converting to q4_1 .. size =    28.00 MiB ->     8.75 MiB\n",
      "[ 369/ 464]                 blk.33.attn_q.weight - [ 3584,  4096,     1,     1], type =   bf16, converting to q4_1 .. size =    28.00 MiB ->     8.75 MiB\n",
      "[ 370/ 464]                 blk.33.attn_v.weight - [ 3584,  2048,     1,     1], type =   bf16, converting to q4_1 .. size =    14.00 MiB ->     4.38 MiB\n",
      "[ 371/ 464]               blk.33.ffn_down.weight - [14336,  3584,     1,     1], type =   bf16, converting to q4_1 .. size =    98.00 MiB ->    30.62 MiB\n",
      "[ 372/ 464]               blk.33.ffn_gate.weight - [ 3584, 14336,     1,     1], type =   bf16, converting to q4_1 .. size =    98.00 MiB ->    30.62 MiB\n",
      "[ 373/ 464]               blk.33.ffn_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
      "[ 374/ 464]                 blk.33.ffn_up.weight - [ 3584, 14336,     1,     1], type =   bf16, converting to q4_1 .. size =    98.00 MiB ->    30.62 MiB\n",
      "[ 375/ 464]    blk.33.post_attention_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
      "[ 376/ 464]          blk.33.post_ffw_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
      "[ 377/ 464]                 blk.34.attn_k.weight - [ 3584,  2048,     1,     1], type =   bf16, converting to q4_1 .. size =    14.00 MiB ->     4.38 MiB\n",
      "[ 378/ 464]              blk.34.attn_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
      "[ 379/ 464]            blk.34.attn_output.weight - [ 4096,  3584,     1,     1], type =   bf16, converting to q4_1 .. size =    28.00 MiB ->     8.75 MiB\n",
      "[ 380/ 464]                 blk.34.attn_q.weight - [ 3584,  4096,     1,     1], type =   bf16, converting to q4_1 .. size =    28.00 MiB ->     8.75 MiB\n",
      "[ 381/ 464]                 blk.34.attn_v.weight - [ 3584,  2048,     1,     1], type =   bf16, converting to q4_1 .. size =    14.00 MiB ->     4.38 MiB\n",
      "[ 382/ 464]               blk.34.ffn_down.weight - [14336,  3584,     1,     1], type =   bf16, converting to q4_1 .. size =    98.00 MiB ->    30.62 MiB\n",
      "[ 383/ 464]               blk.34.ffn_gate.weight - [ 3584, 14336,     1,     1], type =   bf16, converting to q4_1 .. size =    98.00 MiB ->    30.62 MiB\n",
      "[ 384/ 464]               blk.34.ffn_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
      "[ 385/ 464]                 blk.34.ffn_up.weight - [ 3584, 14336,     1,     1], type =   bf16, converting to q4_1 .. size =    98.00 MiB ->    30.62 MiB\n",
      "[ 386/ 464]    blk.34.post_attention_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
      "[ 387/ 464]          blk.34.post_ffw_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
      "[ 388/ 464]                 blk.35.attn_k.weight - [ 3584,  2048,     1,     1], type =   bf16, converting to q4_1 .. size =    14.00 MiB ->     4.38 MiB\n",
      "[ 389/ 464]              blk.35.attn_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
      "[ 390/ 464]            blk.35.attn_output.weight - [ 4096,  3584,     1,     1], type =   bf16, converting to q4_1 .. size =    28.00 MiB ->     8.75 MiB\n",
      "[ 391/ 464]                 blk.35.attn_q.weight - [ 3584,  4096,     1,     1], type =   bf16, converting to q4_1 .. size =    28.00 MiB ->     8.75 MiB\n",
      "[ 392/ 464]                 blk.35.attn_v.weight - [ 3584,  2048,     1,     1], type =   bf16, converting to q4_1 .. size =    14.00 MiB ->     4.38 MiB\n",
      "[ 393/ 464]               blk.35.ffn_down.weight - [14336,  3584,     1,     1], type =   bf16, converting to q4_1 .. size =    98.00 MiB ->    30.62 MiB\n",
      "[ 394/ 464]               blk.35.ffn_gate.weight - [ 3584, 14336,     1,     1], type =   bf16, converting to q4_1 .. size =    98.00 MiB ->    30.62 MiB\n",
      "[ 395/ 464]               blk.35.ffn_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
      "[ 396/ 464]                 blk.35.ffn_up.weight - [ 3584, 14336,     1,     1], type =   bf16, converting to q4_1 .. size =    98.00 MiB ->    30.62 MiB\n",
      "[ 397/ 464]    blk.35.post_attention_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
      "[ 398/ 464]          blk.35.post_ffw_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
      "[ 399/ 464]                 blk.36.attn_k.weight - [ 3584,  2048,     1,     1], type =   bf16, converting to q4_1 .. size =    14.00 MiB ->     4.38 MiB\n",
      "[ 400/ 464]              blk.36.attn_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
      "[ 401/ 464]            blk.36.attn_output.weight - [ 4096,  3584,     1,     1], type =   bf16, converting to q4_1 .. size =    28.00 MiB ->     8.75 MiB\n",
      "[ 402/ 464]                 blk.36.attn_q.weight - [ 3584,  4096,     1,     1], type =   bf16, converting to q4_1 .. size =    28.00 MiB ->     8.75 MiB\n",
      "[ 403/ 464]                 blk.36.attn_v.weight - [ 3584,  2048,     1,     1], type =   bf16, converting to q4_1 .. size =    14.00 MiB ->     4.38 MiB\n",
      "[ 404/ 464]               blk.36.ffn_down.weight - [14336,  3584,     1,     1], type =   bf16, converting to q4_1 .. size =    98.00 MiB ->    30.62 MiB\n",
      "[ 405/ 464]               blk.36.ffn_gate.weight - [ 3584, 14336,     1,     1], type =   bf16, converting to q4_1 .. size =    98.00 MiB ->    30.62 MiB\n",
      "[ 406/ 464]               blk.36.ffn_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
      "[ 407/ 464]                 blk.36.ffn_up.weight - [ 3584, 14336,     1,     1], type =   bf16, converting to q4_1 .. size =    98.00 MiB ->    30.62 MiB\n",
      "[ 408/ 464]    blk.36.post_attention_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
      "[ 409/ 464]          blk.36.post_ffw_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
      "[ 410/ 464]                 blk.37.attn_k.weight - [ 3584,  2048,     1,     1], type =   bf16, converting to q4_1 .. size =    14.00 MiB ->     4.38 MiB\n",
      "[ 411/ 464]              blk.37.attn_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
      "[ 412/ 464]            blk.37.attn_output.weight - [ 4096,  3584,     1,     1], type =   bf16, converting to q4_1 .. size =    28.00 MiB ->     8.75 MiB\n",
      "[ 413/ 464]                 blk.37.attn_q.weight - [ 3584,  4096,     1,     1], type =   bf16, converting to q4_1 .. size =    28.00 MiB ->     8.75 MiB\n",
      "[ 414/ 464]                 blk.37.attn_v.weight - [ 3584,  2048,     1,     1], type =   bf16, converting to q4_1 .. size =    14.00 MiB ->     4.38 MiB\n",
      "[ 415/ 464]               blk.37.ffn_down.weight - [14336,  3584,     1,     1], type =   bf16, converting to q4_1 .. size =    98.00 MiB ->    30.62 MiB\n",
      "[ 416/ 464]               blk.37.ffn_gate.weight - [ 3584, 14336,     1,     1], type =   bf16, converting to q4_1 .. size =    98.00 MiB ->    30.62 MiB\n",
      "[ 417/ 464]               blk.37.ffn_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
      "[ 418/ 464]                 blk.37.ffn_up.weight - [ 3584, 14336,     1,     1], type =   bf16, converting to q4_1 .. size =    98.00 MiB ->    30.62 MiB\n",
      "[ 419/ 464]    blk.37.post_attention_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
      "[ 420/ 464]          blk.37.post_ffw_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
      "[ 421/ 464]                 blk.38.attn_k.weight - [ 3584,  2048,     1,     1], type =   bf16, converting to q4_1 .. size =    14.00 MiB ->     4.38 MiB\n",
      "[ 422/ 464]              blk.38.attn_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
      "[ 423/ 464]            blk.38.attn_output.weight - [ 4096,  3584,     1,     1], type =   bf16, converting to q4_1 .. size =    28.00 MiB ->     8.75 MiB\n",
      "[ 424/ 464]                 blk.38.attn_q.weight - [ 3584,  4096,     1,     1], type =   bf16, converting to q4_1 .. size =    28.00 MiB ->     8.75 MiB\n",
      "[ 425/ 464]                 blk.38.attn_v.weight - [ 3584,  2048,     1,     1], type =   bf16, converting to q4_1 .. size =    14.00 MiB ->     4.38 MiB\n",
      "[ 426/ 464]               blk.38.ffn_down.weight - [14336,  3584,     1,     1], type =   bf16, converting to q4_1 .. size =    98.00 MiB ->    30.62 MiB\n",
      "[ 427/ 464]               blk.38.ffn_gate.weight - [ 3584, 14336,     1,     1], type =   bf16, converting to q4_1 .. size =    98.00 MiB ->    30.62 MiB\n",
      "[ 428/ 464]               blk.38.ffn_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
      "[ 429/ 464]                 blk.38.ffn_up.weight - [ 3584, 14336,     1,     1], type =   bf16, converting to q4_1 .. size =    98.00 MiB ->    30.62 MiB\n",
      "[ 430/ 464]    blk.38.post_attention_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
      "[ 431/ 464]          blk.38.post_ffw_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
      "[ 432/ 464]                 blk.39.attn_k.weight - [ 3584,  2048,     1,     1], type =   bf16, converting to q4_1 .. size =    14.00 MiB ->     4.38 MiB\n",
      "[ 433/ 464]              blk.39.attn_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
      "[ 434/ 464]            blk.39.attn_output.weight - [ 4096,  3584,     1,     1], type =   bf16, converting to q4_1 .. size =    28.00 MiB ->     8.75 MiB\n",
      "[ 435/ 464]                 blk.39.attn_q.weight - [ 3584,  4096,     1,     1], type =   bf16, converting to q4_1 .. size =    28.00 MiB ->     8.75 MiB\n",
      "[ 436/ 464]                 blk.39.attn_v.weight - [ 3584,  2048,     1,     1], type =   bf16, converting to q4_1 .. size =    14.00 MiB ->     4.38 MiB\n",
      "[ 437/ 464]               blk.39.ffn_down.weight - [14336,  3584,     1,     1], type =   bf16, converting to q4_1 .. size =    98.00 MiB ->    30.62 MiB\n",
      "[ 438/ 464]               blk.39.ffn_gate.weight - [ 3584, 14336,     1,     1], type =   bf16, converting to q4_1 .. size =    98.00 MiB ->    30.62 MiB\n",
      "[ 439/ 464]               blk.39.ffn_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
      "[ 440/ 464]                 blk.39.ffn_up.weight - [ 3584, 14336,     1,     1], type =   bf16, converting to q4_1 .. size =    98.00 MiB ->    30.62 MiB\n",
      "[ 441/ 464]    blk.39.post_attention_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
      "[ 442/ 464]          blk.39.post_ffw_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
      "[ 443/ 464]                 blk.40.attn_k.weight - [ 3584,  2048,     1,     1], type =   bf16, converting to q4_1 .. size =    14.00 MiB ->     4.38 MiB\n",
      "[ 444/ 464]              blk.40.attn_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
      "[ 445/ 464]            blk.40.attn_output.weight - [ 4096,  3584,     1,     1], type =   bf16, converting to q4_1 .. size =    28.00 MiB ->     8.75 MiB\n",
      "[ 446/ 464]                 blk.40.attn_q.weight - [ 3584,  4096,     1,     1], type =   bf16, converting to q4_1 .. size =    28.00 MiB ->     8.75 MiB\n",
      "[ 447/ 464]                 blk.40.attn_v.weight - [ 3584,  2048,     1,     1], type =   bf16, converting to q4_1 .. size =    14.00 MiB ->     4.38 MiB\n",
      "[ 448/ 464]               blk.40.ffn_down.weight - [14336,  3584,     1,     1], type =   bf16, converting to q4_1 .. size =    98.00 MiB ->    30.62 MiB\n",
      "[ 449/ 464]               blk.40.ffn_gate.weight - [ 3584, 14336,     1,     1], type =   bf16, converting to q4_1 .. size =    98.00 MiB ->    30.62 MiB\n",
      "[ 450/ 464]               blk.40.ffn_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
      "[ 451/ 464]                 blk.40.ffn_up.weight - [ 3584, 14336,     1,     1], type =   bf16, converting to q4_1 .. size =    98.00 MiB ->    30.62 MiB\n",
      "[ 452/ 464]    blk.40.post_attention_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
      "[ 453/ 464]          blk.40.post_ffw_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
      "[ 454/ 464]                 blk.41.attn_k.weight - [ 3584,  2048,     1,     1], type =   bf16, converting to q4_1 .. size =    14.00 MiB ->     4.38 MiB\n",
      "[ 455/ 464]              blk.41.attn_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
      "[ 456/ 464]            blk.41.attn_output.weight - [ 4096,  3584,     1,     1], type =   bf16, converting to q4_1 .. size =    28.00 MiB ->     8.75 MiB\n",
      "[ 457/ 464]                 blk.41.attn_q.weight - [ 3584,  4096,     1,     1], type =   bf16, converting to q4_1 .. size =    28.00 MiB ->     8.75 MiB\n",
      "[ 458/ 464]                 blk.41.attn_v.weight - [ 3584,  2048,     1,     1], type =   bf16, converting to q4_1 .. size =    14.00 MiB ->     4.38 MiB\n",
      "[ 459/ 464]               blk.41.ffn_down.weight - [14336,  3584,     1,     1], type =   bf16, converting to q4_1 .. size =    98.00 MiB ->    30.62 MiB\n",
      "[ 460/ 464]               blk.41.ffn_gate.weight - [ 3584, 14336,     1,     1], type =   bf16, converting to q4_1 .. size =    98.00 MiB ->    30.62 MiB\n",
      "[ 461/ 464]               blk.41.ffn_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
      "[ 462/ 464]                 blk.41.ffn_up.weight - [ 3584, 14336,     1,     1], type =   bf16, converting to q4_1 .. size =    98.00 MiB ->    30.62 MiB\n",
      "[ 463/ 464]    blk.41.post_attention_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
      "[ 464/ 464]          blk.41.post_ffw_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
      "llama_model_quantize_impl: model size  = 17628.31 MB\n",
      "llama_model_quantize_impl: quant size  =  5681.33 MB\n",
      "\n",
      "main: quantize time = 22740.10 ms\n",
      "main:    total time = 22740.10 ms\n",
      "Unsloth: Conversion completed! Output location: /content/WildBurger/group1_finetuned_gemma2_v3/unsloth.Q4_1.gguf\n",
      "Unsloth: Uploading GGUF to Huggingface Hub...\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d00dbff7a4b04ca3bdc40aa74b01fe57"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "unsloth.Q4_1.gguf:   0%|          | 0.00/5.96G [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "64c85b6218b044f0811c7af2b2bd2a2d"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "No files have been modified since last commit. Skipping to prevent empty commit.\n",
      "WARNING:huggingface_hub.hf_api:No files have been modified since last commit. Skipping to prevent empty commit.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Saved GGUF to https://huggingface.co/WildBurger/group1_finetuned_gemma2_v3\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": "model.push_to_hub_gguf(\"WildBurger/group1_finetuned_gemma2_v3\", tokenizer, quantization_method = \"q4_k_m\", token = \"\")",
   "metadata": {
    "id": "V5HUGpmbVV1B",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 813,
     "referenced_widgets": [
      "e9a707a78f454fe481c5f843988e5ec9",
      "fc4412542769418db5c362b2ef548e7f",
      "4a94bc2a8e4941548c59e271e032291d",
      "ea81e50ef52b4ad5afc266f6e2b67c27",
      "63059fad228947edbc4f514428d18591",
      "6ad5aa9e57b54138b356e5332f197914",
      "9816963e63994c65b635a2c1048b2a67",
      "7a2024faf8e0476c8b9b100c0d84909f",
      "7c9a5285e0fe41189c0e54e8e5dfea25",
      "09278433f06e4cddb64c4470f54d6ab9",
      "df868ffcbf1147b6b9ac1550fe8101b6",
      "dca90da87e7341c1a810558a500e447a",
      "e6a0196ab9684632a428c59ace7303da",
      "5dde400c225f4be2a5695f2ad1fefe11",
      "526acd1a464f4ef3a00078ae3d0e5f74",
      "874e200a52c243aa98e30e880c845a86",
      "ad48076521fb4ab88f62411bc1bec8bc",
      "1846ea7eb79e4a219a62ed2f81c4c5bf",
      "dd6b5364a2c84dbbbf33295a6e118347",
      "8c55cc46e6004395864c0eecb65f23c4",
      "fa4812ecab9e4b7c99f2c9c9b3d69c19",
      "17b28507d88a421fbb4bddd830fb0d99"
     ]
    },
    "outputId": "fbabe9f7-1fd5-4ba8-9809-5145d1a0d918"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[ 434/ 464]            blk.39.attn_output.weight - [ 4096,  3584,     1,     1], type =   bf16, converting to q4_K .. size =    28.00 MiB ->     7.88 MiB\n",
      "[ 435/ 464]                 blk.39.attn_q.weight - [ 3584,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    28.00 MiB ->     7.88 MiB\n",
      "[ 436/ 464]                 blk.39.attn_v.weight - [ 3584,  2048,     1,     1], type =   bf16, converting to q6_K .. size =    14.00 MiB ->     5.74 MiB\n",
      "[ 437/ 464]               blk.39.ffn_down.weight - [14336,  3584,     1,     1], type =   bf16, converting to q6_K .. size =    98.00 MiB ->    40.20 MiB\n",
      "[ 438/ 464]               blk.39.ffn_gate.weight - [ 3584, 14336,     1,     1], type =   bf16, converting to q4_K .. size =    98.00 MiB ->    27.56 MiB\n",
      "[ 439/ 464]               blk.39.ffn_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
      "[ 440/ 464]                 blk.39.ffn_up.weight - [ 3584, 14336,     1,     1], type =   bf16, converting to q4_K .. size =    98.00 MiB ->    27.56 MiB\n",
      "[ 441/ 464]    blk.39.post_attention_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
      "[ 442/ 464]          blk.39.post_ffw_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
      "[ 443/ 464]                 blk.40.attn_k.weight - [ 3584,  2048,     1,     1], type =   bf16, converting to q4_K .. size =    14.00 MiB ->     3.94 MiB\n",
      "[ 444/ 464]              blk.40.attn_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
      "[ 445/ 464]            blk.40.attn_output.weight - [ 4096,  3584,     1,     1], type =   bf16, converting to q4_K .. size =    28.00 MiB ->     7.88 MiB\n",
      "[ 446/ 464]                 blk.40.attn_q.weight - [ 3584,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    28.00 MiB ->     7.88 MiB\n",
      "[ 447/ 464]                 blk.40.attn_v.weight - [ 3584,  2048,     1,     1], type =   bf16, converting to q6_K .. size =    14.00 MiB ->     5.74 MiB\n",
      "[ 448/ 464]               blk.40.ffn_down.weight - [14336,  3584,     1,     1], type =   bf16, converting to q6_K .. size =    98.00 MiB ->    40.20 MiB\n",
      "[ 449/ 464]               blk.40.ffn_gate.weight - [ 3584, 14336,     1,     1], type =   bf16, converting to q4_K .. size =    98.00 MiB ->    27.56 MiB\n",
      "[ 450/ 464]               blk.40.ffn_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
      "[ 451/ 464]                 blk.40.ffn_up.weight - [ 3584, 14336,     1,     1], type =   bf16, converting to q4_K .. size =    98.00 MiB ->    27.56 MiB\n",
      "[ 452/ 464]    blk.40.post_attention_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
      "[ 453/ 464]          blk.40.post_ffw_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
      "[ 454/ 464]                 blk.41.attn_k.weight - [ 3584,  2048,     1,     1], type =   bf16, converting to q4_K .. size =    14.00 MiB ->     3.94 MiB\n",
      "[ 455/ 464]              blk.41.attn_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
      "[ 456/ 464]            blk.41.attn_output.weight - [ 4096,  3584,     1,     1], type =   bf16, converting to q4_K .. size =    28.00 MiB ->     7.88 MiB\n",
      "[ 457/ 464]                 blk.41.attn_q.weight - [ 3584,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    28.00 MiB ->     7.88 MiB\n",
      "[ 458/ 464]                 blk.41.attn_v.weight - [ 3584,  2048,     1,     1], type =   bf16, converting to q6_K .. size =    14.00 MiB ->     5.74 MiB\n",
      "[ 459/ 464]               blk.41.ffn_down.weight - [14336,  3584,     1,     1], type =   bf16, converting to q6_K .. size =    98.00 MiB ->    40.20 MiB\n",
      "[ 460/ 464]               blk.41.ffn_gate.weight - [ 3584, 14336,     1,     1], type =   bf16, converting to q4_K .. size =    98.00 MiB ->    27.56 MiB\n",
      "[ 461/ 464]               blk.41.ffn_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
      "[ 462/ 464]                 blk.41.ffn_up.weight - [ 3584, 14336,     1,     1], type =   bf16, converting to q4_K .. size =    98.00 MiB ->    27.56 MiB\n",
      "[ 463/ 464]    blk.41.post_attention_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
      "[ 464/ 464]          blk.41.post_ffw_norm.weight - [ 3584,     1,     1,     1], type =    f32, size =    0.014 MB\n",
      "llama_model_quantize_impl: model size  = 17628.31 MB\n",
      "llama_model_quantize_impl: quant size  =  5488.40 MB\n",
      "\n",
      "main: quantize time = 154269.06 ms\n",
      "main:    total time = 154269.06 ms\n",
      "Unsloth: Conversion completed! Output location: /content/WildBurger/group1_finetuned_gemma2_v3/unsloth.Q4_K_M.gguf\n",
      "Unsloth: Uploading GGUF to Huggingface Hub...\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e9a707a78f454fe481c5f843988e5ec9"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "unsloth.Q4_K_M.gguf:   0%|          | 0.00/5.76G [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "dca90da87e7341c1a810558a500e447a"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "No files have been modified since last commit. Skipping to prevent empty commit.\n",
      "WARNING:huggingface_hub.hf_api:No files have been modified since last commit. Skipping to prevent empty commit.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Saved GGUF to https://huggingface.co/WildBurger/group1_finetuned_gemma2_v3\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# print(tokenizer._ollama_modelfile)"
   ],
   "metadata": {
    "id": "sSfBSMzzWGhe"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}
